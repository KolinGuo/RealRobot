{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/rl_benchmark/real_robot/model_checkpoints/XArm_pretrained_ckpt/PlaceCubeInBowlXArm-v5/sac/0-nobboxobs-eepctl-tongzhou8s4u1p-g90/models/model_3200000.ckpt')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "model_ckpt = Path(\"/rl_benchmark/real_robot/model_checkpoints/XArm_pretrained_ckpt\") \\\n",
    "             / \"PlaceCubeInBowlXArm-v5/sac/0-nobboxobs-eepctl-tongzhou8s4u1p-g90/models/model_3200000.ckpt\"\n",
    "model_ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmdline args\n",
    "args = [\n",
    "    '/rl_benchmark/pyrl/configs/mfrl/sac/maniskill2/maniskill2_state.py',\n",
    "    '--eval',\n",
    "    '--cfg-options',\n",
    "    \"env_cfg.env_name=PlaceCubeInBowlXArm-v5\",\n",
    "    \"env_cfg.remove_obs_extra=cube_bbox,bowl_bbox\",\n",
    "    \"env_cfg.control_mode=pd_ee_delta_pos\",\n",
    "    \"env_cfg.horizon=50\",\n",
    "    \n",
    "    \"agent_cfg.actor_cfg.nn_cfg.mlp_spec=obs_shape,256,256,256,action_shape*2\",\n",
    "    \"agent_cfg.critic_cfg.nn_cfg.mlp_spec=obs_shape+action_shape,256,256,256,1\",\n",
    "    \"agent_cfg.actor_cfg.head_cfg.log_std_clip_tanh=True\",\n",
    "    \"agent_cfg.actor_cfg.head_cfg.log_std_bound=-5,2\",\n",
    "    \"agent_cfg.gamma=0.9\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "torchsparse is not installed correctly!\n",
      "No module named 'torchsparse'\n",
      "Pointnet++ is not compiled\n",
      "cannot import name 'ball_query_ext' from partially initialized module 'pyrl.utils.cpp_ops.ops_3d.ball_query' (most likely due to a circular import) (/usr/local/lib/python3.10/dist-packages/pyrl/utils/cpp_ops/ops_3d/ball_query/__init__.py)\n",
      "Piontnet++ is not supported\n",
      "cannot import name 'PointFPModule' from 'pyrl.networks.modules' (/usr/local/lib/python3.10/dist-packages/pyrl/networks/modules/__init__.py)\n",
      "SparseConv is not supported\n",
      "No module named 'torchsparse'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;21mpyrl - (3636172862.py:195) - INFO - 2023-05-19,11:18:35 - Search model under ./work_dirs/PlaceCubeInBowlXArm-v5.\u001b[0m\n",
      "\u001b[38;21mPlaceCubeInBowlXArm-v5-eval - (3636172862.py:288) - INFO - 2023-05-19,11:18:35 - Extra arguments that replace the default setting from the config file.\u001b[0m\n",
      "\u001b[38;21mPlaceCubeInBowlXArm-v5-eval - (3636172862.py:290) - INFO - 2023-05-19,11:18:35 - env_cfg.env_name PlaceCubeInBowlXArm-v5\u001b[0m\n",
      "\u001b[38;21mPlaceCubeInBowlXArm-v5-eval - (3636172862.py:290) - INFO - 2023-05-19,11:18:35 - env_cfg.remove_obs_extra ['cube_bbox', 'bowl_bbox']\u001b[0m\n",
      "\u001b[38;21mPlaceCubeInBowlXArm-v5-eval - (3636172862.py:290) - INFO - 2023-05-19,11:18:35 - env_cfg.control_mode pd_ee_delta_pos\u001b[0m\n",
      "\u001b[38;21mPlaceCubeInBowlXArm-v5-eval - (3636172862.py:290) - INFO - 2023-05-19,11:18:35 - env_cfg.horizon 50\u001b[0m\n",
      "\u001b[38;21mPlaceCubeInBowlXArm-v5-eval - (3636172862.py:290) - INFO - 2023-05-19,11:18:35 - agent_cfg.actor_cfg.nn_cfg.mlp_spec ['obs_shape', 256, 256, 256, 'action_shape*2']\u001b[0m\n",
      "\u001b[38;21mPlaceCubeInBowlXArm-v5-eval - (3636172862.py:290) - INFO - 2023-05-19,11:18:35 - agent_cfg.critic_cfg.nn_cfg.mlp_spec ['obs_shape+action_shape', 256, 256, 256, 1]\u001b[0m\n",
      "\u001b[38;21mPlaceCubeInBowlXArm-v5-eval - (3636172862.py:290) - INFO - 2023-05-19,11:18:35 - agent_cfg.actor_cfg.head_cfg.log_std_clip_tanh True\u001b[0m\n",
      "\u001b[38;21mPlaceCubeInBowlXArm-v5-eval - (3636172862.py:290) - INFO - 2023-05-19,11:18:35 - agent_cfg.actor_cfg.head_cfg.log_std_bound [-5, 2]\u001b[0m\n",
      "\u001b[38;21mPlaceCubeInBowlXArm-v5-eval - (3636172862.py:290) - INFO - 2023-05-19,11:18:35 - agent_cfg.gamma 0.9\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mWARNING\u001b[0m: \u001b[36mFind no checkpoints under ./work_dirs/PlaceCubeInBowlXArm-v5!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;21mPlaceCubeInBowlXArm-v5-eval - (3636172862.py:292) - INFO - 2023-05-19,11:18:35 - Config:\n",
      "agent_cfg = dict(\n",
      "    type='SAC',\n",
      "    batch_size=1024,\n",
      "    gamma=0.9,\n",
      "    update_coeff=0.005,\n",
      "    alpha=0.2,\n",
      "    target_update_interval=1,\n",
      "    automatic_alpha_tuning=True,\n",
      "    alpha_optim_cfg=dict(type='Adam', lr=0.0003),\n",
      "    actor_cfg=dict(\n",
      "        type='ContinuousActor',\n",
      "        head_cfg=dict(\n",
      "            type='TanhGaussianHead',\n",
      "            log_std_bound=[-5, 2],\n",
      "            log_std_clip_tanh=True),\n",
      "        nn_cfg=dict(\n",
      "            type='LinearMLP',\n",
      "            norm_cfg=None,\n",
      "            mlp_spec=['obs_shape', 256, 256, 256, 'action_shape*2'],\n",
      "            bias='auto',\n",
      "            inactivated_output=True,\n",
      "            dense_init_cfg=dict(type='xavier_init', gain=1, bias=0)),\n",
      "        optim_cfg=dict(type='Adam', lr=0.0003)),\n",
      "    critic_cfg=dict(\n",
      "        type='ContinuousCritic',\n",
      "        num_heads='2 + num_constraints',\n",
      "        nn_cfg=dict(\n",
      "            type='LinearMLP',\n",
      "            norm_cfg=None,\n",
      "            bias='auto',\n",
      "            mlp_spec=['obs_shape+action_shape', 256, 256, 256, 1],\n",
      "            inactivated_output=True,\n",
      "            dense_init_cfg=dict(type='xavier_init', gain=1, bias=0)),\n",
      "        optim_cfg=dict(type='Adam', lr=0.0003)),\n",
      "    use_rnd=False,\n",
      "    use_rnd_obs_rms=True,\n",
      "    use_rew_int_rms=True,\n",
      "    rew_int_scale=1.0,\n",
      "    rnd_obs_slice=dict(),\n",
      "    rnd_critic_cfg=dict(\n",
      "        type='ContinuousValue',\n",
      "        num_heads='1',\n",
      "        nn_cfg=dict(\n",
      "            type='LinearMLP',\n",
      "            norm_cfg=None,\n",
      "            bias='auto',\n",
      "            mlp_spec=['obs_shape', 256, 256],\n",
      "            inactivated_output=True,\n",
      "            dense_init_cfg=dict(type='xavier_init', gain=1, bias=0)),\n",
      "        optim_cfg=dict(type='Adam', lr=0.0003)),\n",
      "    constraint_cfg=dict(\n",
      "        lam_model='Parameter',\n",
      "        constraint_type='single_step',\n",
      "        constraint_thresholds=[],\n",
      "        max_ep_len='max_ep_len',\n",
      "        gamma='gamma',\n",
      "        constraint_names=[],\n",
      "        lam_inits=[],\n",
      "        use_constraint_type='discounted_ep',\n",
      "        auto_tuning=True,\n",
      "        lam_nn_cfg=dict(\n",
      "            type='ContinuousValue',\n",
      "            num_heads='num_constraints',\n",
      "            nn_cfg=dict(\n",
      "                type='LinearMLP',\n",
      "                norm_cfg=None,\n",
      "                bias='auto',\n",
      "                mlp_spec=['obs_shape', 256, 256, 1],\n",
      "                inactivated_output=True,\n",
      "                dense_init_cfg=dict(type='xavier_init', gain=1, bias=0))),\n",
      "        optim_cfg=dict(\n",
      "            type='Adam',\n",
      "            lr=0.0001,\n",
      "            param_cfg=dict({'(.*?)visual_nn(.*?)': None})),\n",
      "        clip_constraint=False,\n",
      "        cost_norm_scale=1.0))\n",
      "env_cfg = dict(\n",
      "    type='gym',\n",
      "    env_name='PlaceCubeInBowlXArm-v5',\n",
      "    obs_mode='state',\n",
      "    ignore_dones=True,\n",
      "    horizon=50,\n",
      "    remove_obs_extra=['cube_bbox', 'bowl_bbox'],\n",
      "    control_mode='pd_ee_delta_pos')\n",
      "train_cfg = dict(\n",
      "    on_policy=False,\n",
      "    total_steps=2000000,\n",
      "    warm_steps=4000,\n",
      "    n_log=1000,\n",
      "    n_eval=100000,\n",
      "    n_checkpoint=200000,\n",
      "    n_steps=1,\n",
      "    n_updates=1,\n",
      "    exp_logger_cfg=dict(\n",
      "        type='wandb',\n",
      "        project='constraint-manipulation-debug',\n",
      "        name='SAC-PickCube-0',\n",
      "        key='46ece8f021c1a76ae8e1f46fbd3974b7f85d62bf',\n",
      "        job_type='cost_debug_exp'),\n",
      "    ep_stats_cfg=dict(\n",
      "        info_keys_mode=dict(\n",
      "            rewards=[True, 'sum', 'all'],\n",
      "            max_single_R=[True, 'max', 'all'],\n",
      "            lens=[True, 'sum', 'all'],\n",
      "            success=[True, 'max', 'mean'],\n",
      "            step_times=[True, 'mean', 'mean'],\n",
      "            min_step_times=[False, 'min', 'mean'],\n",
      "            max_step_times=[False, 'max', 'mean'],\n",
      "            cost_tcp_to_obj_dist=[True, 'sum', 'all', 'rate'])))\n",
      "replay_cfg = dict(\n",
      "    type='ReplayMemory',\n",
      "    capacity=1000000,\n",
      "    sampling_cfg=dict(type='OneStepTransition', seed=0))\n",
      "rollout_cfg = dict(\n",
      "    type='Rollout', num_procs=1, with_info=True, multi_thread=False)\n",
      "eval_cfg = dict(\n",
      "    type='Evaluation',\n",
      "    num_procs=1,\n",
      "    num=10,\n",
      "    use_hidden_state=False,\n",
      "    save_traj=True,\n",
      "    save_video=True,\n",
      "    log_video=True,\n",
      "    video_render_mode='rgb_array',\n",
      "    log_every_step=False,\n",
      "    env_cfg=dict(ignore_dones=False),\n",
      "    ep_info_keys=[\n",
      "        'success', 'is_obj_grasped', 'is_obj_placed', 'is_robot_static',\n",
      "        'tcp_to_obj_dist', 'cost_tcp_to_obj_dist', 'is_cube_grasped',\n",
      "        'is_cube_inside', 'is_cube_static', 'is_bowl_static',\n",
      "        'tcp_to_cube_dist', 'cube_to_goal_dist', 'ee_close_to_handle',\n",
      "        'open_enough', 'cabinet_static', 'dist_ee_to_handle',\n",
      "        'cost_dist_ee_to_handle', 'dist_ee_center_to_handle',\n",
      "        'cost_dist_ee_center_to_handle', 'angles_ee_to_grasp_poses',\n",
      "        'cost_angles_ee_to_grasp_poses'\n",
      "    ])\n",
      "work_dir = None\n",
      "resume_from = None\n",
      "expert_replay_cfg = None\n",
      "recent_traj_replay_cfg = None\n",
      "\u001b[0m\n",
      "\u001b[38;21mPlaceCubeInBowlXArm-v5-eval - (3636172862.py:293) - INFO - 2023-05-19,11:18:35 - Set random seed to 1975082078\u001b[0m\n",
      "\u001b[38;21mPlaceCubeInBowlXArm-v5-eval - (3636172862.py:328) - INFO - 2023-05-19,11:18:35 - Build evaluation!\u001b[0m\n",
      "\u001b[38;21mPlaceCubeInBowlXArm-v5-eval - (3636172862.py:337) - INFO - 2023-05-19,11:18:35 - Building evaluation: eval_cfg: {'type': 'Evaluation', 'num_procs': 1, 'num': 10, 'use_hidden_state': False, 'save_traj': True, 'save_video': True, 'log_video': True, 'video_render_mode': 'rgb_array', 'log_every_step': False, 'env_cfg': {'type': 'gym', 'env_name': 'PlaceCubeInBowlXArm-v5', 'obs_mode': 'state', 'ignore_dones': False, 'horizon': 50, 'remove_obs_extra': ['cube_bbox', 'bowl_bbox'], 'control_mode': 'pd_ee_delta_pos'}, 'ep_info_keys': ['success', 'is_obj_grasped', 'is_obj_placed', 'is_robot_static', 'tcp_to_obj_dist', 'cost_tcp_to_obj_dist', 'is_cube_grasped', 'is_cube_inside', 'is_cube_static', 'is_bowl_static', 'tcp_to_cube_dist', 'cube_to_goal_dist', 'ee_close_to_handle', 'open_enough', 'cabinet_static', 'dist_ee_to_handle', 'cost_dist_ee_to_handle', 'dist_ee_center_to_handle', 'cost_dist_ee_center_to_handle', 'angles_ee_to_grasp_poses', 'cost_angles_ee_to_grasp_poses']}\u001b[0m\n",
      "\u001b[38;21mEvaluation-PlaceCubeInBowlXArm-v5-eval - (evaluation.py:108) - INFO - 2023-05-19,11:18:38 - Evaluation environments have seed in [964475117, 964475118)!\u001b[0m\n",
      "\u001b[38;21mPlaceCubeInBowlXArm-v5-eval - (3636172862.py:346) - INFO - 2023-05-19,11:18:38 - Get obs shape!\u001b[0m\n",
      "\u001b[38;21mPlaceCubeInBowlXArm-v5-eval - (3636172862.py:358) - INFO - 2023-05-19,11:18:38 - State shape:64, action shape:4\u001b[0m\n",
      "\u001b[38;21mPlaceCubeInBowlXArm-v5-eval - (3636172862.py:359) - INFO - 2023-05-19,11:18:38 - Environment has the continuous action space with dimension 4.\u001b[0m\n",
      "\u001b[38;21mPlaceCubeInBowlXArm-v5-eval - (3636172862.py:374) - INFO - 2023-05-19,11:18:38 - Final agent config:\n",
      "{'type': 'SAC', 'batch_size': 1024, 'gamma': 0.9, 'update_coeff': 0.005, 'alpha': 0.2, 'target_update_interval': 1, 'automatic_alpha_tuning': True, 'alpha_optim_cfg': {'type': 'Adam', 'lr': 0.0003}, 'actor_cfg': {'type': 'ContinuousActor', 'head_cfg': {'type': 'TanhGaussianHead', 'log_std_bound': [-5, 2], 'log_std_clip_tanh': True}, 'nn_cfg': {'type': 'LinearMLP', 'norm_cfg': None, 'mlp_spec': [64, 256, 256, 256, 8], 'bias': 'auto', 'inactivated_output': True, 'dense_init_cfg': {'type': 'xavier_init', 'gain': 1, 'bias': 0}}, 'optim_cfg': {'type': 'Adam', 'lr': 0.0003}}, 'critic_cfg': {'type': 'ContinuousCritic', 'num_heads': 2, 'nn_cfg': {'type': 'LinearMLP', 'norm_cfg': None, 'bias': 'auto', 'mlp_spec': [68, 256, 256, 256, 1], 'inactivated_output': True, 'dense_init_cfg': {'type': 'xavier_init', 'gain': 1, 'bias': 0}}, 'optim_cfg': {'type': 'Adam', 'lr': 0.0003}}, 'use_rnd': False, 'use_rnd_obs_rms': True, 'use_rew_int_rms': True, 'rew_int_scale': 1.0, 'rnd_obs_slice': {}, 'rnd_critic_cfg': {'type': 'ContinuousValue', 'num_heads': 1, 'nn_cfg': {'type': 'LinearMLP', 'norm_cfg': None, 'bias': 'auto', 'mlp_spec': [64, 256, 256], 'inactivated_output': True, 'dense_init_cfg': {'type': 'xavier_init', 'gain': 1, 'bias': 0}}, 'optim_cfg': {'type': 'Adam', 'lr': 0.0003}}, 'constraint_cfg': {'lam_model': 'Parameter', 'constraint_type': 'single_step', 'constraint_thresholds': [], 'max_ep_len': 50, 'gamma': 0.9, 'constraint_names': [], 'lam_inits': [], 'use_constraint_type': 'discounted_ep', 'auto_tuning': True, 'lam_nn_cfg': {'type': 'ContinuousValue', 'num_heads': 0, 'nn_cfg': {'type': 'LinearMLP', 'norm_cfg': None, 'bias': 'auto', 'mlp_spec': [64, 256, 256, 1], 'inactivated_output': True, 'dense_init_cfg': {'type': 'xavier_init', 'gain': 1, 'bias': 0}}}, 'optim_cfg': {'type': 'Adam', 'lr': 0.0001, 'param_cfg': {'(.*?)visual_nn(.*?)': None}}, 'clip_constraint': False, 'cost_norm_scale': 1.0}, 'env_params': {'obs_shape': 64, 'action_shape': 4, 'action_space': Box([-1. -1. -1. -1.], [1. 1. 1. 1.], (4,), float32), 'is_discrete': False, 'message': 'Environment has the continuous action space with dimension 4.'}}\u001b[0m\n",
      "\u001b[38;21mPlaceCubeInBowlXArm-v5-eval - (collect_env.py:158) - INFO - 2023-05-19,11:18:38 - meta_collect_time: 2023-05-19-11:18:38\u001b[0m\n",
      "\u001b[38;21mPlaceCubeInBowlXArm-v5-eval - (collect_env.py:158) - INFO - 2023-05-19,11:18:38 - pyrl: version: 1.9.0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ENV] No successful grasp pose found!\n",
      "Resume agent with checkpoint!\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "def pyrl_init(args):\n",
    "\n",
    "    # Imports\n",
    "    import argparse\n",
    "    import glob\n",
    "    import os\n",
    "    import os.path as osp\n",
    "    import shutil\n",
    "    import time\n",
    "    import warnings\n",
    "    from copy import deepcopy\n",
    "    from pathlib import Path\n",
    "    import gym\n",
    "    import numpy as np\n",
    "\n",
    "    from pyrl.utils.meta import (\n",
    "        Config,\n",
    "        DictAction,\n",
    "        add_dist_var,\n",
    "        add_env_var,\n",
    "        colored_print,\n",
    "        get_logger,\n",
    "        is_debug_mode,\n",
    "        set_cpu_random_seed,\n",
    "        log_meta_info,\n",
    "        get_total_memory,\n",
    "    )\n",
    "\n",
    "    warnings.simplefilter(action=\"ignore\")\n",
    "\n",
    "    from pyrl.utils.data import is_not_null, is_null\n",
    "\n",
    "    def parse_args(cmd_args=[]):\n",
    "        parser = argparse.ArgumentParser(description=\"Unified API for Training and Evaluation\")\n",
    "        # Configurations\n",
    "        parser.add_argument(\"config\", help=\"Configuration file path\")\n",
    "        parser.add_argument(\n",
    "            \"--cfg-options\",\n",
    "            \"--opt\",\n",
    "            nargs=\"+\",\n",
    "            action=DictAction,\n",
    "            help=\"Override some settings in the configuration file. The key-value pair \"\n",
    "            \"in xxx=yyy format will be merged into config file. If the value to \"\n",
    "            'be overridden is a list, it should be like key=\"[a,b]\" or key=a,b '\n",
    "            'It also allows nested list/tuple values, e.g. key=\"[(a,b),(c,d)]\" '\n",
    "            \"Note that the quotation marks are necessary and that no white space \"\n",
    "            \"is allowed.\",\n",
    "        )\n",
    "        parser.add_argument(\"--debug\", action=\"store_true\", default=False)\n",
    "\n",
    "        # Parameters for log dir\n",
    "        parser.add_argument(\"--work-dir\", help=\"The directory to save logs and models\")\n",
    "        parser.add_argument(\"--dev\", action=\"store_true\", default=False, help=\"Add timestamp to the name of work-dir\")\n",
    "        parser.add_argument(\"--with-agent-type\", default=False, action=\"store_true\", help=\"Add agent type to work-dir\")\n",
    "        parser.add_argument(\n",
    "            \"--agent-type-first\",\n",
    "            default=False,\n",
    "            action=\"store_true\",\n",
    "            help=\"When work-dir is None, we will use agent_type/config_name or config_name/agent_type as work-dir\",\n",
    "        )\n",
    "        parser.add_argument(\"--clean-up\", help=\"Clean up the work-dir\", action=\"store_true\")\n",
    "\n",
    "        # Evaluation mode\n",
    "        parser.add_argument(\"--evaluation\", \"--eval\", help=\"Evaluate a model, instead of training it\", action=\"store_true\")\n",
    "        parser.add_argument(\"--reg-loss\", help=\"Measure regression loss during evaluation\", action=\"store_true\")\n",
    "        parser.add_argument(\"--test-name\", help=\"Subdirectory name under work-dir to save the test result (if None, use {work-dir}/test)\", default=None)\n",
    "\n",
    "        # Resume checkpoint model\n",
    "        parser.add_argument(\"--resume-from\", default=None, nargs=\"+\", help=\"A specific checkpoint file to resume from\")\n",
    "        parser.add_argument(\n",
    "            \"--auto-resume\",\n",
    "            help=\"Auto-resume the checkpoint under work-dir. If --resume-from is not specified, --auto-resume is set to True\",\n",
    "            action=\"store_true\",\n",
    "        )\n",
    "        parser.add_argument(\"--resume-keys-map\", default=None, nargs=\"+\", action=DictAction, help=\"Specify how to change the model keys in checkpoints\")\n",
    "\n",
    "        # Specify GPU\n",
    "        group_gpus = parser.add_mutually_exclusive_group()\n",
    "        group_gpus.add_argument(\"--num-cpus\", default=None, type=int, help=\"Number of gpus to use\")\n",
    "        group_gpus.add_argument(\"--num-gpus\", default=None, type=int, help=\"Number of gpus to use\")\n",
    "        group_gpus.add_argument(\"--gpu-ids\", default=None, type=int, nargs=\"+\", help=\"ids of gpus to use\")\n",
    "        parser.add_argument(\n",
    "            \"--env-gpu-ids\", default=None, type=int, nargs=\"+\", help=\"ids of gpus for environment simulation; if not specified, this equals --gpu-ids\"\n",
    "        )\n",
    "\n",
    "        # Torch and reproducibility settings\n",
    "        parser.add_argument(\"--seed\", type=int, default=None, help=\"Set torch and numpy random seed\")\n",
    "        parser.add_argument(\"--cudnn-benchmark\", action=\"store_true\", help=\"Whether to use benchmark mode in cudnn.\")\n",
    "\n",
    "        parser.add_argument(\"--deterministic\", action=\"store_true\", help=\"Whether to use deterministic mode for torch.\")\n",
    "        parser.add_argument(\n",
    "            \"--reproducible\", action=\"store_true\", help=\"Use deterministic mode also, the program will check the if the code is committed with git!\"\n",
    "        )\n",
    "\n",
    "        # Distributed parameters\n",
    "        # parser.add_argument('--launcher', choices=['none', 'pytorch', 'slurm', 'mpi'], default='none', help='job launcher')\n",
    "        # parser.add_argument('--local-rank', type=int, default=0)\n",
    "        args = parser.parse_args(cmd_args)\n",
    "\n",
    "        # Merge cfg with args.cfg_options\n",
    "        cfg = Config.fromfile(args.config)\n",
    "        if args.cfg_options is not None:\n",
    "            for key, value in args.cfg_options.items():\n",
    "                try:\n",
    "                    value = eval(value)\n",
    "                    args.cfg_options[key] = value\n",
    "                except:\n",
    "                    pass\n",
    "            cfg.merge_from_dict(args.cfg_options)\n",
    "\n",
    "        args.with_agent_type = args.with_agent_type or args.agent_type_first\n",
    "        for key in [\"work_dir\", \"env_cfg\", \"resume_from\", \"eval_cfg\", \"replay_cfg\", \"expert_replay_cfg\", \"recent_traj_replay_cfg\", \"rollout_cfg\"]:\n",
    "            cfg[key] = cfg.get(key, None)\n",
    "        if args.debug:\n",
    "            os.environ[\"PYRL_DEBUG\"] = \"True\"\n",
    "        elif \"PYRL_DEBUG\" not in os.environ:\n",
    "            os.environ[\"PYRL_DEBUG\"] = \"False\"\n",
    "        if args.seed is None:\n",
    "            args.seed = np.random.randint(2**32 - int(1e8))\n",
    "            args.deterministic = args.deterministic\n",
    "        else:\n",
    "            args.deterministic = True\n",
    "\n",
    "        if args.reproducible:\n",
    "            args.deterministic = True\n",
    "\n",
    "        if args.evaluation:\n",
    "            from pyrl.methods.builder import SL\n",
    "\n",
    "            args.reg_loss = args.reg_loss or cfg.agent_cfg.type in SL\n",
    "        args.mode = \"eval\" if args.evaluation else \"train\"\n",
    "\n",
    "        if args.num_cpus:\n",
    "            pass\n",
    "        return args, cfg\n",
    "\n",
    "    def get_python_env_info():\n",
    "        if is_not_null(args.num_gpus) and is_not_null(args.gpu_ids):\n",
    "            colored_print(\"Please use either 'num-gpus' or 'gpu-ids'!\", level=\"error\")\n",
    "            exit(0)\n",
    "\n",
    "        if is_not_null(args.num_gpus):\n",
    "            args.gpu_ids = list(range(args.num_gpus))\n",
    "            args.num_gpus = None\n",
    "        if args.gpu_ids is None:\n",
    "            args.gpu_ids = []\n",
    "\n",
    "        if args.evaluation and len(args.gpu_ids) > 1:\n",
    "            colored_print(f\"Multiple GPU evaluation is not supported; we will use the first GPU to do evaluation!\", level=\"warning\")\n",
    "            args.gpu_ids = args.gpu_ids[:1]\n",
    "\n",
    "    def build_work_dir():\n",
    "        if is_null(args.work_dir):\n",
    "            root_dir = \"./work_dirs\"\n",
    "            env_name = cfg.env_cfg.get(\"env_name\", None) if is_not_null(cfg.env_cfg) else None\n",
    "            config_name = osp.splitext(osp.basename(args.config))[0]\n",
    "            folder_name = env_name if is_not_null(env_name) else config_name\n",
    "            if args.with_agent_type:\n",
    "                if args.agent_type_first:\n",
    "                    args.work_dir = osp.join(root_dir, agent_type, folder_name)\n",
    "                else:\n",
    "                    args.work_dir = osp.join(root_dir, folder_name, agent_type)\n",
    "            else:\n",
    "                args.work_dir = osp.join(root_dir, folder_name)\n",
    "        elif args.with_agent_type:\n",
    "            if args.agent_type_first:\n",
    "                colored_print(\"When you specify the work dir path, the agent type cannot be at the beginning of the path!\", level=\"warning\")\n",
    "            args.work_dir = osp.join(args.work_dir, agent_type)\n",
    "\n",
    "        if args.dev:\n",
    "            splits = list(osp.split(args.work_dir))\n",
    "            splits[1] += \"-dev\"\n",
    "            args.work_dir = osp.join(*splits)\n",
    "            args.work_dir = osp.join(args.work_dir, args.timestamp)\n",
    "\n",
    "        if args.clean_up:\n",
    "            if args.evaluation or args.auto_resume or (is_not_null(args.resume_from) and os.path.commonprefix(args.resume_from) == args.work_dir):\n",
    "                colored_print(\n",
    "                    \"We will ignore the clean-up flag, since we are either in the evaluation mode or resuming from the directory!\", level=\"warning\"\n",
    "                )\n",
    "            else:\n",
    "                shutil.rmtree(args.work_dir, ignore_errors=True)\n",
    "        os.makedirs(osp.abspath(args.work_dir), exist_ok=True)\n",
    "        \n",
    "    def find_checkpoint():\n",
    "        logger = get_logger()\n",
    "        if is_not_null(args.resume_from):\n",
    "            if is_not_null(cfg.resume_from):\n",
    "                colored_print(f\"The resumed checkpoint from the config file is overwritten by {args.resume_from}!\", level=\"warning\")\n",
    "            cfg.resume_from = args.resume_from\n",
    "\n",
    "        if args.auto_resume or (args.evaluation and is_null(cfg.resume_from)):\n",
    "            logger.info(f\"Search model under {args.work_dir}.\")\n",
    "            model_names = list(glob.glob(osp.join(args.work_dir, \"models\", \"*.ckpt\")))\n",
    "            latest_index = -1\n",
    "            latest_name = None\n",
    "            for model_i in model_names:\n",
    "                index_str = osp.basename(model_i).split(\".\")[0].split(\"_\")[1]\n",
    "                if index_str == \"final\":\n",
    "                    continue\n",
    "                index = eval(index_str)\n",
    "                if index > latest_index:\n",
    "                    latest_index = index\n",
    "                    latest_name = model_i\n",
    "\n",
    "            if is_null(latest_name):\n",
    "                colored_print(f\"Find no checkpoints under {args.work_dir}!\", level=\"warning\")\n",
    "            else:\n",
    "                cfg.resume_from = latest_name\n",
    "                cfg.train_cfg[\"resume_steps\"] = latest_index\n",
    "        if is_not_null(cfg.resume_from):\n",
    "            if isinstance(cfg.resume_from, str):\n",
    "                cfg.resume_from = [\n",
    "                    cfg.resume_from,\n",
    "                ]\n",
    "            logger.info(f\"Get {len(cfg.resume_from)} checkpoint {cfg.resume_from}.\")\n",
    "            logger.info(f\"Check checkpoint {cfg.resume_from}!\")\n",
    "\n",
    "            for file in cfg.resume_from:\n",
    "                if not (osp.exists(file) and osp.isfile(file)):\n",
    "                    logger.error(f\"Checkpoint file {file} does not exist!\")\n",
    "                    exit(-1)\n",
    "                    \n",
    "    # Remove mujoco_py lock\n",
    "    mjpy_lock = Path(gym.__file__).parent.parent / \"mujoco_py/generated/mujocopy-buildlock.lock\"\n",
    "    if mjpy_lock.exists():\n",
    "        os.remove(str(mjpy_lock))\n",
    "\n",
    "    add_env_var()\n",
    "\n",
    "    args, cfg = parse_args(args)\n",
    "    args.timestamp = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "    agent_type = cfg.agent_cfg.type\n",
    "\n",
    "    if args.reproducible:\n",
    "        from pyrl.utils.meta import check_reproducibility\n",
    "\n",
    "        check_reproducibility()\n",
    "\n",
    "    get_python_env_info()\n",
    "\n",
    "    build_work_dir()\n",
    "    find_checkpoint()\n",
    "\n",
    "    work_dir = args.work_dir\n",
    "    if args.evaluation:\n",
    "        test_name = args.test_name if args.test_name is not None else \"test\"\n",
    "        work_dir = osp.join(work_dir, test_name)\n",
    "        # Always clean up for evaluation\n",
    "        shutil.rmtree(work_dir, ignore_errors=True)\n",
    "        os.makedirs(work_dir, exist_ok=True)\n",
    "    args.work_dir = work_dir\n",
    "\n",
    "    logger_name = cfg.env_cfg.env_name if is_not_null(cfg.env_cfg) else cfg.agent_cfg.type\n",
    "    args.name_suffix = f\"{args.mode}\"\n",
    "    if args.test_name is not None:\n",
    "        args.name_suffix += f\"-{args.test_name}\"\n",
    "    os.environ[\"PYRL_LOGGER_NAME\"] = f\"{logger_name}-{args.name_suffix}\"\n",
    "    cfg.dump(osp.join(work_dir, f\"{args.timestamp}-{args.name_suffix}.py\"))\n",
    "\n",
    "    import numpy as np\n",
    "    rank, world_size = 0, 1\n",
    "\n",
    "    args.seed += rank\n",
    "\n",
    "    add_dist_var(rank, world_size)\n",
    "    set_cpu_random_seed(args.seed)\n",
    "    np.set_printoptions(precision=5, suppress=True)\n",
    "\n",
    "    if is_not_null(cfg.env_cfg) and len(args.gpu_ids) > 0:\n",
    "        if args.env_gpu_ids is not None:\n",
    "            assert len(args.env_gpu_ids) == len(args.gpu_ids), \"Number of simulation gpus should be the same as the number of training gpus!\"\n",
    "        else:\n",
    "            args.env_gpu_ids = args.gpu_ids\n",
    "        cfg.env_cfg.device = f\"cuda:{args.env_gpu_ids[rank]}\"\n",
    "\n",
    "    work_dir = args.work_dir\n",
    "    logger_file = osp.join(work_dir, f\"{args.timestamp}-{args.name_suffix}.log\")\n",
    "    logger = get_logger(name=None, log_file=logger_file, log_level=cfg.get(\"log_level\", \"INFO\"))\n",
    "\n",
    "    if is_debug_mode():\n",
    "        dash_line = \"-\" * 60 + \"\\n\"\n",
    "        logger.info(\"Environment info:\\n\" + dash_line + args.env_info + \"\\n\" + dash_line)\n",
    "\n",
    "    if args.cfg_options is not None:\n",
    "        logger.info(f\"Extra arguments that replace the default setting from the config file.\")\n",
    "        for key, value in args.cfg_options.items():\n",
    "            logger.info(f\"{key} {value}\")\n",
    "\n",
    "    logger.info(f\"Config:\\n{cfg.pretty_text}\")\n",
    "    logger.info(f\"Set random seed to {args.seed}\")\n",
    "\n",
    "    # Create replay buffer for RL\n",
    "    if is_not_null(cfg.replay_cfg) and (not args.evaluation or (args.reg_loss and cfg.replay_cfg.get(\"buffer_filenames\", None) is not None)):\n",
    "        logger.info(f\"Build replay buffer!\")\n",
    "        from pyrl.env import build_replay\n",
    "\n",
    "        replay = build_replay(cfg.replay_cfg)\n",
    "        expert_replay, recent_traj_replay = None, None\n",
    "        if is_not_null(cfg.expert_replay_cfg):\n",
    "            assert cfg.expert_replay_cfg.buffer_filenames is not None\n",
    "            expert_replay = build_replay(cfg.expert_replay_cfg)\n",
    "        if is_not_null(cfg.recent_traj_replay_cfg):\n",
    "            recent_traj_replay = build_replay(cfg.recent_traj_replay_cfg)\n",
    "    else:\n",
    "        replay = None\n",
    "        expert_replay = None\n",
    "        recent_traj_replay = None\n",
    "\n",
    "    # Create rollout module for online methods\n",
    "    if not args.evaluation and is_not_null(cfg.rollout_cfg):\n",
    "        from pyrl.env import build_rollout\n",
    "\n",
    "        logger.info(f\"Build rollout! Total memory before build rollout: {get_total_memory()}!\")\n",
    "        rollout_cfg = cfg.rollout_cfg\n",
    "        rollout_cfg[\"env_cfg\"] = deepcopy(cfg.env_cfg)\n",
    "        rollout = build_rollout(rollout_cfg)\n",
    "    else:\n",
    "        rollout = None\n",
    "\n",
    "    # Build evaluation module\n",
    "    if is_not_null(cfg.eval_cfg) and rank == 0:\n",
    "        # Only the first process will do evaluation\n",
    "        from pyrl.env import build_evaluation\n",
    "\n",
    "        logger.info(f\"Build evaluation!\")\n",
    "        eval_cfg = cfg.eval_cfg\n",
    "        # Evaluation environment setup can be different from the training setup. (Like early-stop or object sets)\n",
    "        if eval_cfg.get(\"env_cfg\", None) is None:\n",
    "            eval_cfg[\"env_cfg\"] = deepcopy(cfg.env_cfg)\n",
    "        else:\n",
    "            tmp = eval_cfg[\"env_cfg\"]\n",
    "            eval_cfg[\"env_cfg\"] = deepcopy(cfg.env_cfg)\n",
    "            eval_cfg[\"env_cfg\"].update(tmp)\n",
    "        get_logger().info(f\"Building evaluation: eval_cfg: {eval_cfg}\")\n",
    "        evaluator = build_evaluation(eval_cfg)\n",
    "    else:\n",
    "        evaluator = None\n",
    "\n",
    "    # Get environments information for agents\n",
    "    obs_shape, action_shape = None, None\n",
    "    if is_not_null(cfg.env_cfg):\n",
    "        # For RL which needs environments\n",
    "        logger.info(f\"Get obs shape!\")\n",
    "        from pyrl.env import get_env_info\n",
    "\n",
    "        if rollout is not None:\n",
    "            env_params = get_env_info(cfg.env_cfg, rollout.vec_env)\n",
    "        elif hasattr(evaluator, \"vec_env\"):\n",
    "            env_params = get_env_info(cfg.env_cfg, evaluator.vec_env)\n",
    "        else:\n",
    "            env_params = get_env_info(cfg.env_cfg)\n",
    "        cfg.agent_cfg[\"env_params\"] = env_params\n",
    "        obs_shape = env_params[\"obs_shape\"]\n",
    "        action_shape = env_params[\"action_shape\"]\n",
    "        logger.info(f'State shape:{env_params[\"obs_shape\"]}, action shape:{env_params[\"action_shape\"]}')\n",
    "        logger.info(env_params[\"message\"])\n",
    "    elif is_not_null(replay):\n",
    "        obs_shape = None\n",
    "        for obs_key in [\"inputs\", \"obs\"]:\n",
    "            if obs_key in replay.memory:\n",
    "                obs_shape = replay.memory.slice(0).shape[obs_key]\n",
    "                break\n",
    "\n",
    "    if is_not_null(obs_shape) or is_not_null(action_shape):\n",
    "        from pyrl.networks.utils import get_kwargs_from_shape, replace_placeholder_with_args\n",
    "\n",
    "        replaceable_kwargs = get_kwargs_from_shape(obs_shape, action_shape)\n",
    "        cfg = replace_placeholder_with_args(cfg, **replaceable_kwargs)\n",
    "    from pyrl.methods.mfrl.constraint import get_kwargs_for_constraint\n",
    "    cfg = replace_placeholder_with_args(cfg, **get_kwargs_for_constraint(cfg))\n",
    "    logger.info(f\"Final agent config:\\n{cfg.agent_cfg}\")\n",
    "\n",
    "    # Output version of important packages\n",
    "    log_meta_info(logger)\n",
    "\n",
    "    from pyrl.methods.builder import MPC\n",
    "\n",
    "    # if cfg.agent_cfg.type in MPC:\n",
    "    #     main_mpc(rollout, evaluator, cfg)\n",
    "    # else:\n",
    "    #     main_rl(rollout, evaluator, replay, args, cfg, expert_replay=expert_replay, recent_traj_replay=recent_traj_replay)\n",
    "\n",
    "    # if rank == 0:\n",
    "    #     env_info_dict = collect_env()\n",
    "    #     args.env_info = \"\\n\".join([f\"{k}: {v}\" for k, v in env_info_dict.items()])\n",
    "\n",
    "    # if is_not_null(evaluator):\n",
    "    #     evaluator.close()\n",
    "    #     logger.info(\"Close evaluator object\")\n",
    "    # if is_not_null(rollout):\n",
    "    #     rollout.close()\n",
    "    #     logger.info(\"Close rollout object\")\n",
    "    # if is_not_null(replay):\n",
    "    #     replay.close()\n",
    "    #     logger.info(\"Delete replay buffer\")\n",
    "\n",
    "    from pyrl.methods.builder import build_agent\n",
    "    agent = build_agent(cfg.agent_cfg)\n",
    "    agent = agent.to(\"cuda\")\n",
    "    return agent, rollout, evaluator, replay\n",
    "\n",
    "agent, rollout, evaluator, replay = pyrl_init(args)\n",
    "# trajectories = rollout.forward_with_policy(None, 5000, replay=replay)\n",
    "# memory = replay\n",
    "# self = agent\n",
    "\n",
    "# sampled_batch = memory.sample(self.batch_size).to_torch(\n",
    "#     device=self.device, non_blocking=True\n",
    "# )\n",
    "# sampled_batch = self.process_obs(sampled_batch)\n",
    "\n",
    "# prev_actions = sampled_batch[\"prev_actions\"]\n",
    "# obs, actions = sampled_batch[\"obs\"], sampled_batch[\"actions\"]\n",
    "# rewards, dones = sampled_batch[\"rewards\"], sampled_batch[\"dones\"].float()\n",
    "# next_obs, infos = sampled_batch[\"next_obs\"], sampled_batch[\"infos\"]\n",
    "\n",
    "#ret = rollout.vec_env.step_random_actions(10)\n",
    "#ret\n",
    "\n",
    "#trajectories = rollout.forward_with_policy(None, 50, replay=replay)\n",
    "\n",
    "from pyrl.utils.torch import BaseAgent, load_checkpoint\n",
    "print(\"Resume agent with checkpoint!\")\n",
    "load_checkpoint(agent, model_ckpt, \"cuda\")\n",
    "\n",
    "agent = agent.eval()\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight'])\n",
      "\n",
      "Loading GroundingDINO: Took 2.906 seconds\n",
      "\n",
      "Loading SAM: Took 4.199 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;21mRealSenseAPI - (realsense.py:161) - INFO - 2023-05-19 11:18 - Found Intel RealSense D435 (S/N: 146322072630 FW: 05.12.09.00 on USB 3.2)\u001b[0m\n",
      "\u001b[38;21mRSDevice - (realsense.py:88) - INFO - 2023-05-19 11:18 - Loaded \"High Accuracy\" preset for <RSDevice: Intel RealSense D435 (S/N: 146322072630)>\u001b[0m\n",
      "\u001b[38;21mRSDevice - (realsense.py:37) - INFO - 2023-05-19 11:18 - Setting Depth \"option.exposure\" to 1500\u001b[0m\n",
      "\u001b[38;21mRealSenseAPI - (realsense.py:167) - INFO - 2023-05-19 11:18 - Loading finished: found 1 devices\u001b[0m\n",
      "\u001b[38;21mRSDevice - (realsense.py:100) - INFO - 2023-05-19 11:18 - Started device <RSDevice: Intel RealSense D435 (S/N: 146322072630)> with 2 streams\u001b[0m\n",
      "\u001b[38;21mRSDevice - (realsense.py:102) - INFO - 2023-05-19 11:18 - <pyrealsense2.[video_]stream_profile: Depth(0) 848x480 @ 30fps Z16>\u001b[0m\n",
      "\u001b[38;21mRSDevice - (realsense.py:102) - INFO - 2023-05-19 11:18 - <pyrealsense2.[video_]stream_profile: Color(0) 848x480 @ 30fps RGB8>\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(480, 848, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from grounded_sam_track import GroundedSAMTrack\n",
    "grounded_sam_track = GroundedSAMTrack(\n",
    "    aot_max_len_long_term=2,\n",
    "    predict_gap=9999,\n",
    "    prompt_with_robot_arm=True,\n",
    "    device=\"cuda:1\",\n",
    ")\n",
    "env_object_texts = [\"red cube\", \"green bowl\"]\n",
    "\n",
    "import pyrealsense2 as rs\n",
    "from real_robot.utils.realsense import RealSenseAPI\n",
    "from real_robot.utils.camera import depth2xyz, transform_points\n",
    "\n",
    "camera_pose = np.load(\"/rl_benchmark/real_robot/notebooks/Tb_b2c.npy\")\n",
    "\n",
    "realsense = RealSenseAPI(preset=\"High Accuracy\",\n",
    "                         depth_option_kwargs={\n",
    "                             rs.option.exposure: 1500\n",
    "                         })\n",
    "color_image, depth_image, intr_array = realsense.capture()\n",
    "\n",
    "xyz_image = depth2xyz(depth_image, *intr_array)\n",
    "world_xyz_image = transform_points(xyz_image, camera_pose)\n",
    "\n",
    "world_xyz_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK_VERSION: 1.11.6\n",
      "ROBOT_IP: 192.168.1.209, VERSION: v1.12.0, PROTOCOL: V1, DETAIL: 7,7,XS1203,XX0000,v1.12.0, TYPE1300: [0, 0]\n",
      "change prot_flag to 3\n",
      "************* GetErrorWarnCode, Status: 0 **************\n",
      "* ErrorCode: 0, Info: Normal\n",
      "* WarnCode: 0, Info: Normal\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 11:18:56.508943: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qpos: [ 0.     0.     0.     1.047  0.     1.047 -1.571  0.001  0.001]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.464 -0.     0.187 -0.    -0.707 -0.707 -0.   ]\n",
      "goal_pos: [ 0.566 -0.21   0.083]\n",
      "tcp_to_goal_pos: [ 0.102 -0.21  -0.104]\n",
      "cube_pose: [ 0.344 -0.264  0.024  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.12  -0.264 -0.163]\n",
      "cube_to_goal_pos: [0.222 0.055 0.059]\n",
      "bowl_pose: [ 0.566 -0.21   0.033  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.102 -0.21  -0.154]\n",
      "cube_to_bowl_pos: [0.222 0.055 0.009]\n",
      "\n",
      "action: [-0.99  -0.996 -0.187  0.142]\n",
      "Stepping action ...\n",
      "delta xyz [-49.51439 -49.79398  -9.35998] gripper_action 358.9745408296585\n",
      "qpos: [-0.041 -0.164 -0.074  0.898 -0.014  1.061 -1.679  0.025  0.025]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.414 -0.05   0.196  0.    -0.707 -0.707  0.   ]\n",
      "goal_pos: [ 0.564 -0.211  0.079]\n",
      "tcp_to_goal_pos: [ 0.149 -0.162 -0.117]\n",
      "cube_pose: [ 0.343 -0.264  0.023  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.071 -0.215 -0.173]\n",
      "cube_to_goal_pos: [0.22  0.053 0.056]\n",
      "bowl_pose: [ 0.564 -0.211  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.149 -0.162 -0.167]\n",
      "cube_to_bowl_pos: [0.22  0.053 0.006]\n",
      "\n",
      "action: [-0.908 -0.995  0.653  0.569]\n",
      "Stepping action ...\n",
      "delta xyz [-45.38443 -49.7696   32.66626] gripper_action 175.4963105916977\n",
      "qpos: [-0.069 -0.267 -0.178  0.704 -0.057  0.967 -1.779  0.035  0.035]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.364 -0.095  0.164  0.    -0.707 -0.707  0.   ]\n",
      "goal_pos: [ 0.56  -0.207  0.078]\n",
      "tcp_to_goal_pos: [ 0.196 -0.112 -0.086]\n",
      "cube_pose: [ 0.343 -0.263  0.024  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.021 -0.168 -0.14 ]\n",
      "cube_to_goal_pos: [0.217 0.056 0.054]\n",
      "bowl_pose: [ 0.56  -0.207  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.196 -0.112 -0.136]\n",
      "cube_to_bowl_pos: [0.217 0.056 0.004]\n",
      "\n",
      "action: [ 0.017 -0.59   0.918  0.931]\n",
      "Stepping action ...\n",
      "delta xyz [  0.87323 -29.5103   45.87502] gripper_action 19.73548710346222\n",
      "qpos: [-0.056 -0.292 -0.218  0.538 -0.085  0.825 -1.778  0.043  0.043]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.335 -0.094  0.118  0.    -0.707 -0.707  0.   ]\n",
      "goal_pos: [ 0.565 -0.21   0.079]\n",
      "tcp_to_goal_pos: [ 0.231 -0.116 -0.039]\n",
      "cube_pose: [ 0.345 -0.26   0.023  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.011 -0.166 -0.095]\n",
      "cube_to_goal_pos: [0.22  0.05  0.056]\n",
      "bowl_pose: [ 0.565 -0.21   0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.231 -0.116 -0.089]\n",
      "cube_to_bowl_pos: [0.22  0.05  0.006]\n",
      "\n",
      "action: [-0.808  0.262  0.815 -0.022]\n",
      "Stepping action ...\n",
      "delta xyz [-40.38532  13.10718  40.73498] gripper_action 429.3537243641913\n",
      "qpos: [-0.065 -0.11  -0.307  0.574 -0.053  0.68  -1.9    0.022  0.022]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.348 -0.134  0.077  0.    -0.707 -0.707  0.   ]\n",
      "goal_pos: [ 0.563 -0.206  0.079]\n",
      "tcp_to_goal_pos: [ 0.215 -0.072  0.002]\n",
      "cube_pose: [ 0.345 -0.264  0.024  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.003 -0.13  -0.053]\n",
      "cube_to_goal_pos: [0.217 0.058 0.056]\n",
      "bowl_pose: [ 0.563 -0.206  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.215 -0.072 -0.048]\n",
      "cube_to_bowl_pos: [0.217 0.058 0.006]\n",
      "\n",
      "action: [-0.987 -0.076  0.261 -0.694]\n",
      "Stepping action ...\n",
      "delta xyz [-49.3275   -3.82475  13.04594] gripper_action 718.282881975174\n",
      "qpos: [-0.123 -0.02  -0.368  0.623 -0.012  0.642 -2.052  0.007  0.007]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.344 -0.184  0.064  0.    -0.707 -0.707  0.   ]\n",
      "goal_pos: [ 0.566 -0.21   0.078]\n",
      "tcp_to_goal_pos: [ 0.222 -0.026  0.014]\n",
      "cube_pose: [ 0.345 -0.265  0.023  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.001 -0.081 -0.041]\n",
      "cube_to_goal_pos: [0.22  0.055 0.055]\n",
      "bowl_pose: [ 0.566 -0.21   0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.222 -0.026 -0.036]\n",
      "cube_to_bowl_pos: [0.22  0.055 0.005]\n",
      "\n",
      "action: [-0.862  0.188  0.997 -0.002]\n",
      "Stepping action ...\n",
      "delta xyz [-43.10819   9.41213  49.87358] gripper_action 420.99434597883373\n",
      "qpos: [-0.244  0.209 -0.315  0.71   0.131  0.515 -2.237  0.022  0.022]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.353 -0.227  0.014 -0.     0.707  0.707 -0.   ]\n",
      "goal_pos: [ 0.561 -0.208  0.077]\n",
      "tcp_to_goal_pos: [0.208 0.018 0.063]\n",
      "cube_pose: [ 0.345 -0.259  0.025  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.008 -0.033  0.011]\n",
      "cube_to_goal_pos: [0.216 0.051 0.052]\n",
      "bowl_pose: [ 0.561 -0.208  0.027  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [0.208 0.018 0.013]\n",
      "cube_to_bowl_pos: [0.216 0.051 0.002]\n",
      "\n",
      "action: [-0.949  0.175 -0.942  0.929]\n",
      "Stepping action ...\n",
      "delta xyz [-47.4261    8.76621 -47.11249] gripper_action 20.32405436038971\n",
      "qpos: [-0.358  0.18  -0.291  0.857  0.081  0.686 -2.278  0.043  0.043]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.362 -0.274  0.061 -0.     0.707  0.707 -0.   ]\n",
      "goal_pos: [ 0.565 -0.211  0.078]\n",
      "tcp_to_goal_pos: [0.203 0.063 0.017]\n",
      "cube_pose: [ 0.348 -0.293  0.027  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.014 -0.019 -0.034]\n",
      "cube_to_goal_pos: [0.217 0.082 0.051]\n",
      "bowl_pose: [ 0.565 -0.211  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.203  0.063 -0.033]\n",
      "cube_to_bowl_pos: [0.217 0.082 0.001]\n",
      "\n",
      "action: [-0.376 -0.589  0.76   0.485]\n",
      "Stepping action ...\n",
      "delta xyz [-18.79486 -29.46829  37.97567] gripper_action 211.39383852481842\n",
      "[SDK][ERROR][2023-05-19 11:20:19][base.py:348] - - wait_move, xarm is stop, state=5\n",
      "qpos: [-0.439  0.217 -0.266  0.813  0.11   0.585 -2.359  0.033  0.033]\n",
      "qvel: [-0.027 -0.288  0.01  -0.007  0.009 -0.034 -0.026  0.     0.   ]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.343 -0.294  0.037  0.01   0.708  0.706  0.003]\n",
      "goal_pos: [ 0.56  -0.206  0.079]\n",
      "tcp_to_goal_pos: [0.217 0.087 0.042]\n",
      "cube_pose: [ 0.35  -0.301  0.031  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.007 -0.008 -0.007]\n",
      "cube_to_goal_pos: [0.21  0.095 0.049]\n",
      "bowl_pose: [ 0.56  -0.206  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.217  0.087 -0.008]\n",
      "cube_to_bowl_pos: [ 0.21   0.095 -0.001]\n",
      "\n",
      "action: [ 0.715  1.    -0.995  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [ 35.75986  49.99811 -49.76876] gripper_action -10.0\n",
      "ControllerError, code: 31\n",
      "[SDK][ERROR][2023-05-19 11:20:23][base.py:348] - - API -> set_tool_position -> code=1, pos=[35.75986, 49.99811, -49.768764, 0.0, 0.0, 0.0], velo=100.0, acc=2000\n",
      "qpos: [-0.443  0.177 -0.265  0.812  0.111  0.581 -2.362  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.351 -0.299  0.055  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.566 -0.21   0.079]\n",
      "tcp_to_goal_pos: [0.215 0.089 0.024]\n",
      "cube_pose: [ 0.349 -0.299  0.038  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.002 -0.    -0.017]\n",
      "cube_to_goal_pos: [0.216 0.089 0.04 ]\n",
      "bowl_pose: [ 0.566 -0.21   0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.215  0.089 -0.026]\n",
      "cube_to_bowl_pos: [ 0.216  0.089 -0.01 ]\n",
      "\n",
      "action: [ 0.275  0.965 -0.917  1.   ]\n",
      "************* GetErrorWarnCode, Status: 0 **************\n",
      "* ErrorCode: 31, Info: Collision Caused Abnormal Current\n",
      "* WarnCode: 0, Info: Normal\n",
      "**************************************************\n",
      "[SDK][ERROR][2023-05-19 11:20:24][base.py:348] - - API -> clean_warn -> code=1\n",
      "[motion_enable], xArm is not ready to move\n",
      "[set_state], xArm is ready to move\n",
      "ControllerError had clean\n",
      "Stepping action ...\n",
      "delta xyz [ 13.75853  48.24827 -45.84863] gripper_action -9.994617700576782\n",
      "qpos: [-0.418  0.15  -0.21   0.948  0.061  0.738 -2.237  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.397 -0.284  0.103  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.564 -0.205  0.079]\n",
      "tcp_to_goal_pos: [ 0.168  0.078 -0.024]\n",
      "cube_pose: [ 0.347 -0.292  0.024  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.049 -0.008 -0.079]\n",
      "cube_to_goal_pos: [0.217 0.086 0.055]\n",
      "bowl_pose: [ 0.564 -0.205  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.168  0.078 -0.074]\n",
      "cube_to_bowl_pos: [0.217 0.086 0.005]\n",
      "\n",
      "action: [-0.526 -0.959  0.864 -0.866]\n",
      "Stepping action ...\n",
      "delta xyz [-26.30486 -47.97272  43.17997] gripper_action 792.4471235275269\n",
      "qpos: [-0.518  0.19  -0.212  0.845  0.099  0.598 -2.374  0.003  0.003]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.351 -0.311  0.058  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.565 -0.209  0.078]\n",
      "tcp_to_goal_pos: [0.214 0.102 0.02 ]\n",
      "cube_pose: [ 0.349 -0.296  0.026  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.002  0.016 -0.032]\n",
      "cube_to_goal_pos: [0.216 0.086 0.052]\n",
      "bowl_pose: [ 0.565 -0.209  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.214  0.102 -0.03 ]\n",
      "cube_to_bowl_pos: [0.216 0.086 0.002]\n",
      "\n",
      "action: [-0.276 -0.282  0.975  0.972]\n",
      "Stepping action ...\n",
      "delta xyz [-13.80474 -14.1073   48.76129] gripper_action 2.12014377117157\n",
      "qpos: [-0.613  0.315 -0.15   0.839  0.143  0.469 -2.449  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.34  -0.326  0.009  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.561 -0.208  0.078]\n",
      "tcp_to_goal_pos: [0.221 0.118 0.069]\n",
      "cube_pose: [ 0.362 -0.303  0.024  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [0.022 0.023 0.016]\n",
      "cube_to_goal_pos: [0.199 0.095 0.054]\n",
      "bowl_pose: [ 0.561 -0.208  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [0.221 0.118 0.019]\n",
      "cube_to_bowl_pos: [0.199 0.095 0.004]\n",
      "\n",
      "action: [ 0.962  0.996 -0.997  0.999]\n",
      "Stepping action ...\n",
      "delta xyz [ 48.07561  49.79867 -49.85569] gripper_action -9.728219509124756\n",
      "qpos: [-0.538  0.199 -0.086  0.869  0.047  0.607 -2.229  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.387 -0.277  0.06   0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.564 -0.207  0.078]\n",
      "tcp_to_goal_pos: [0.177 0.07  0.018]\n",
      "cube_pose: [ 0.343 -0.26   0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.044  0.017 -0.03 ]\n",
      "cube_to_goal_pos: [0.22  0.053 0.048]\n",
      "bowl_pose: [ 0.564 -0.207  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.177  0.07  -0.032]\n",
      "cube_to_bowl_pos: [ 0.22   0.053 -0.002]\n",
      "\n",
      "action: [-0.186 -0.9    0.454  0.964]\n",
      "Stepping action ...\n",
      "delta xyz [ -9.27692 -44.97575  22.70695] gripper_action 5.366721153259277\n",
      "qpos: [-0.601  0.183 -0.096  0.751  0.066  0.506 -2.321  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.343 -0.287  0.035  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.562 -0.207  0.079]\n",
      "tcp_to_goal_pos: [0.219 0.08  0.044]\n",
      "cube_pose: [ 0.359 -0.247  0.014  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.016  0.04  -0.021]\n",
      "cube_to_goal_pos: [0.203 0.04  0.064]\n",
      "bowl_pose: [ 0.562 -0.207  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.219  0.08  -0.006]\n",
      "cube_to_bowl_pos: [0.203 0.04  0.014]\n",
      "\n",
      "action: [ 0.367 -0.712 -0.955  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [ 18.33105 -35.58424 -47.72806] gripper_action -9.986851811408997\n",
      "qpos: [-0.585 -0.051 -0.141  0.627  0.016  0.614 -2.308  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.305 -0.267  0.08   0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.561 -0.208  0.078]\n",
      "tcp_to_goal_pos: [ 0.256  0.059 -0.002]\n",
      "cube_pose: [ 0.344 -0.248  0.024  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.039  0.019 -0.056]\n",
      "cube_to_goal_pos: [0.217 0.04  0.054]\n",
      "bowl_pose: [ 0.561 -0.208  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.256  0.059 -0.052]\n",
      "cube_to_bowl_pos: [0.217 0.04  0.004]\n",
      "\n",
      "action: [-0.536  0.803  0.928  0.525]\n",
      "Stepping action ...\n",
      "delta xyz [-26.80559  40.15839  46.41669] gripper_action 194.16473925113678\n",
      "qpos: [-0.567  0.203 -0.139  0.785  0.085  0.522 -2.343  0.034  0.034]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.348 -0.295  0.037  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.56  -0.208  0.079]\n",
      "tcp_to_goal_pos: [0.213 0.087 0.042]\n",
      "cube_pose: [ 0.354 -0.298  0.069  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.006 -0.003  0.032]\n",
      "cube_to_goal_pos: [0.207 0.09  0.01 ]\n",
      "bowl_pose: [ 0.56  -0.208  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.213  0.087 -0.008]\n",
      "cube_to_bowl_pos: [ 0.207  0.09  -0.04 ]\n",
      "\n",
      "action: [ 0.998  1.    -0.911  0.99 ]\n",
      "Stepping action ...\n",
      "delta xyz [ 49.89594  49.97546 -45.56224] gripper_action -5.536792278289795\n",
      "qpos: [-0.472  0.116 -0.084  0.841  0.024  0.661 -2.142  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.395 -0.244  0.084  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.561 -0.209  0.081]\n",
      "tcp_to_goal_pos: [ 0.166  0.035 -0.003]\n",
      "cube_pose: [ 0.344 -0.246  0.022  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.052 -0.002 -0.061]\n",
      "cube_to_goal_pos: [0.218 0.037 0.058]\n",
      "bowl_pose: [ 0.561 -0.209  0.031  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.166  0.035 -0.053]\n",
      "cube_to_bowl_pos: [0.218 0.037 0.008]\n",
      "\n",
      "action: [-0.32  -0.926  0.806  0.692]\n",
      "Stepping action ...\n",
      "delta xyz [-15.98641 -46.29959  40.2849 ] gripper_action 122.23966240882874\n",
      "qpos: [-0.525  0.141 -0.115  0.717  0.055  0.513 -2.255  0.038  0.038]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.351 -0.261  0.041  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.563 -0.211  0.078]\n",
      "tcp_to_goal_pos: [0.212 0.05  0.037]\n",
      "cube_pose: [ 0.348 -0.257  0.032  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.004  0.004 -0.009]\n",
      "cube_to_goal_pos: [0.216 0.046 0.046]\n",
      "bowl_pose: [ 0.563 -0.211  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.212  0.05  -0.013]\n",
      "cube_to_bowl_pos: [ 0.216  0.046 -0.004]\n",
      "\n",
      "action: [-0.183  0.688 -0.975  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [ -9.13134  34.40971 -48.76308] gripper_action -10.0\n",
      "qpos: [-0.504  0.109 -0.112  0.862  0.033  0.689 -2.21   0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.383 -0.269  0.092  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.561 -0.207  0.079]\n",
      "tcp_to_goal_pos: [ 0.178  0.062 -0.013]\n",
      "cube_pose: [ 0.342 -0.248  0.023  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.041  0.021 -0.069]\n",
      "cube_to_goal_pos: [0.219 0.041 0.056]\n",
      "bowl_pose: [ 0.561 -0.207  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.178  0.062 -0.063]\n",
      "cube_to_bowl_pos: [0.219 0.041 0.006]\n",
      "\n",
      "action: [-0.432 -0.921  0.84   0.797]\n",
      "Stepping action ...\n",
      "delta xyz [-21.57922 -46.05236  41.9923 ] gripper_action 77.11887240409851\n",
      "qpos: [-0.566  0.15  -0.147  0.757  0.072  0.546 -2.34   0.04   0.04 ]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.339 -0.292  0.048  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.566 -0.212  0.078]\n",
      "tcp_to_goal_pos: [0.227 0.079 0.03 ]\n",
      "cube_pose: [ 0.359 -0.25   0.021  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.02   0.042 -0.027]\n",
      "cube_to_goal_pos: [0.206 0.037 0.057]\n",
      "bowl_pose: [ 0.566 -0.212  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.227  0.079 -0.02 ]\n",
      "cube_to_bowl_pos: [0.206 0.037 0.007]\n",
      "\n",
      "action: [ 0.686 -0.709 -0.805  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [ 34.29144 -35.44623 -40.25486] gripper_action -9.786092042922974\n",
      "qpos: [-0.531 -0.096 -0.181  0.597 -0.003  0.628 -2.278  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.302 -0.256  0.086  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.565 -0.209  0.079]\n",
      "tcp_to_goal_pos: [ 0.263  0.047 -0.006]\n",
      "cube_pose: [ 0.344 -0.25   0.024  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.042  0.006 -0.061]\n",
      "cube_to_goal_pos: [0.221 0.042 0.055]\n",
      "bowl_pose: [ 0.565 -0.209  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.263  0.047 -0.056]\n",
      "cube_to_bowl_pos: [0.221 0.042 0.005]\n",
      "\n",
      "action: [-0.859  0.808  0.984 -0.165]\n",
      "Stepping action ...\n",
      "delta xyz [-42.92881  40.41566  49.22386] gripper_action 490.90047284960747\n",
      "qpos: [-0.531  0.2   -0.187  0.791  0.103  0.534 -2.37   0.019  0.019]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.345 -0.301  0.04   0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.567 -0.212  0.077]\n",
      "tcp_to_goal_pos: [0.222 0.088 0.037]\n",
      "cube_pose: [ 0.35  -0.283  0.061  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [0.005 0.018 0.021]\n",
      "cube_to_goal_pos: [0.217 0.071 0.017]\n",
      "bowl_pose: [ 0.567 -0.212  0.027  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.222  0.088 -0.013]\n",
      "cube_to_bowl_pos: [ 0.217  0.071 -0.033]\n",
      "\n",
      "action: [ 0.965  1.    -0.948  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [ 48.25155  49.99506 -47.38237] gripper_action -9.947484135627747\n",
      "qpos: [-0.446  0.109 -0.126  0.849  0.032  0.677 -2.165  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.392 -0.251  0.089  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.562 -0.212  0.08 ]\n",
      "tcp_to_goal_pos: [ 0.17   0.039 -0.009]\n",
      "cube_pose: [ 0.343 -0.249  0.024  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.049  0.002 -0.065]\n",
      "cube_to_goal_pos: [0.219 0.037 0.056]\n",
      "bowl_pose: [ 0.562 -0.212  0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.17   0.039 -0.059]\n",
      "cube_to_bowl_pos: [0.219 0.037 0.006]\n",
      "\n",
      "action: [-0.37  -0.887  0.831  0.619]\n",
      "Stepping action ...\n",
      "delta xyz [-18.49036 -44.36814  41.54845] gripper_action 153.79941582679749\n",
      "qpos: [-0.508  0.145 -0.152  0.737  0.067  0.53  -2.283  0.036  0.036]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.35  -0.271  0.045  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.562 -0.21   0.079]\n",
      "tcp_to_goal_pos: [0.212 0.061 0.033]\n",
      "cube_pose: [ 0.349 -0.262  0.036  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.001  0.009 -0.009]\n",
      "cube_to_goal_pos: [0.213 0.052 0.043]\n",
      "bowl_pose: [ 0.562 -0.21   0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.212  0.061 -0.017]\n",
      "cube_to_bowl_pos: [ 0.213  0.052 -0.007]\n",
      "\n",
      "action: [ 0.033  0.672 -0.98   1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [  1.67044  33.57542 -48.99708] gripper_action -10.0\n",
      "qpos: [-0.478  0.094 -0.139  0.856  0.035  0.698 -2.211  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.381 -0.268  0.096  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.563 -0.206  0.079]\n",
      "tcp_to_goal_pos: [ 0.182  0.061 -0.018]\n",
      "cube_pose: [ 0.344 -0.247  0.023  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.037  0.02  -0.073]\n",
      "cube_to_goal_pos: [0.219 0.041 0.055]\n",
      "bowl_pose: [ 0.563 -0.206  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.182  0.061 -0.068]\n",
      "cube_to_bowl_pos: [0.219 0.041 0.005]\n",
      "\n",
      "action: [-0.422 -0.899  0.869  0.59 ]\n",
      "Stepping action ...\n",
      "delta xyz [-21.12226 -44.93413  43.46388] gripper_action 166.2932449579239\n",
      "qpos: [-0.539  0.14  -0.172  0.751  0.075  0.551 -2.34   0.036  0.036]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.338 -0.29   0.051  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.565 -0.209  0.078]\n",
      "tcp_to_goal_pos: [0.227 0.081 0.027]\n",
      "cube_pose: [ 0.352 -0.266  0.039  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.014  0.024 -0.012]\n",
      "cube_to_goal_pos: [0.213 0.058 0.039]\n",
      "bowl_pose: [ 0.565 -0.209  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.227  0.081 -0.023]\n",
      "cube_to_bowl_pos: [ 0.213  0.058 -0.011]\n",
      "\n",
      "action: [ 0.13   0.82  -0.983  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [  6.48216  41.01436 -49.14885] gripper_action -10.0\n",
      "qpos: [-0.497  0.098 -0.151  0.881  0.039  0.72  -2.245  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.376 -0.282  0.102  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.56  -0.209  0.078]\n",
      "tcp_to_goal_pos: [ 0.184  0.073 -0.024]\n",
      "cube_pose: [ 0.343 -0.248  0.024  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.033  0.034 -0.078]\n",
      "cube_to_goal_pos: [0.217 0.038 0.053]\n",
      "bowl_pose: [ 0.56  -0.209  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.184  0.073 -0.074]\n",
      "cube_to_bowl_pos: [0.217 0.038 0.003]\n",
      "\n",
      "action: [-0.287 -0.803  0.819  0.173]\n",
      "Stepping action ...\n",
      "delta xyz [-14.33029 -40.17326  40.96382] gripper_action 345.6720596551895\n",
      "qpos: [-0.545  0.134 -0.18   0.775  0.073  0.581 -2.351  0.026  0.026]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.339 -0.298  0.059  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.563 -0.208  0.078]\n",
      "tcp_to_goal_pos: [0.224 0.089 0.018]\n",
      "cube_pose: [ 0.344 -0.248  0.009  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.006  0.049 -0.05 ]\n",
      "cube_to_goal_pos: [0.218 0.04  0.068]\n",
      "bowl_pose: [ 0.563 -0.208  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.224  0.089 -0.032]\n",
      "cube_to_bowl_pos: [0.218 0.04  0.018]\n",
      "\n",
      "action: [ 0.522 -0.31   0.193  0.562]\n",
      "Stepping action ...\n",
      "delta xyz [ 26.10031 -15.48087   9.64012] gripper_action 178.42346131801605\n",
      "qpos: [-0.529  0.084 -0.172  0.666  0.058  0.521 -2.318  0.035  0.035]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.324 -0.272  0.048  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.561 -0.211  0.078]\n",
      "tcp_to_goal_pos: [0.237 0.061 0.03 ]\n",
      "cube_pose: [ 0.345 -0.254  0.036  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.021  0.018 -0.012]\n",
      "cube_to_goal_pos: [0.217 0.043 0.042]\n",
      "bowl_pose: [ 0.561 -0.211  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.237  0.061 -0.02 ]\n",
      "cube_to_bowl_pos: [ 0.217  0.043 -0.008]\n",
      "\n",
      "action: [-0.221  0.983 -0.996  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [-11.07346  49.15753 -49.81533] gripper_action -10.0\n",
      "qpos: [-0.491  0.084 -0.165  0.859  0.039  0.712 -2.252  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.37  -0.281  0.101  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.564 -0.21   0.078]\n",
      "tcp_to_goal_pos: [ 0.194  0.072 -0.023]\n",
      "cube_pose: [ 0.341 -0.249  0.024  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.029  0.032 -0.077]\n",
      "cube_to_goal_pos: [0.222 0.039 0.054]\n",
      "bowl_pose: [ 0.564 -0.21   0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.194  0.072 -0.073]\n",
      "cube_to_bowl_pos: [0.222 0.039 0.004]\n",
      "\n",
      "action: [-0.179 -0.81   0.839 -0.111]\n",
      "Stepping action ...\n",
      "delta xyz [ -8.94955 -40.481    41.94044] gripper_action 467.6760847121477\n",
      "qpos: [-0.531  0.115 -0.193  0.741  0.071  0.566 -2.35   0.02   0.02 ]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.332 -0.292  0.057  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.564 -0.208  0.079]\n",
      "tcp_to_goal_pos: [0.232 0.084 0.022]\n",
      "cube_pose: [ 0.343 -0.251  0.017  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.011  0.041 -0.04 ]\n",
      "cube_to_goal_pos: [0.221 0.043 0.062]\n",
      "bowl_pose: [ 0.564 -0.208  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.232  0.084 -0.028]\n",
      "cube_to_bowl_pos: [0.221 0.043 0.012]\n",
      "\n",
      "action: [ 0.406 -0.314  0.544  0.967]\n",
      "Stepping action ...\n",
      "delta xyz [ 20.28714 -15.70988  27.18016] gripper_action 4.293054938316345\n",
      "qpos: [-0.53   0.128 -0.176  0.644  0.084  0.456 -2.348  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.318 -0.272  0.028  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.566 -0.209  0.08 ]\n",
      "tcp_to_goal_pos: [0.248 0.063 0.051]\n",
      "cube_pose: [ 0.348 -0.257  0.032  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [0.03  0.015 0.004]\n",
      "cube_to_goal_pos: [0.217 0.048 0.048]\n",
      "bowl_pose: [ 0.566 -0.209  0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [0.248 0.063 0.001]\n",
      "cube_to_bowl_pos: [ 0.217  0.048 -0.002]\n",
      "\n",
      "action: [-0.308  0.993 -0.999  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [-15.42087  49.67385 -49.96368] gripper_action -10.0\n",
      "qpos: [-0.51   0.119 -0.16   0.837  0.052  0.655 -2.278  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.365 -0.286  0.081  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.564 -0.211  0.077]\n",
      "tcp_to_goal_pos: [ 0.199  0.075 -0.004]\n",
      "cube_pose: [ 0.344 -0.248  0.022  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.021  0.038 -0.06 ]\n",
      "cube_to_goal_pos: [0.219 0.036 0.055]\n",
      "bowl_pose: [ 0.564 -0.211  0.027  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.199  0.075 -0.054]\n",
      "cube_to_bowl_pos: [0.219 0.036 0.005]\n",
      "\n",
      "action: [ 0.264 -0.78   0.109 -0.448]\n",
      "Stepping action ...\n",
      "delta xyz [ 13.1966  -39.00484   5.42701] gripper_action 612.6274472475052\n",
      "qpos: [-0.515  0.026 -0.187  0.691  0.034  0.602 -2.299  0.012  0.012]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.326 -0.273  0.073  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.564 -0.209  0.079]\n",
      "tcp_to_goal_pos: [0.238 0.064 0.006]\n",
      "cube_pose: [ 0.344 -0.249  0.024  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.018  0.024 -0.049]\n",
      "cube_to_goal_pos: [0.22  0.04  0.055]\n",
      "bowl_pose: [ 0.564 -0.209  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.238  0.064 -0.044]\n",
      "cube_to_bowl_pos: [0.22  0.04  0.005]\n",
      "\n",
      "action: [-0.28   0.13   0.985  0.963]\n",
      "Stepping action ...\n",
      "delta xyz [-13.97948   6.52205  49.23366] gripper_action 5.822114944458008\n",
      "qpos: [-0.54   0.199 -0.169  0.73   0.106  0.473 -2.366  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.335 -0.288  0.025  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.565 -0.205  0.078]\n",
      "tcp_to_goal_pos: [0.23  0.083 0.053]\n",
      "cube_pose: [ 0.359 -0.263  0.025  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.024  0.025 -0.   ]\n",
      "cube_to_goal_pos: [0.206 0.058 0.053]\n",
      "bowl_pose: [ 0.565 -0.205  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [0.23  0.083 0.003]\n",
      "cube_to_bowl_pos: [0.206 0.058 0.003]\n",
      "\n",
      "action: [-0.198  0.978 -1.     1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [ -9.88171  48.89463 -49.9787 ] gripper_action -9.999461770057678\n",
      "qpos: [-0.53   0.183 -0.137  0.909  0.06   0.665 -2.28   0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.381 -0.297  0.078  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.56  -0.208  0.079]\n",
      "tcp_to_goal_pos: [0.179 0.089 0.001]\n",
      "cube_pose: [ 0.343 -0.249  0.024  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.038  0.047 -0.054]\n",
      "cube_to_goal_pos: [0.217 0.042 0.055]\n",
      "bowl_pose: [ 0.56  -0.208  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.179  0.089 -0.049]\n",
      "cube_to_bowl_pos: [0.217 0.042 0.005]\n",
      "\n",
      "action: [ 0.186 -0.924  0.134 -0.619]\n",
      "Stepping action ...\n",
      "delta xyz [  9.29808 -46.22007   6.71907] gripper_action 686.2484610080719\n",
      "qpos: [-0.555  0.087 -0.159  0.748  0.051  0.6   -2.323  0.009  0.009]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.335 -0.288  0.068  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.563 -0.209  0.08 ]\n",
      "tcp_to_goal_pos: [0.227 0.079 0.012]\n",
      "cube_pose: [ 0.344 -0.251  0.025  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.009  0.037 -0.043]\n",
      "cube_to_goal_pos: [0.219 0.042 0.055]\n",
      "bowl_pose: [ 0.563 -0.209  0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.227  0.079 -0.038]\n",
      "cube_to_bowl_pos: [0.219 0.042 0.005]\n",
      "\n",
      "action: [ 0.375 -0.395  0.818  0.969]\n",
      "Stepping action ...\n",
      "delta xyz [ 18.76563 -19.7379   40.91238] gripper_action 3.44049870967865\n",
      "qpos: [-0.553  0.131 -0.15   0.639  0.079  0.447 -2.34   0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.318 -0.27   0.026  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.562 -0.21   0.08 ]\n",
      "tcp_to_goal_pos: [0.244 0.06  0.054]\n",
      "cube_pose: [ 0.349 -0.255  0.034  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [0.031 0.015 0.009]\n",
      "cube_to_goal_pos: [0.213 0.045 0.045]\n",
      "bowl_pose: [ 0.562 -0.21   0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [0.244 0.06  0.004]\n",
      "cube_to_bowl_pos: [ 0.213  0.045 -0.005]\n",
      "\n",
      "action: [-0.363  0.998 -0.999  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [-18.16505  49.884   -49.93769] gripper_action -10.0\n",
      "qpos: [-0.532  0.126 -0.139  0.838  0.05   0.649 -2.277  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.365 -0.287  0.079  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.564 -0.208  0.079]\n",
      "tcp_to_goal_pos: [ 0.199  0.078 -0.   ]\n",
      "cube_pose: [ 0.344 -0.249  0.022  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.021  0.038 -0.057]\n",
      "cube_to_goal_pos: [0.22  0.04  0.057]\n",
      "bowl_pose: [ 0.564 -0.208  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.199  0.078 -0.05 ]\n",
      "cube_to_bowl_pos: [0.22  0.04  0.007]\n",
      "\n",
      "action: [ 0.237 -0.822  0.016 -0.267]\n",
      "Stepping action ...\n",
      "delta xyz [ 11.83101 -41.1028    0.80261] gripper_action 534.6659421920776\n",
      "qpos: [-0.537  0.02  -0.172  0.692  0.032  0.609 -2.304  0.017  0.017]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.324 -0.275  0.076  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.563 -0.208  0.08 ]\n",
      "tcp_to_goal_pos: [0.239 0.067 0.004]\n",
      "cube_pose: [ 0.343 -0.246  0.023  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.019  0.029 -0.053]\n",
      "cube_to_goal_pos: [0.22  0.037 0.057]\n",
      "bowl_pose: [ 0.563 -0.208  0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.239  0.067 -0.046]\n",
      "cube_to_bowl_pos: [0.22  0.037 0.007]\n",
      "\n",
      "action: [-0.045  0.056  0.933  0.925]\n",
      "Stepping action ...\n",
      "delta xyz [-2.24433  2.82029 46.66332] gripper_action 22.086193561553955\n",
      "qpos: [-0.538  0.159 -0.163  0.692  0.088  0.473 -2.344  0.043  0.043]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.33  -0.279  0.029  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.562 -0.208  0.079]\n",
      "tcp_to_goal_pos: [0.233 0.071 0.05 ]\n",
      "cube_pose: [ 0.354 -0.258  0.036  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [0.024 0.02  0.007]\n",
      "cube_to_goal_pos: [0.208 0.051 0.042]\n",
      "bowl_pose: [ 0.562 -0.208  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.233  0.071 -0.   ]\n",
      "cube_to_bowl_pos: [ 0.208  0.051 -0.008]\n",
      "\n",
      "action: [-0.261  0.994 -0.999  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [-13.04075  49.695   -49.93242] gripper_action -9.99984622001648\n",
      "qpos: [-0.522  0.151 -0.141  0.882  0.053  0.669 -2.27   0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.376 -0.29   0.082  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.561 -0.211  0.079]\n",
      "tcp_to_goal_pos: [ 0.185  0.079 -0.003]\n",
      "cube_pose: [ 0.342 -0.25   0.023  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.034  0.04  -0.06 ]\n",
      "cube_to_goal_pos: [0.219 0.039 0.056]\n",
      "bowl_pose: [ 0.561 -0.211  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.185  0.079 -0.053]\n",
      "cube_to_bowl_pos: [0.219 0.039 0.006]\n",
      "\n",
      "action: [-0.009 -0.87   0.209 -0.258]\n",
      "Stepping action ...\n",
      "delta xyz [ -0.45068 -43.52047  10.45838] gripper_action 530.9084564447403\n",
      "qpos: [-0.553  0.086 -0.17   0.751  0.054  0.604 -2.334  0.017  0.017]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.333 -0.291  0.069  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.565 -0.213  0.08 ]\n",
      "tcp_to_goal_pos: [0.232 0.078 0.011]\n",
      "cube_pose: [ 0.342 -0.249  0.019  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.009  0.042 -0.051]\n",
      "cube_to_goal_pos: [0.223 0.035 0.061]\n",
      "bowl_pose: [ 0.565 -0.213  0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.232  0.078 -0.039]\n",
      "cube_to_bowl_pos: [0.223 0.035 0.011]\n",
      "\n",
      "action: [ 0.401 -0.36   0.671  0.907]\n",
      "Stepping action ...\n",
      "delta xyz [ 20.07356 -18.0066   33.56083] gripper_action 29.931510090827942\n",
      "qpos: [-0.544  0.109 -0.164  0.644  0.072  0.474 -2.339  0.042  0.042]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.317 -0.272  0.034  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.563 -0.21   0.079]\n",
      "tcp_to_goal_pos: [0.245 0.062 0.045]\n",
      "cube_pose: [ 0.348 -0.257  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.031  0.015 -0.005]\n",
      "cube_to_goal_pos: [0.215 0.048 0.05 ]\n",
      "bowl_pose: [ 0.563 -0.21   0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.245  0.062 -0.005]\n",
      "cube_to_bowl_pos: [ 0.215  0.048 -0.   ]\n",
      "\n",
      "action: [-0.233  0.983 -0.999  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [-11.66999  49.12617 -49.9425 ] gripper_action -10.0\n",
      "qpos: [-0.511  0.098 -0.154  0.829  0.044  0.669 -2.266  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.364 -0.282  0.087  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.563 -0.21   0.078]\n",
      "tcp_to_goal_pos: [ 0.199  0.073 -0.009]\n",
      "cube_pose: [ 0.342 -0.246  0.022  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.022  0.036 -0.065]\n",
      "cube_to_goal_pos: [0.221 0.036 0.056]\n",
      "bowl_pose: [ 0.563 -0.21   0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.199  0.073 -0.059]\n",
      "cube_to_bowl_pos: [0.221 0.036 0.006]\n",
      "\n",
      "action: [ 0.148 -0.82   0.438 -0.353]\n",
      "Stepping action ...\n",
      "delta xyz [  7.38815 -40.99543  21.88947] gripper_action 571.60934060812\n",
      "qpos: [-0.523  0.052 -0.185  0.683  0.046  0.57  -2.315  0.015  0.015]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.324 -0.275  0.063  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.561 -0.206  0.081]\n",
      "tcp_to_goal_pos: [0.237 0.069 0.018]\n",
      "cube_pose: [ 0.343 -0.248  0.023  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.019  0.028 -0.04 ]\n",
      "cube_to_goal_pos: [0.218 0.042 0.058]\n",
      "bowl_pose: [ 0.561 -0.206  0.031  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.237  0.069 -0.032]\n",
      "cube_to_bowl_pos: [0.218 0.042 0.008]\n",
      "\n",
      "action: [-0.15   0.033  0.863  0.995]\n",
      "Stepping action ...\n",
      "delta xyz [-7.507    1.63237 43.13277] gripper_action -7.688046097755432\n",
      "qpos: [-0.547  0.191 -0.164  0.699  0.106  0.449 -2.37   0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.328 -0.284  0.02   0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.562 -0.21   0.079]\n",
      "tcp_to_goal_pos: [0.234 0.074 0.058]\n",
      "cube_pose: [ 0.356 -0.261  0.026  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [0.028 0.023 0.006]\n",
      "cube_to_goal_pos: [0.206 0.051 0.052]\n",
      "bowl_pose: [ 0.562 -0.21   0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [0.234 0.074 0.008]\n",
      "cube_to_bowl_pos: [0.206 0.051 0.002]\n",
      "\n",
      "action: [-0.286  0.98  -0.999  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [-14.2941   49.01835 -49.97321] gripper_action -10.0\n",
      "qpos: [-0.54   0.177 -0.136  0.885  0.061  0.646 -2.29   0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.374 -0.297  0.073  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.562 -0.21   0.077]\n",
      "tcp_to_goal_pos: [0.188 0.087 0.004]\n",
      "cube_pose: [ 0.342 -0.252  0.021  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.032  0.045 -0.052]\n",
      "cube_to_goal_pos: [0.22  0.041 0.056]\n",
      "bowl_pose: [ 0.562 -0.21   0.027  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.188  0.087 -0.046]\n",
      "cube_to_bowl_pos: [0.22  0.041 0.006]\n",
      "\n",
      "action: [ 0.379 -0.899 -0.178 -0.529]\n",
      "Stepping action ...\n",
      "delta xyz [ 18.96676 -44.95516  -8.89398] gripper_action 647.5293010473251\n",
      "qpos: [-0.544  0.028 -0.163  0.714  0.033  0.623 -2.302  0.011  0.011]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.329 -0.278  0.079  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.564 -0.207  0.08 ]\n",
      "tcp_to_goal_pos: [0.235 0.07  0.001]\n",
      "cube_pose: [ 0.343 -0.246  0.024  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.014  0.032 -0.055]\n",
      "cube_to_goal_pos: [0.221 0.038 0.056]\n",
      "bowl_pose: [ 0.564 -0.207  0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.235  0.07  -0.049]\n",
      "cube_to_bowl_pos: [0.221 0.038 0.006]\n",
      "\n",
      "action: [ 0.114 -0.178  0.98   0.908]\n",
      "Stepping action ...\n",
      "delta xyz [ 5.68791 -8.87561 48.9852 ] gripper_action 29.706735014915466\n",
      "qpos: [-0.541  0.136 -0.161  0.66   0.081  0.464 -2.341  0.043  0.043]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.323 -0.273  0.029  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.564 -0.208  0.08 ]\n",
      "tcp_to_goal_pos: [0.241 0.065 0.051]\n",
      "cube_pose: [ 0.351 -0.256  0.035  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [0.029 0.018 0.005]\n",
      "cube_to_goal_pos: [0.212 0.047 0.046]\n",
      "bowl_pose: [ 0.564 -0.208  0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [0.241 0.065 0.001]\n",
      "cube_to_bowl_pos: [ 0.212  0.047 -0.004]\n",
      "\n",
      "action: [-0.291  0.996 -0.999  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [-14.55534  49.78265 -49.95264] gripper_action -10.0\n",
      "qpos: [-0.519  0.129 -0.145  0.853  0.05   0.662 -2.271  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.369 -0.287  0.083  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.56  -0.209  0.077]\n",
      "tcp_to_goal_pos: [ 0.191  0.077 -0.005]\n",
      "cube_pose: [ 0.344 -0.252  0.025  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.026  0.035 -0.058]\n",
      "cube_to_goal_pos: [0.217 0.042 0.053]\n",
      "bowl_pose: [ 0.56  -0.209  0.027  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.191  0.077 -0.055]\n",
      "cube_to_bowl_pos: [0.217 0.042 0.003]\n",
      "\n",
      "action: [ 0.13  -0.825  0.275 -0.113]\n",
      "Stepping action ...\n",
      "delta xyz [  6.49751 -41.27127  13.73501] gripper_action 468.435450270772\n",
      "qpos: [-0.537  0.064 -0.173  0.712  0.047  0.586 -2.317  0.02   0.02 ]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.329 -0.28   0.066  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.558 -0.21   0.079]\n",
      "tcp_to_goal_pos: [0.229 0.07  0.012]\n",
      "cube_pose: [ 0.344 -0.249  0.022  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.015  0.032 -0.045]\n",
      "cube_to_goal_pos: [0.215 0.039 0.057]\n",
      "bowl_pose: [ 0.558 -0.21   0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.229  0.07  -0.038]\n",
      "cube_to_bowl_pos: [0.215 0.039 0.007]\n",
      "\n",
      "action: [ 0.17  -0.159  0.791  0.978]\n",
      "Stepping action ...\n",
      "delta xyz [ 8.50069 -7.96998 39.54478] gripper_action -0.5346626043319702\n",
      "qpos: [-0.539  0.146 -0.16   0.661  0.086  0.454 -2.343  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.323 -0.273  0.026  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.563 -0.212  0.077]\n",
      "tcp_to_goal_pos: [0.24  0.061 0.051]\n",
      "cube_pose: [ 0.35  -0.257  0.035  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [0.027 0.016 0.009]\n",
      "cube_to_goal_pos: [0.213 0.044 0.042]\n",
      "bowl_pose: [ 0.563 -0.212  0.027  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [0.24  0.061 0.001]\n",
      "cube_to_bowl_pos: [ 0.213  0.044 -0.008]\n",
      "\n",
      "action: [-0.335  0.996 -0.998  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [-16.72636  49.78379 -49.91901] gripper_action -9.99992311000824\n",
      "qpos: [-0.524  0.141 -0.143  0.857  0.053  0.655 -2.275  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.37  -0.288  0.079  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.561 -0.21   0.078]\n",
      "tcp_to_goal_pos: [ 0.19   0.079 -0.001]\n",
      "cube_pose: [ 0.343 -0.25   0.024  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.027  0.038 -0.056]\n",
      "cube_to_goal_pos: [0.218 0.04  0.054]\n",
      "bowl_pose: [ 0.561 -0.21   0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.19   0.079 -0.051]\n",
      "cube_to_bowl_pos: [0.218 0.04  0.004]\n",
      "\n",
      "action: [ 0.147 -0.819  0.004 -0.178]\n",
      "Stepping action ...\n",
      "delta xyz [  7.35449 -40.92706   0.20265] gripper_action 496.40924349427223\n",
      "qpos: [-0.538  0.041 -0.174  0.721  0.039  0.617 -2.311  0.019  0.019]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.329 -0.281  0.076  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.562 -0.209  0.077]\n",
      "tcp_to_goal_pos: [0.233 0.072 0.001]\n",
      "cube_pose: [ 0.342 -0.248  0.023  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.013  0.033 -0.053]\n",
      "cube_to_goal_pos: [0.22  0.039 0.054]\n",
      "bowl_pose: [ 0.562 -0.209  0.027  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.233  0.072 -0.049]\n",
      "cube_to_bowl_pos: [0.22  0.039 0.004]\n",
      "\n",
      "action: [ 0.283 -0.193  0.918  0.898]\n",
      "Stepping action ...\n",
      "delta xyz [14.16747 -9.65563 45.87839] gripper_action 33.65867555141449\n",
      "qpos: [-0.527  0.126 -0.166  0.647  0.078  0.461 -2.329  0.042  0.042]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.322 -0.268  0.03   0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.56  -0.207  0.078]\n",
      "tcp_to_goal_pos: [0.238 0.062 0.049]\n",
      "cube_pose: [ 0.351 -0.256  0.032  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [0.029 0.012 0.002]\n",
      "cube_to_goal_pos: [0.209 0.049 0.046]\n",
      "bowl_pose: [ 0.56  -0.207  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.238  0.062 -0.001]\n",
      "cube_to_bowl_pos: [ 0.209  0.049 -0.004]\n",
      "\n",
      "action: [-0.202  0.993 -0.999  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [-10.12004  49.66832 -49.96812] gripper_action -9.999974370002747\n",
      "qpos: [-0.499  0.11  -0.149  0.83   0.045  0.657 -2.251  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.369 -0.277  0.083  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.567 -0.21   0.079]\n",
      "tcp_to_goal_pos: [ 0.198  0.067 -0.003]\n",
      "cube_pose: [ 0.345 -0.247  0.021  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.024  0.03  -0.061]\n",
      "cube_to_goal_pos: [0.222 0.037 0.058]\n",
      "bowl_pose: [ 0.567 -0.21   0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.198  0.067 -0.053]\n",
      "cube_to_bowl_pos: [0.222 0.037 0.008]\n",
      "\n",
      "action: [-0.103 -0.842  0.543  0.083]\n",
      "Stepping action ...\n",
      "delta xyz [ -5.16781 -42.12183  27.13577] gripper_action 384.19649571180344\n",
      "qpos: [-0.536  0.1   -0.178  0.709  0.063  0.548 -2.335  0.024  0.024]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.329 -0.283  0.053  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.561 -0.206  0.079]\n",
      "tcp_to_goal_pos: [0.233 0.077 0.026]\n",
      "cube_pose: [ 0.346 -0.262  0.034  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.017  0.021 -0.02 ]\n",
      "cube_to_goal_pos: [0.215 0.056 0.045]\n",
      "bowl_pose: [ 0.561 -0.206  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.233  0.077 -0.024]\n",
      "cube_to_bowl_pos: [ 0.215  0.056 -0.005]\n",
      "\n",
      "action: [ 0.062  0.307 -0.891  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [  3.10327  15.35484 -44.55825] gripper_action -9.999513030052185\n",
      "qpos: [-0.505  0.015 -0.185  0.768  0.026  0.69  -2.278  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.341 -0.278  0.099  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.562 -0.209  0.079]\n",
      "tcp_to_goal_pos: [ 0.221  0.07  -0.02 ]\n",
      "cube_pose: [ 0.345 -0.249  0.024  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.003  0.029 -0.075]\n",
      "cube_to_goal_pos: [0.218 0.04  0.055]\n",
      "bowl_pose: [ 0.562 -0.209  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.221  0.07  -0.07 ]\n",
      "cube_to_bowl_pos: [0.218 0.04  0.005]\n",
      "\n",
      "action: [ 0.088 -0.521  0.975 -0.401]\n",
      "Stepping action ...\n",
      "delta xyz [  4.40144 -26.0726   48.7316 ] gripper_action 592.3267850279808\n",
      "qpos: [-0.507  0.078 -0.209  0.66   0.064  0.521 -2.338  0.014  0.014]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.318 -0.275  0.048  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.561 -0.21   0.078]\n",
      "tcp_to_goal_pos: [0.243 0.066 0.03 ]\n",
      "cube_pose: [ 0.348 -0.259  0.037  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.03   0.016 -0.012]\n",
      "cube_to_goal_pos: [0.213 0.05  0.042]\n",
      "bowl_pose: [ 0.561 -0.21   0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.243  0.066 -0.02 ]\n",
      "cube_to_bowl_pos: [ 0.213  0.05  -0.008]\n",
      "\n",
      "action: [-0.11   0.893 -0.76   1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [ -5.50443  44.62585 -38.00135] gripper_action -9.99976933002472\n",
      "qpos: [-0.473  0.083 -0.192  0.817  0.045  0.672 -2.268  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.36  -0.28   0.089  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.566 -0.208  0.079]\n",
      "tcp_to_goal_pos: [ 0.205  0.072 -0.01 ]\n",
      "cube_pose: [ 0.344 -0.247  0.023  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.016  0.033 -0.066]\n",
      "cube_to_goal_pos: [0.221 0.039 0.056]\n",
      "bowl_pose: [ 0.566 -0.208  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.205  0.072 -0.06 ]\n",
      "cube_to_bowl_pos: [0.221 0.039 0.006]\n",
      "\n",
      "action: [ 0.38  -0.783  0.661 -0.343]\n",
      "Stepping action ...\n",
      "delta xyz [ 18.99867 -39.15954  33.07297] gripper_action 567.5909158587456\n",
      "qpos: [-0.476  0.051 -0.208  0.645  0.047  0.532 -2.292  0.015  0.015]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.323 -0.262  0.053  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.564 -0.211  0.078]\n",
      "tcp_to_goal_pos: [0.241 0.051 0.025]\n",
      "cube_pose: [ 0.347 -0.255  0.039  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.024  0.007 -0.015]\n",
      "cube_to_goal_pos: [0.217 0.044 0.039]\n",
      "bowl_pose: [ 0.564 -0.211  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.241  0.051 -0.025]\n",
      "cube_to_bowl_pos: [ 0.217  0.044 -0.011]\n",
      "\n",
      "action: [-0.471  0.955 -0.674  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [-23.57156  47.74331 -33.68892] gripper_action -9.999948740005493\n",
      "qpos: [-0.463  0.109 -0.2    0.853  0.053  0.683 -2.27   0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.369 -0.284  0.09   0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.564 -0.209  0.078]\n",
      "tcp_to_goal_pos: [ 0.195  0.076 -0.012]\n",
      "cube_pose: [ 0.344 -0.249  0.023  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.025  0.035 -0.067]\n",
      "cube_to_goal_pos: [0.22  0.04  0.055]\n",
      "bowl_pose: [ 0.564 -0.209  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.195  0.076 -0.062]\n",
      "cube_to_bowl_pos: [0.22  0.04  0.005]\n",
      "\n",
      "action: [ 0.243 -0.822  0.64  -0.44 ]\n",
      "Stepping action ...\n",
      "delta xyz [ 12.1602  -41.09756  32.00262] gripper_action 609.3412971496582\n",
      "qpos: [-0.483  0.08  -0.212  0.69   0.059  0.55  -2.312  0.013  0.013]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.33  -0.273  0.056  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.562 -0.207  0.08 ]\n",
      "tcp_to_goal_pos: [0.232 0.066 0.025]\n",
      "cube_pose: [ 0.348 -0.256  0.033  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.018  0.017 -0.023]\n",
      "cube_to_goal_pos: [0.214 0.049 0.047]\n",
      "bowl_pose: [ 0.562 -0.207  0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.232  0.066 -0.025]\n",
      "cube_to_bowl_pos: [ 0.214  0.049 -0.003]\n",
      "\n",
      "action: [-0.166  0.238  0.045  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [-8.30311 11.90887  2.22843] gripper_action -9.998231530189514\n",
      "qpos: [-0.487  0.124 -0.204  0.743  0.074  0.559 -2.319  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.342 -0.282  0.054  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.559 -0.209  0.078]\n",
      "tcp_to_goal_pos: [0.217 0.073 0.024]\n",
      "cube_pose: [ 0.345 -0.245  0.021  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.003  0.036 -0.033]\n",
      "cube_to_goal_pos: [0.213 0.036 0.057]\n",
      "bowl_pose: [ 0.559 -0.209  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.217  0.073 -0.026]\n",
      "cube_to_bowl_pos: [0.213 0.036 0.007]\n",
      "\n",
      "action: [ 0.845 -0.861 -0.912  0.996]\n",
      "Stepping action ...\n",
      "delta xyz [ 42.26818 -43.03595 -45.5927 ] gripper_action -8.199979662895203\n",
      "qpos: [-0.452 -0.175 -0.233  0.554 -0.044  0.662 -2.219  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.296 -0.238  0.096  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.566 -0.205  0.078]\n",
      "tcp_to_goal_pos: [ 0.27   0.033 -0.018]\n",
      "cube_pose: [ 0.345 -0.251  0.024  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.049 -0.013 -0.072]\n",
      "cube_to_goal_pos: [0.221 0.046 0.054]\n",
      "bowl_pose: [ 0.566 -0.205  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.27   0.033 -0.068]\n",
      "cube_to_bowl_pos: [0.221 0.046 0.004]\n",
      "\n",
      "action: [-0.958  0.868  0.999 -0.48 ]\n",
      "Stepping action ...\n",
      "delta xyz [-47.91886  43.39127  49.97191] gripper_action 626.407223045826\n",
      "qpos: [-0.438  0.149 -0.261  0.757  0.1    0.552 -2.348  0.012  0.012]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.342 -0.287  0.05   0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.562 -0.208  0.079]\n",
      "tcp_to_goal_pos: [0.22  0.079 0.029]\n",
      "cube_pose: [ 0.344 -0.252  0.022  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.001  0.035 -0.028]\n",
      "cube_to_goal_pos: [0.218 0.044 0.057]\n",
      "bowl_pose: [ 0.562 -0.208  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.22   0.079 -0.021]\n",
      "cube_to_bowl_pos: [0.218 0.044 0.007]\n",
      "\n",
      "action: [ 0.373 -0.632  0.223  0.999]\n",
      "Stepping action ...\n",
      "delta xyz [ 18.6291  -31.62411  11.13492] gripper_action -9.470638036727905\n",
      "qpos: [-0.459  0.086 -0.253  0.622  0.08   0.477 -2.349  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.312 -0.269  0.037  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.566 -0.21   0.079]\n",
      "tcp_to_goal_pos: [0.255 0.059 0.042]\n",
      "cube_pose: [ 0.347 -0.253  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.035  0.016 -0.009]\n",
      "cube_to_goal_pos: [0.219 0.043 0.051]\n",
      "bowl_pose: [ 0.566 -0.21   0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.255  0.059 -0.008]\n",
      "cube_to_bowl_pos: [0.219 0.043 0.001]\n",
      "\n",
      "action: [-0.334  0.951 -0.991  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [-16.68926  47.53066 -49.56565] gripper_action -10.0\n",
      "qpos: [-0.445  0.081 -0.235  0.815  0.051  0.672 -2.286  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.356 -0.284  0.089  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.561 -0.211  0.079]\n",
      "tcp_to_goal_pos: [ 0.205  0.073 -0.01 ]\n",
      "cube_pose: [ 0.343 -0.247  0.022  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.013  0.038 -0.067]\n",
      "cube_to_goal_pos: [0.218 0.036 0.057]\n",
      "bowl_pose: [ 0.561 -0.211  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.205  0.073 -0.06 ]\n",
      "cube_to_bowl_pos: [0.218 0.036 0.007]\n",
      "\n",
      "action: [ 0.588 -0.695  0.534 -0.566]\n",
      "Stepping action ...\n",
      "delta xyz [ 29.40209 -34.74848  26.68877] gripper_action 663.4202325344086\n",
      "qpos: [-0.435  0.021 -0.238  0.634  0.034  0.55  -2.271  0.01   0.01 ]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.323 -0.256  0.06   0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.565 -0.21   0.079]\n",
      "tcp_to_goal_pos: [0.242 0.046 0.019]\n",
      "cube_pose: [ 0.346 -0.25   0.037  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.023  0.005 -0.023]\n",
      "cube_to_goal_pos: [0.219 0.041 0.041]\n",
      "bowl_pose: [ 0.565 -0.21   0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.242  0.046 -0.031]\n",
      "cube_to_bowl_pos: [ 0.219  0.041 -0.009]\n",
      "\n",
      "action: [-0.658  0.691  0.591  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [-32.90962  34.56929  29.56477] gripper_action -9.834045767784119\n",
      "qpos: [-0.478  0.228 -0.2    0.803  0.116  0.519 -2.339  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.359 -0.289  0.033  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.561 -0.21   0.078]\n",
      "tcp_to_goal_pos: [0.202 0.079 0.045]\n",
      "cube_pose: [ 0.367 -0.295  0.066  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.008 -0.005  0.033]\n",
      "cube_to_goal_pos: [0.194 0.084 0.012]\n",
      "bowl_pose: [ 0.561 -0.21   0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.202  0.079 -0.005]\n",
      "cube_to_bowl_pos: [ 0.194  0.084 -0.038]\n",
      "\n",
      "action: [ 0.998  1.    -0.937  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [ 49.8843   49.98298 -46.84737] gripper_action -9.83368694782257\n",
      "qpos: [-0.405  0.14  -0.128  0.865  0.035  0.661 -2.126  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.407 -0.238  0.081  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.564 -0.207  0.079]\n",
      "tcp_to_goal_pos: [ 0.157  0.031 -0.003]\n",
      "cube_pose: [ 0.345 -0.248  0.022  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.062 -0.01  -0.059]\n",
      "cube_to_goal_pos: [0.219 0.04  0.056]\n",
      "bowl_pose: [ 0.564 -0.207  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.157  0.031 -0.053]\n",
      "cube_to_bowl_pos: [0.219 0.04  0.006]\n",
      "\n",
      "action: [-0.333 -0.951  0.72  -0.064]\n",
      "Stepping action ...\n",
      "delta xyz [-16.6446  -47.53805  35.98924] gripper_action 447.35901929438114\n",
      "qpos: [-0.473  0.15  -0.144  0.736  0.061  0.524 -2.235  0.021  0.021]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.361 -0.256  0.043  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.562 -0.21   0.079]\n",
      "tcp_to_goal_pos: [0.201 0.046 0.036]\n",
      "cube_pose: [ 0.353 -0.255  0.036  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.008  0.001 -0.007]\n",
      "cube_to_goal_pos: [0.209 0.045 0.044]\n",
      "bowl_pose: [ 0.562 -0.21   0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.201  0.046 -0.014]\n",
      "cube_to_bowl_pos: [ 0.209  0.045 -0.006]\n",
      "\n",
      "action: [-0.115  0.664 -0.905  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [ -5.76046  33.20993 -45.27329] gripper_action -9.99992311000824\n",
      "qpos: [-0.46   0.119 -0.131  0.869  0.036  0.686 -2.185  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.392 -0.26   0.091  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.564 -0.207  0.077]\n",
      "tcp_to_goal_pos: [ 0.172  0.053 -0.013]\n",
      "cube_pose: [ 0.346 -0.25   0.023  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.046  0.01  -0.067]\n",
      "cube_to_goal_pos: [0.218 0.043 0.054]\n",
      "bowl_pose: [ 0.564 -0.207  0.027  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.172  0.053 -0.063]\n",
      "cube_to_bowl_pos: [0.218 0.043 0.004]\n",
      "\n",
      "action: [-0.335 -0.899  0.84   0.706]\n",
      "Stepping action ...\n",
      "delta xyz [-16.73426 -44.94712  42.00476] gripper_action 116.37428879737854\n",
      "qpos: [-0.522  0.153 -0.153  0.752  0.07   0.539 -2.3    0.038  0.038]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.349 -0.278  0.047  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.565 -0.209  0.08 ]\n",
      "tcp_to_goal_pos: [0.216 0.07  0.033]\n",
      "cube_pose: [ 0.349 -0.267  0.034  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.     0.011 -0.013]\n",
      "cube_to_goal_pos: [0.216 0.058 0.046]\n",
      "bowl_pose: [ 0.565 -0.209  0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.216  0.07  -0.017]\n",
      "cube_to_bowl_pos: [ 0.216  0.058 -0.004]\n",
      "\n",
      "action: [ 0.103  0.475 -0.974  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [  5.12784  23.75025 -48.70592] gripper_action -10.0\n",
      "qpos: [-0.493  0.075 -0.145  0.833  0.033  0.694 -2.231  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.37  -0.272  0.096  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.568 -0.209  0.079]\n",
      "tcp_to_goal_pos: [ 0.198  0.063 -0.017]\n",
      "cube_pose: [ 0.345 -0.247  0.025  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.025  0.024 -0.071]\n",
      "cube_to_goal_pos: [0.223 0.038 0.054]\n",
      "bowl_pose: [ 0.568 -0.209  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.198  0.063 -0.067]\n",
      "cube_to_bowl_pos: [0.223 0.038 0.004]\n",
      "\n",
      "action: [-0.257 -0.854  0.831  0.16 ]\n",
      "Stepping action ...\n",
      "delta xyz [-12.85114 -42.68047  41.52746] gripper_action 351.30301490426064\n",
      "qpos: [-0.534  0.11  -0.183  0.719  0.068  0.549 -2.341  0.026  0.026]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.33  -0.286  0.053  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.56  -0.211  0.08 ]\n",
      "tcp_to_goal_pos: [0.231 0.075 0.027]\n",
      "cube_pose: [ 0.346 -0.268  0.038  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.016  0.017 -0.015]\n",
      "cube_to_goal_pos: [0.215 0.058 0.042]\n",
      "bowl_pose: [ 0.56  -0.211  0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.231  0.075 -0.023]\n",
      "cube_to_bowl_pos: [ 0.215  0.058 -0.008]\n",
      "\n",
      "action: [ 0.142  0.853 -0.972  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [  7.09467  42.65686 -48.59222] gripper_action -10.0\n",
      "qpos: [-0.485  0.07  -0.164  0.851  0.035  0.718 -2.243  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.37  -0.277  0.104  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.564 -0.207  0.079]\n",
      "tcp_to_goal_pos: [ 0.194  0.07  -0.025]\n",
      "cube_pose: [ 0.345 -0.248  0.024  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.024  0.029 -0.08 ]\n",
      "cube_to_goal_pos: [0.218 0.041 0.055]\n",
      "bowl_pose: [ 0.564 -0.207  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.194  0.07  -0.075]\n",
      "cube_to_bowl_pos: [0.218 0.041 0.005]\n",
      "\n",
      "action: [-0.176 -0.779  0.877 -0.1  ]\n",
      "Stepping action ...\n",
      "delta xyz [ -8.77799 -38.95155  43.8305 ] gripper_action 462.8319127112627\n",
      "qpos: [-0.52   0.107 -0.195  0.735  0.067  0.567 -2.338  0.02   0.02 ]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.333 -0.287  0.058  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.562 -0.209  0.079]\n",
      "tcp_to_goal_pos: [0.229 0.078 0.021]\n",
      "cube_pose: [ 0.346 -0.253  0.02   1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.013  0.035 -0.038]\n",
      "cube_to_goal_pos: [0.217 0.043 0.059]\n",
      "bowl_pose: [ 0.562 -0.209  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.229  0.078 -0.029]\n",
      "cube_to_bowl_pos: [0.217 0.043 0.009]\n",
      "\n",
      "action: [ 0.302 -0.328  0.614  0.987]\n",
      "Stepping action ...\n",
      "delta xyz [ 15.12335 -16.38993  30.69411] gripper_action -4.61465060710907\n",
      "qpos: [-0.528  0.138 -0.178  0.648  0.09   0.45  -2.353  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.319 -0.273  0.026  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.562 -0.21   0.078]\n",
      "tcp_to_goal_pos: [0.243 0.063 0.052]\n",
      "cube_pose: [ 0.349 -0.256  0.034  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [0.031 0.017 0.008]\n",
      "cube_to_goal_pos: [0.213 0.046 0.044]\n",
      "bowl_pose: [ 0.562 -0.21   0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [0.243 0.063 0.002]\n",
      "cube_to_bowl_pos: [ 0.213  0.046 -0.006]\n",
      "\n",
      "action: [-0.313  0.996 -0.999  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [-15.67235  49.80464 -49.93653] gripper_action -9.999897480010986\n",
      "qpos: [-0.512  0.129 -0.16   0.84   0.055  0.65  -2.281  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.365 -0.287  0.079  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.567 -0.209  0.078]\n",
      "tcp_to_goal_pos: [ 0.201  0.078 -0.001]\n",
      "cube_pose: [ 0.345 -0.25   0.021  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.021  0.037 -0.058]\n",
      "cube_to_goal_pos: [0.222 0.041 0.057]\n",
      "bowl_pose: [ 0.567 -0.209  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.201  0.078 -0.051]\n",
      "cube_to_bowl_pos: [0.222 0.041 0.007]\n",
      "\n",
      "action: [ 0.254 -0.808  0.209 -0.197]\n",
      "Stepping action ...\n",
      "delta xyz [ 12.69234 -40.41116  10.45373] gripper_action 504.6712973713875\n",
      "qpos: [-0.522  0.047 -0.184  0.689  0.043  0.58  -2.309  0.018  0.018]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.326 -0.275  0.066  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.566 -0.208  0.079]\n",
      "tcp_to_goal_pos: [0.24  0.067 0.013]\n",
      "cube_pose: [ 0.345 -0.247  0.021  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.019  0.028 -0.045]\n",
      "cube_to_goal_pos: [0.221 0.039 0.058]\n",
      "bowl_pose: [ 0.566 -0.208  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.24   0.067 -0.037]\n",
      "cube_to_bowl_pos: [0.221 0.039 0.008]\n",
      "\n",
      "action: [-0.192  0.021  0.858  0.985]\n",
      "Stepping action ...\n",
      "delta xyz [-9.5873   1.0317  42.87738] gripper_action -3.6365586519241333\n",
      "qpos: [-0.546  0.187 -0.167  0.707  0.103  0.461 -2.369  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.329 -0.286  0.023  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.563 -0.21   0.08 ]\n",
      "tcp_to_goal_pos: [0.233 0.076 0.057]\n",
      "cube_pose: [ 0.354 -0.259  0.024  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [0.025 0.026 0.   ]\n",
      "cube_to_goal_pos: [0.209 0.049 0.056]\n",
      "bowl_pose: [ 0.563 -0.21   0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [0.233 0.076 0.007]\n",
      "cube_to_bowl_pos: [0.209 0.049 0.006]\n",
      "\n",
      "action: [-0.449  0.964 -1.     1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [-22.43121  48.19534 -49.98863] gripper_action -9.999948740005493\n",
      "qpos: [-0.551  0.188 -0.141  0.912  0.065  0.663 -2.309  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.374 -0.307  0.077  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.564 -0.211  0.08 ]\n",
      "tcp_to_goal_pos: [0.19  0.096 0.003]\n",
      "cube_pose: [ 0.345 -0.251  0.018  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.03   0.056 -0.059]\n",
      "cube_to_goal_pos: [0.22  0.04  0.062]\n",
      "bowl_pose: [ 0.564 -0.211  0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.19   0.096 -0.047]\n",
      "cube_to_bowl_pos: [0.22  0.04  0.012]\n",
      "\n",
      "action: [ 0.144 -0.947  0.067 -0.922]\n",
      "Stepping action ...\n",
      "delta xyz [  7.19038 -47.36198   3.37481] gripper_action 816.2905049324036\n",
      "qpos: [-0.58   0.088 -0.167  0.757  0.056  0.608 -2.36   0.002  0.002]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.327 -0.3    0.07   0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.564 -0.209  0.078]\n",
      "tcp_to_goal_pos: [0.236 0.09  0.008]\n",
      "cube_pose: [ 0.345 -0.25   0.019  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.018  0.05  -0.051]\n",
      "cube_to_goal_pos: [0.218 0.041 0.059]\n",
      "bowl_pose: [ 0.564 -0.209  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.236  0.09  -0.042]\n",
      "cube_to_bowl_pos: [0.218 0.041 0.009]\n",
      "\n",
      "action: [ 0.578 -0.046  0.864  0.579]\n",
      "Stepping action ...\n",
      "delta xyz [28.90848 -2.29163 43.22066] gripper_action 170.90144157409668\n",
      "qpos: [-0.554  0.152 -0.138  0.67   0.079  0.457 -2.328  0.035  0.035]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.328 -0.272  0.026  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.563 -0.211  0.08 ]\n",
      "tcp_to_goal_pos: [0.235 0.061 0.053]\n",
      "cube_pose: [ 0.355 -0.262  0.038  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [0.028 0.01  0.011]\n",
      "cube_to_goal_pos: [0.207 0.051 0.042]\n",
      "bowl_pose: [ 0.563 -0.211  0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [0.235 0.061 0.003]\n",
      "cube_to_bowl_pos: [ 0.207  0.051 -0.008]\n",
      "\n",
      "action: [-0.064  0.998 -0.998  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [ -3.21625  49.92179 -49.90532] gripper_action -9.99992311000824\n",
      "qpos: [-0.517  0.125 -0.118  0.836  0.041  0.648 -2.235  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.375 -0.274  0.079  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.563 -0.211  0.079]\n",
      "tcp_to_goal_pos: [0.189 0.063 0.   ]\n",
      "cube_pose: [ 0.355 -0.253  0.026  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.019  0.021 -0.053]\n",
      "cube_to_goal_pos: [0.208 0.042 0.053]\n",
      "bowl_pose: [ 0.563 -0.211  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.189  0.063 -0.05 ]\n",
      "cube_to_bowl_pos: [0.208 0.042 0.003]\n",
      "\n",
      "action: [-0.228 -0.873  0.415  0.887]\n",
      "Stepping action ...\n",
      "delta xyz [-11.41524 -43.66968  20.76447] gripper_action 38.432928919792175\n",
      "qpos: [-0.56   0.105 -0.154  0.727  0.059  0.56  -2.331  0.042  0.042]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.332 -0.286  0.056  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.563 -0.212  0.08 ]\n",
      "tcp_to_goal_pos: [0.23  0.074 0.024]\n",
      "cube_pose: [ 0.357 -0.264  0.041  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.025  0.022 -0.015]\n",
      "cube_to_goal_pos: [0.205 0.052 0.039]\n",
      "bowl_pose: [ 0.563 -0.212  0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.23   0.074 -0.026]\n",
      "cube_to_bowl_pos: [ 0.205  0.052 -0.011]\n",
      "\n",
      "action: [ 0.013  0.974 -0.995  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [  0.64044  48.69715 -49.77208] gripper_action -9.999948740005493\n",
      "qpos: [-0.509  0.092 -0.141  0.895  0.036  0.741 -2.244  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.378 -0.284  0.109  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.566 -0.208  0.08 ]\n",
      "tcp_to_goal_pos: [ 0.188  0.076 -0.029]\n",
      "cube_pose: [ 0.357 -0.25   0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.021  0.034 -0.081]\n",
      "cube_to_goal_pos: [0.209 0.042 0.052]\n",
      "bowl_pose: [ 0.566 -0.208  0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.188  0.076 -0.079]\n",
      "cube_to_bowl_pos: [0.209 0.042 0.002]\n",
      "\n",
      "action: [-0.1   -0.659  0.858 -0.118]\n",
      "Stepping action ...\n",
      "delta xyz [ -4.97523 -32.93184  42.88258] gripper_action 470.8801931887865\n",
      "qpos: [-0.536  0.127 -0.164  0.784  0.062  0.596 -2.317  0.02   0.02 ]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.347 -0.29   0.064  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.562 -0.211  0.081]\n",
      "tcp_to_goal_pos: [0.215 0.079 0.016]\n",
      "cube_pose: [ 0.357 -0.256  0.023  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.009  0.033 -0.041]\n",
      "cube_to_goal_pos: [0.205 0.045 0.058]\n",
      "bowl_pose: [ 0.562 -0.211  0.031  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.215  0.079 -0.034]\n",
      "cube_to_bowl_pos: [0.205 0.045 0.008]\n",
      "\n",
      "action: [ 0.342 -0.43   0.755  0.975]\n",
      "Stepping action ...\n",
      "delta xyz [ 17.10058 -21.48257  37.7307 ] gripper_action 0.5552786588668823\n",
      "qpos: [-0.548  0.161 -0.145  0.676  0.085  0.454 -2.336  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.328 -0.274  0.025  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.565 -0.21   0.079]\n",
      "tcp_to_goal_pos: [0.237 0.064 0.055]\n",
      "cube_pose: [ 0.356 -0.254  0.038  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [0.027 0.02  0.014]\n",
      "cube_to_goal_pos: [0.21  0.044 0.041]\n",
      "bowl_pose: [ 0.565 -0.21   0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [0.237 0.064 0.005]\n",
      "cube_to_bowl_pos: [ 0.21   0.044 -0.009]\n",
      "\n",
      "action: [-0.38   0.998 -0.997  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [-19.00942  49.91434 -49.87039] gripper_action -9.999871850013733\n",
      "qpos: [-0.538  0.16  -0.128  0.878  0.053  0.656 -2.274  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.375 -0.291  0.078  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.566 -0.205  0.078]\n",
      "tcp_to_goal_pos: [0.191 0.087 0.   ]\n",
      "cube_pose: [ 0.351 -0.253  0.023  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.024  0.039 -0.054]\n",
      "cube_to_goal_pos: [0.215 0.048 0.055]\n",
      "bowl_pose: [ 0.566 -0.205  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.191  0.087 -0.05 ]\n",
      "cube_to_bowl_pos: [0.215 0.048 0.005]\n",
      "\n",
      "action: [ 0.314 -0.888  0.21  -0.294]\n",
      "Stepping action ...\n",
      "delta xyz [ 15.6853  -44.40195  10.52297] gripper_action 546.5803924202919\n",
      "qpos: [-0.549  0.066 -0.15   0.707  0.044  0.579 -2.304  0.016  0.016]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.331 -0.276  0.064  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.567 -0.209  0.079]\n",
      "tcp_to_goal_pos: [0.235 0.067 0.014]\n",
      "cube_pose: [ 0.352 -0.244  0.024  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.021  0.032 -0.04 ]\n",
      "cube_to_goal_pos: [0.215 0.035 0.055]\n",
      "bowl_pose: [ 0.567 -0.209  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.235  0.067 -0.036]\n",
      "cube_to_bowl_pos: [0.215 0.035 0.005]\n",
      "\n",
      "action: [ 0.088 -0.048  0.808  0.992]\n",
      "Stepping action ...\n",
      "delta xyz [ 4.39951 -2.38669 40.39919] gripper_action -6.619608402252197\n",
      "qpos: [-0.551  0.168 -0.136  0.682  0.083  0.453 -2.327  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.331 -0.273  0.024  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.561 -0.21   0.08 ]\n",
      "tcp_to_goal_pos: [0.229 0.063 0.056]\n",
      "cube_pose: [ 0.357 -0.255  0.04   1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [0.026 0.018 0.017]\n",
      "cube_to_goal_pos: [0.203 0.045 0.039]\n",
      "bowl_pose: [ 0.561 -0.21   0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [0.229 0.063 0.006]\n",
      "cube_to_bowl_pos: [ 0.203  0.045 -0.011]\n",
      "\n",
      "action: [-0.318  0.998 -0.997  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [-15.91793  49.91956 -49.84406] gripper_action -9.99894917011261\n",
      "qpos: [-0.538  0.162 -0.117  0.877  0.05   0.653 -2.26   0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.378 -0.287  0.077  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.567 -0.207  0.08 ]\n",
      "tcp_to_goal_pos: [0.189 0.08  0.003]\n",
      "cube_pose: [ 0.354 -0.251  0.026  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.024  0.036 -0.051]\n",
      "cube_to_goal_pos: [0.213 0.044 0.054]\n",
      "bowl_pose: [ 0.567 -0.207  0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.189  0.08  -0.047]\n",
      "cube_to_bowl_pos: [0.213 0.044 0.004]\n",
      "\n",
      "action: [ 0.168 -0.882 -0.115  0.162]\n",
      "Stepping action ...\n",
      "delta xyz [  8.38411 -44.07821  -5.73849] gripper_action 350.4527077078819\n",
      "qpos: [-0.551  0.04  -0.15   0.731  0.035  0.629 -2.297  0.026  0.026]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.334 -0.279  0.08   0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.563 -0.21   0.079]\n",
      "tcp_to_goal_pos: [ 0.229  0.069 -0.001]\n",
      "cube_pose: [ 0.354 -0.246  0.026  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.019  0.033 -0.054]\n",
      "cube_to_goal_pos: [0.209 0.036 0.053]\n",
      "bowl_pose: [ 0.563 -0.21   0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.229  0.069 -0.051]\n",
      "cube_to_bowl_pos: [0.209 0.036 0.003]\n",
      "\n",
      "action: [0.38  0.082 0.871 0.922]\n",
      "Stepping action ...\n",
      "delta xyz [19.01647  4.11501 43.55012] gripper_action 23.672690391540527\n",
      "qpos: [-0.52   0.133 -0.134  0.684  0.062  0.489 -2.275  0.043  0.043]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.341 -0.261  0.036  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.563 -0.206  0.079]\n",
      "tcp_to_goal_pos: [0.222 0.055 0.043]\n",
      "cube_pose: [ 0.355 -0.257  0.036  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.015  0.004 -0.   ]\n",
      "cube_to_goal_pos: [0.208 0.051 0.043]\n",
      "bowl_pose: [ 0.563 -0.206  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.222  0.055 -0.007]\n",
      "cube_to_bowl_pos: [ 0.208  0.051 -0.007]\n",
      "\n",
      "action: [ 0.107  0.999 -1.     1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [  5.3366   49.96893 -49.98468] gripper_action -9.999948740005493\n",
      "qpos: [-0.472  0.104 -0.112  0.842  0.03   0.675 -2.174  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.388 -0.254  0.089  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.563 -0.21   0.078]\n",
      "tcp_to_goal_pos: [ 0.175  0.044 -0.01 ]\n",
      "cube_pose: [ 0.353 -0.247  0.027  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.035  0.008 -0.062]\n",
      "cube_to_goal_pos: [0.21  0.037 0.051]\n",
      "bowl_pose: [ 0.563 -0.21   0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.175  0.044 -0.06 ]\n",
      "cube_to_bowl_pos: [0.21  0.037 0.001]\n",
      "\n",
      "action: [-0.441 -0.888  0.817  0.71 ]\n",
      "Stepping action ...\n",
      "delta xyz [-22.05072 -44.41225  40.87367] gripper_action 114.7648274898529\n",
      "qpos: [-0.533  0.145 -0.145  0.74   0.067  0.534 -2.302  0.038  0.038]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.346 -0.277  0.046  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.563 -0.209  0.078]\n",
      "tcp_to_goal_pos: [0.217 0.068 0.032]\n",
      "cube_pose: [ 0.356 -0.266  0.037  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.01   0.012 -0.009]\n",
      "cube_to_goal_pos: [0.207 0.057 0.041]\n",
      "bowl_pose: [ 0.563 -0.209  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.217  0.068 -0.018]\n",
      "cube_to_bowl_pos: [ 0.207  0.057 -0.009]\n",
      "\n",
      "action: [ 0.058  0.989 -0.995  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [  2.90271  49.47071 -49.74768] gripper_action -10.0\n",
      "qpos: [-0.492  0.127 -0.121  0.906  0.037  0.715 -2.208  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.392 -0.273  0.098  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.565 -0.21   0.078]\n",
      "tcp_to_goal_pos: [ 0.173  0.063 -0.02 ]\n",
      "cube_pose: [ 0.353 -0.248  0.026  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.039  0.025 -0.073]\n",
      "cube_to_goal_pos: [0.212 0.039 0.053]\n",
      "bowl_pose: [ 0.565 -0.21   0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.173  0.063 -0.07 ]\n",
      "cube_to_bowl_pos: [0.212 0.039 0.003]\n",
      "\n",
      "action: [-0.455 -0.852  0.839  0.696]\n",
      "Stepping action ...\n",
      "delta xyz [-22.77342 -42.58556  41.92582] gripper_action 120.7164204120636\n",
      "qpos: [-0.558  0.171 -0.147  0.81   0.073  0.578 -2.33   0.038  0.038]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.352 -0.297  0.055  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.566 -0.208  0.079]\n",
      "tcp_to_goal_pos: [0.214 0.089 0.025]\n",
      "cube_pose: [ 0.372 -0.245  0.02   1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.02   0.052 -0.035]\n",
      "cube_to_goal_pos: [0.194 0.038 0.06 ]\n",
      "bowl_pose: [ 0.566 -0.208  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.214  0.089 -0.025]\n",
      "cube_to_bowl_pos: [0.194 0.038 0.01 ]\n",
      "\n",
      "action: [ 0.54  -0.482 -0.468  0.963]\n",
      "Stepping action ...\n",
      "delta xyz [ 27.00459 -24.10018 -23.38263] gripper_action 5.946446061134338\n",
      "qpos: [-0.537  0.014 -0.157  0.686  0.029  0.609 -2.287  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.327 -0.269  0.076  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.563 -0.209  0.079]\n",
      "tcp_to_goal_pos: [0.236 0.061 0.003]\n",
      "cube_pose: [ 0.354 -0.245  0.025  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.027  0.025 -0.05 ]\n",
      "cube_to_goal_pos: [0.209 0.036 0.054]\n",
      "bowl_pose: [ 0.563 -0.209  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.236  0.061 -0.047]\n",
      "cube_to_bowl_pos: [0.209 0.036 0.004]\n",
      "\n",
      "action: [-0.031  0.538  0.435  0.983]\n",
      "Stepping action ...\n",
      "delta xyz [-1.54775 26.88637 21.74132] gripper_action -2.6885563135147095\n",
      "qpos: [-0.51   0.13  -0.146  0.758  0.057  0.566 -2.27   0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.355 -0.272  0.056  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.562 -0.21   0.079]\n",
      "tcp_to_goal_pos: [0.207 0.062 0.023]\n",
      "cube_pose: [ 0.354 -0.262  0.038  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.001  0.01  -0.018]\n",
      "cube_to_goal_pos: [0.208 0.052 0.042]\n",
      "bowl_pose: [ 0.562 -0.21   0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.207  0.062 -0.027]\n",
      "cube_to_bowl_pos: [ 0.208  0.052 -0.008]\n",
      "\n",
      "action: [-0.023  0.104 -0.957  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [ -1.15919   5.18068 -47.8305 ] gripper_action -10.0\n",
      "qpos: [-0.495  0.029 -0.16   0.802  0.025  0.71  -2.242  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.357 -0.271  0.104  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.561 -0.209  0.078]\n",
      "tcp_to_goal_pos: [ 0.204  0.062 -0.026]\n",
      "cube_pose: [ 0.352 -0.246  0.025  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.005  0.026 -0.078]\n",
      "cube_to_goal_pos: [0.209 0.036 0.053]\n",
      "bowl_pose: [ 0.561 -0.209  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.204  0.062 -0.076]\n",
      "cube_to_bowl_pos: [0.209 0.036 0.003]\n",
      "\n",
      "action: [ 0.091 -0.591  0.974 -0.39 ]\n",
      "Stepping action ...\n",
      "delta xyz [  4.56061 -29.57442  48.71318] gripper_action 587.9000616073608\n",
      "qpos: [-0.497  0.078 -0.187  0.679  0.054  0.54  -2.298  0.014  0.014]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.331 -0.268  0.053  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.56  -0.209  0.079]\n",
      "tcp_to_goal_pos: [0.23  0.06  0.025]\n",
      "cube_pose: [ 0.354 -0.262  0.043  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.024  0.007 -0.011]\n",
      "cube_to_goal_pos: [0.206 0.053 0.036]\n",
      "bowl_pose: [ 0.56  -0.209  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.23   0.06  -0.025]\n",
      "cube_to_bowl_pos: [ 0.206  0.053 -0.014]\n",
      "\n",
      "action: [-0.191  0.994 -0.928  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [ -9.53878  49.70253 -46.42419] gripper_action -10.0\n",
      "qpos: [-0.463  0.089 -0.174  0.872  0.039  0.72  -2.234  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.377 -0.276  0.103  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.563 -0.21   0.08 ]\n",
      "tcp_to_goal_pos: [ 0.186  0.067 -0.023]\n",
      "cube_pose: [ 0.354 -0.248  0.026  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.024  0.028 -0.077]\n",
      "cube_to_goal_pos: [0.21  0.039 0.054]\n",
      "bowl_pose: [ 0.563 -0.21   0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.186  0.067 -0.073]\n",
      "cube_to_bowl_pos: [0.21  0.039 0.004]\n",
      "\n",
      "action: [-0.031 -0.756  0.859 -0.101]\n",
      "Stepping action ...\n",
      "delta xyz [ -1.55339 -37.794    42.95111] gripper_action 463.45171332359314\n",
      "qpos: [-0.495  0.112 -0.193  0.74   0.065  0.568 -2.308  0.02   0.02 ]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.342 -0.279  0.058  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.565 -0.207  0.08 ]\n",
      "tcp_to_goal_pos: [0.223 0.072 0.022]\n",
      "cube_pose: [ 0.354 -0.269  0.048  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.012  0.011 -0.01 ]\n",
      "cube_to_goal_pos: [0.211 0.061 0.032]\n",
      "bowl_pose: [ 0.565 -0.207  0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.223  0.072 -0.028]\n",
      "cube_to_bowl_pos: [ 0.211  0.061 -0.018]\n",
      "\n",
      "action: [ 0.1    0.982 -0.944  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [  4.99205  49.09    -47.19749] gripper_action -10.0\n",
      "qpos: [-0.453  0.101 -0.165  0.903  0.038  0.739 -2.213  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.388 -0.273  0.108  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.563 -0.21   0.08 ]\n",
      "tcp_to_goal_pos: [ 0.175  0.063 -0.028]\n",
      "cube_pose: [ 0.354 -0.25   0.027  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.035  0.023 -0.081]\n",
      "cube_to_goal_pos: [0.21  0.04  0.053]\n",
      "bowl_pose: [ 0.563 -0.21   0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.175  0.063 -0.078]\n",
      "cube_to_bowl_pos: [0.21  0.04  0.003]\n",
      "\n",
      "action: [-0.403 -0.704  0.892  0.335]\n",
      "Stepping action ...\n",
      "delta xyz [-20.13243 -35.2035   44.62316] gripper_action 275.9871855378151\n",
      "qpos: [-0.512  0.159 -0.183  0.818  0.076  0.599 -2.323  0.03   0.03 ]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.356 -0.294  0.062  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.565 -0.211  0.082]\n",
      "tcp_to_goal_pos: [0.209 0.083 0.02 ]\n",
      "cube_pose: [ 0.355 -0.255  0.019  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.001  0.039 -0.043]\n",
      "cube_to_goal_pos: [0.21  0.044 0.063]\n",
      "bowl_pose: [ 0.565 -0.211  0.032  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.209  0.083 -0.03 ]\n",
      "cube_to_bowl_pos: [0.21  0.044 0.013]\n",
      "\n",
      "action: [ 0.56  -0.694 -0.199  0.946]\n",
      "Stepping action ...\n",
      "delta xyz [ 27.98548 -34.7065   -9.94459] gripper_action 13.322631120681763\n",
      "qpos: [-0.502  0.011 -0.195  0.657  0.03   0.582 -2.291  0.043  0.043]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.321 -0.266  0.069  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.561 -0.209  0.079]\n",
      "tcp_to_goal_pos: [0.24  0.057 0.011]\n",
      "cube_pose: [ 0.354 -0.245  0.027  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.033  0.021 -0.042]\n",
      "cube_to_goal_pos: [0.207 0.036 0.053]\n",
      "bowl_pose: [ 0.561 -0.209  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.24   0.057 -0.039]\n",
      "cube_to_bowl_pos: [0.207 0.036 0.003]\n",
      "\n",
      "action: [-0.188  0.641  0.332  0.993]\n",
      "Stepping action ...\n",
      "delta xyz [-9.40814 32.07193 16.60474] gripper_action -6.785818934440613\n",
      "qpos: [-0.485  0.139 -0.179  0.764  0.069  0.563 -2.289  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.354 -0.276  0.054  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.565 -0.208  0.078]\n",
      "tcp_to_goal_pos: [0.211 0.068 0.023]\n",
      "cube_pose: [ 0.355 -0.257  0.036  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.001  0.019 -0.018]\n",
      "cube_to_goal_pos: [0.21  0.049 0.041]\n",
      "bowl_pose: [ 0.565 -0.208  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.211  0.068 -0.027]\n",
      "cube_to_bowl_pos: [ 0.21   0.049 -0.009]\n",
      "\n",
      "action: [-0.098 -0.651 -0.957  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [ -4.89009 -32.54407 -47.84927] gripper_action -9.999589920043945\n",
      "qpos: [-0.5   -0.041 -0.227  0.709  0.011  0.687 -2.304  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.318 -0.279  0.1    0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.564 -0.21   0.079]\n",
      "tcp_to_goal_pos: [ 0.246  0.07  -0.021]\n",
      "cube_pose: [ 0.353 -0.244  0.026  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.035  0.035 -0.074]\n",
      "cube_to_goal_pos: [0.211 0.034 0.053]\n",
      "bowl_pose: [ 0.564 -0.21   0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.246  0.07  -0.071]\n",
      "cube_to_bowl_pos: [0.211 0.034 0.003]\n",
      "\n",
      "action: [ 0.339  0.774  0.92  -0.466]\n",
      "Stepping action ...\n",
      "delta xyz [16.9689  38.69245 45.98482] gripper_action 620.5619817972183\n",
      "qpos: [-0.443  0.128 -0.192  0.755  0.064  0.566 -2.254  0.012  0.012]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.36  -0.264  0.056  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.566 -0.208  0.08 ]\n",
      "tcp_to_goal_pos: [0.206 0.056 0.023]\n",
      "cube_pose: [ 0.354 -0.249  0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.005  0.015 -0.027]\n",
      "cube_to_goal_pos: [0.211 0.04  0.05 ]\n",
      "bowl_pose: [ 0.566 -0.208  0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.206  0.056 -0.027]\n",
      "cube_to_bowl_pos: [ 0.211  0.04  -0.   ]\n",
      "\n",
      "action: [ 0.03  -0.675  0.228  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [  1.47989 -33.77434  11.405  ] gripper_action -9.902426600456238\n",
      "qpos: [-0.475  0.088 -0.203  0.651  0.064  0.502 -2.301  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.327 -0.263  0.043  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.56  -0.206  0.078]\n",
      "tcp_to_goal_pos: [0.233 0.056 0.035]\n",
      "cube_pose: [ 0.355 -0.253  0.036  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.028  0.01  -0.007]\n",
      "cube_to_goal_pos: [0.205 0.047 0.043]\n",
      "bowl_pose: [ 0.56  -0.206  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.233  0.056 -0.015]\n",
      "cube_to_bowl_pos: [ 0.205  0.047 -0.007]\n",
      "\n",
      "action: [-0.149  0.997 -1.     1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [ -7.4651   49.8712  -49.97823] gripper_action -9.993900060653687\n",
      "qpos: [-0.443  0.08  -0.185  0.836  0.038  0.694 -2.225  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.374 -0.269  0.096  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.564 -0.211  0.078]\n",
      "tcp_to_goal_pos: [ 0.19   0.058 -0.018]\n",
      "cube_pose: [ 0.354 -0.248  0.026  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.02   0.021 -0.07 ]\n",
      "cube_to_goal_pos: [0.21  0.037 0.053]\n",
      "bowl_pose: [ 0.564 -0.211  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.19   0.058 -0.068]\n",
      "cube_to_bowl_pos: [0.21  0.037 0.003]\n",
      "\n",
      "action: [ 0.133 -0.793  0.851 -0.242]\n",
      "Stepping action ...\n",
      "delta xyz [  6.62537 -39.62972  42.57354] gripper_action 524.084802865982\n",
      "qpos: [-0.465  0.089 -0.2    0.683  0.059  0.533 -2.283  0.017  0.017]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.336 -0.263  0.051  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.56  -0.212  0.08 ]\n",
      "tcp_to_goal_pos: [0.224 0.051 0.029]\n",
      "cube_pose: [ 0.356 -0.259  0.041  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.02   0.004 -0.009]\n",
      "cube_to_goal_pos: [0.204 0.047 0.039]\n",
      "bowl_pose: [ 0.56  -0.212  0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.224  0.051 -0.021]\n",
      "cube_to_bowl_pos: [ 0.204  0.047 -0.011]\n",
      "\n",
      "action: [-0.165  0.996 -0.978  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [ -8.24156  49.79235 -48.8899 ] gripper_action -10.0\n",
      "qpos: [-0.437  0.093 -0.182  0.876  0.039  0.72  -2.215  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.383 -0.27   0.103  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.563 -0.209  0.078]\n",
      "tcp_to_goal_pos: [ 0.18   0.061 -0.024]\n",
      "cube_pose: [ 0.353 -0.249  0.027  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.03   0.021 -0.076]\n",
      "cube_to_goal_pos: [0.21  0.04  0.051]\n",
      "bowl_pose: [ 0.563 -0.209  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.18   0.061 -0.074]\n",
      "cube_to_bowl_pos: [0.21  0.04  0.001]\n",
      "\n",
      "action: [-0.236 -0.761  0.886  0.114]\n",
      "Stepping action ...\n",
      "delta xyz [-11.79382 -38.05402  44.30922] gripper_action 370.9708468616009\n",
      "qpos: [-0.488  0.134 -0.198  0.765  0.074  0.571 -2.313  0.025  0.025]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.348 -0.283  0.057  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.565 -0.208  0.078]\n",
      "tcp_to_goal_pos: [0.218 0.075 0.022]\n",
      "cube_pose: [ 0.355 -0.27   0.049  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.007  0.013 -0.008]\n",
      "cube_to_goal_pos: [0.21  0.062 0.03 ]\n",
      "bowl_pose: [ 0.565 -0.208  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.218  0.075 -0.028]\n",
      "cube_to_bowl_pos: [ 0.21   0.062 -0.02 ]\n",
      "\n",
      "action: [ 0.073  0.986 -0.951  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [  3.62516  49.31012 -47.54111] gripper_action -10.0\n",
      "qpos: [-0.455  0.126 -0.166  0.932  0.044  0.744 -2.219  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.394 -0.278  0.107  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.562 -0.206  0.077]\n",
      "tcp_to_goal_pos: [ 0.167  0.072 -0.029]\n",
      "cube_pose: [ 0.353 -0.248  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.041  0.03  -0.079]\n",
      "cube_to_goal_pos: [0.209 0.043 0.05 ]\n",
      "bowl_pose: [ 0.562 -0.206  0.027  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.167  0.072 -0.079]\n",
      "cube_to_bowl_pos: [ 0.209  0.043 -0.   ]\n",
      "\n",
      "action: [-0.394 -0.683  0.834  0.192]\n",
      "Stepping action ...\n",
      "delta xyz [-19.71662 -34.16572  41.72415] gripper_action 337.542115598917\n",
      "qpos: [-0.517  0.177 -0.177  0.85   0.078  0.613 -2.322  0.027  0.027]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.363 -0.299  0.064  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.565 -0.208  0.077]\n",
      "tcp_to_goal_pos: [0.202 0.091 0.013]\n",
      "cube_pose: [ 0.35  -0.255  0.024  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.012  0.044 -0.04 ]\n",
      "cube_to_goal_pos: [0.215 0.047 0.054]\n",
      "bowl_pose: [ 0.565 -0.208  0.027  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.202  0.091 -0.037]\n",
      "cube_to_bowl_pos: [0.215 0.047 0.004]\n",
      "\n",
      "action: [ 0.733 -0.815 -0.384  0.833]\n",
      "Stepping action ...\n",
      "delta xyz [ 36.65879 -40.72663 -19.2221 ] gripper_action 61.756815910339355\n",
      "qpos: [-0.499 -0.023 -0.192  0.656  0.017  0.615 -2.272  0.041  0.041]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.321 -0.262  0.08   0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.563 -0.208  0.079]\n",
      "tcp_to_goal_pos: [ 0.242  0.053 -0.   ]\n",
      "cube_pose: [ 0.354 -0.247  0.026  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.033  0.015 -0.054]\n",
      "cube_to_goal_pos: [0.209 0.038 0.053]\n",
      "bowl_pose: [ 0.563 -0.208  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.242  0.053 -0.05 ]\n",
      "cube_to_bowl_pos: [0.209 0.038 0.003]\n",
      "\n",
      "action: [-0.502  0.686  0.976  0.827]\n",
      "Stepping action ...\n",
      "delta xyz [-25.12483  34.2932   48.77522] gripper_action 64.3265563249588\n",
      "qpos: [-0.511  0.221 -0.167  0.797  0.1    0.517 -2.328  0.041  0.041]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.358 -0.288  0.034  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.563 -0.209  0.08 ]\n",
      "tcp_to_goal_pos: [0.205 0.079 0.046]\n",
      "cube_pose: [ 0.38  -0.289  0.068  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.022 -0.001  0.034]\n",
      "cube_to_goal_pos: [0.184 0.08  0.013]\n",
      "bowl_pose: [ 0.563 -0.209  0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.205  0.079 -0.004]\n",
      "cube_to_bowl_pos: [ 0.184  0.08  -0.037]\n",
      "\n",
      "action: [ 1.    1.   -0.95  1.  ]\n",
      "Stepping action ...\n",
      "delta xyz [ 49.97874  49.98509 -47.50903] gripper_action -9.79611337184906\n",
      "qpos: [-0.429  0.133 -0.102  0.859  0.028  0.662 -2.12   0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.405 -0.237  0.082  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.56  -0.208  0.079]\n",
      "tcp_to_goal_pos: [ 0.155  0.029 -0.004]\n",
      "cube_pose: [ 0.354 -0.247  0.027  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.051 -0.01  -0.056]\n",
      "cube_to_goal_pos: [0.206 0.039 0.052]\n",
      "bowl_pose: [ 0.56  -0.208  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.155  0.029 -0.054]\n",
      "cube_to_bowl_pos: [0.206 0.039 0.002]\n",
      "\n",
      "action: [-0.306 -0.898  0.764  0.342]\n",
      "Stepping action ...\n",
      "delta xyz [-15.30024 -44.90121  38.19214] gripper_action 273.01819384098053\n",
      "qpos: [-0.488  0.151 -0.122  0.734  0.055  0.52  -2.224  0.03   0.03 ]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.363 -0.253  0.042  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.564 -0.21   0.078]\n",
      "tcp_to_goal_pos: [0.201 0.043 0.036]\n",
      "cube_pose: [ 0.362 -0.257  0.04   1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.    -0.004 -0.002]\n",
      "cube_to_goal_pos: [0.201 0.047 0.038]\n",
      "bowl_pose: [ 0.564 -0.21   0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.201  0.043 -0.014]\n",
      "cube_to_bowl_pos: [ 0.201  0.047 -0.012]\n",
      "\n",
      "action: [ 0.005  0.992 -0.983  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [  0.23815  49.59572 -49.12907] gripper_action -10.0\n",
      "qpos: [-0.457  0.142 -0.098  0.911  0.029  0.705 -2.144  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.409 -0.252  0.094  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.566 -0.208  0.08 ]\n",
      "tcp_to_goal_pos: [ 0.156  0.044 -0.014]\n",
      "cube_pose: [ 0.351 -0.244  0.025  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.058  0.007 -0.069]\n",
      "cube_to_goal_pos: [0.214 0.036 0.055]\n",
      "bowl_pose: [ 0.566 -0.208  0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.156  0.044 -0.064]\n",
      "cube_to_bowl_pos: [0.214 0.036 0.005]\n",
      "\n",
      "action: [-0.387 -0.918  0.844  0.818]\n",
      "Stepping action ...\n",
      "delta xyz [-19.37028 -45.89123  42.19722] gripper_action 68.39442133903503\n",
      "qpos: [-0.522  0.169 -0.12   0.789  0.059  0.557 -2.258  0.041  0.041]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.366 -0.272  0.05   0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.561 -0.208  0.078]\n",
      "tcp_to_goal_pos: [0.195 0.065 0.028]\n",
      "cube_pose: [ 0.358 -0.267  0.04   1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.007  0.005 -0.01 ]\n",
      "cube_to_goal_pos: [0.203 0.059 0.038]\n",
      "bowl_pose: [ 0.561 -0.208  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.195  0.065 -0.022]\n",
      "cube_to_bowl_pos: [ 0.203  0.059 -0.012]\n",
      "\n",
      "action: [ 0.252  0.799 -0.955  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [ 12.60413  39.94719 -47.74348] gripper_action -10.0\n",
      "qpos: [-0.478  0.127 -0.096  0.909  0.028  0.719 -2.162  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.403 -0.258  0.099  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.565 -0.209  0.08 ]\n",
      "tcp_to_goal_pos: [ 0.162  0.049 -0.02 ]\n",
      "cube_pose: [ 0.353 -0.245  0.025  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.05   0.013 -0.074]\n",
      "cube_to_goal_pos: [0.212 0.037 0.054]\n",
      "bowl_pose: [ 0.565 -0.209  0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.162  0.049 -0.07 ]\n",
      "cube_to_bowl_pos: [0.212 0.037 0.004]\n",
      "\n",
      "action: [-0.384 -0.861  0.853  0.865]\n",
      "Stepping action ...\n",
      "delta xyz [-19.1844  -43.03556  42.63625] gripper_action 47.907723784446716\n",
      "qpos: [-0.534  0.161 -0.124  0.796  0.058  0.573 -2.273  0.042  0.042]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.362 -0.279  0.055  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.563 -0.21   0.079]\n",
      "tcp_to_goal_pos: [0.2   0.069 0.024]\n",
      "cube_pose: [ 0.356 -0.252  0.02   1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.007  0.027 -0.035]\n",
      "cube_to_goal_pos: [0.207 0.042 0.06 ]\n",
      "bowl_pose: [ 0.563 -0.21   0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.2    0.069 -0.026]\n",
      "cube_to_bowl_pos: [0.207 0.042 0.01 ]\n",
      "\n",
      "action: [ 0.644 -0.893 -0.812  0.995]\n",
      "Stepping action ...\n",
      "delta xyz [ 32.18284 -44.64399 -40.59978] gripper_action -7.658340930938721\n",
      "qpos: [-0.505 -0.098 -0.163  0.617 -0.006  0.65  -2.232  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.316 -0.245  0.092  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.564 -0.21   0.079]\n",
      "tcp_to_goal_pos: [ 0.248  0.035 -0.013]\n",
      "cube_pose: [ 0.353 -0.247  0.027  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.037 -0.002 -0.065]\n",
      "cube_to_goal_pos: [0.211 0.037 0.052]\n",
      "bowl_pose: [ 0.564 -0.21   0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.248  0.035 -0.063]\n",
      "cube_to_bowl_pos: [0.211 0.037 0.002]\n",
      "\n",
      "action: [-0.824  0.747  0.992 -0.324]\n",
      "Stepping action ...\n",
      "delta xyz [-41.22472  37.34927  49.59563] gripper_action 559.1368868947029\n",
      "qpos: [-0.504  0.186 -0.179  0.794  0.088  0.549 -2.322  0.015  0.015]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.356 -0.288  0.046  0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.563 -0.207  0.08 ]\n",
      "tcp_to_goal_pos: [0.208 0.081 0.034]\n",
      "cube_pose: [ 0.346 -0.256  0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [-0.01   0.032 -0.016]\n",
      "cube_to_goal_pos: [0.218 0.049 0.05 ]\n",
      "bowl_pose: [ 0.563 -0.207  0.03   1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.208  0.081 -0.016]\n",
      "cube_to_bowl_pos: [0.218 0.049 0.   ]\n",
      "\n",
      "action: [ 0.252 -0.78  -0.733  1.   ]\n",
      "Stepping action ...\n",
      "delta xyz [ 12.58741 -38.99904 -36.65308] gripper_action -9.997565150260925\n",
      "qpos: [-0.514 -0.013 -0.21   0.669  0.023  0.619 -2.311  0.044  0.044]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.315 -0.274  0.08   0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.566 -0.208  0.079]\n",
      "tcp_to_goal_pos: [ 0.251  0.066 -0.   ]\n",
      "cube_pose: [ 0.354 -0.248  0.028  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [ 0.039  0.027 -0.052]\n",
      "cube_to_goal_pos: [0.212 0.04  0.052]\n",
      "bowl_pose: [ 0.566 -0.208  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.251  0.066 -0.05 ]\n",
      "cube_to_bowl_pos: [0.212 0.04  0.002]\n",
      "\n",
      "action: [0.11  0.788 0.843 0.467]\n",
      "Stepping action ...\n",
      "delta xyz [ 5.51887 39.39963 42.1506 ] gripper_action 219.0527480840683\n",
      "qpos: [-0.478  0.172 -0.171  0.752  0.081  0.52  -2.283  0.033  0.033]\n",
      "qvel: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "base_pose: [0. 0. 0. 1. 0. 0. 0.]\n",
      "tcp_pose: [ 0.356 -0.27   0.04   0.031  0.707  0.706  0.01 ]\n",
      "goal_pos: [ 0.566 -0.209  0.079]\n",
      "tcp_to_goal_pos: [0.21  0.061 0.039]\n",
      "cube_pose: [ 0.358 -0.265  0.045  1.     0.     0.     0.   ]\n",
      "tcp_to_cube_pos: [0.002 0.005 0.005]\n",
      "cube_to_goal_pos: [0.208 0.056 0.034]\n",
      "bowl_pose: [ 0.566 -0.209  0.029  1.     0.     0.     0.   ]\n",
      "tcp_to_bowl_pos: [ 0.21   0.061 -0.011]\n",
      "cube_to_bowl_pos: [ 0.208  0.056 -0.016]\n",
      "\n",
      "action: [ 0.247  0.999 -0.998  1.   ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "\n",
    "from real_robot.agents.xarm import XArm7\n",
    "\n",
    "robot = XArm7()\n",
    "\n",
    "from pyrl.utils.lib3d import np2pcd\n",
    "def _process_pts(\n",
    "        pts_lst,\n",
    "        voxel_downsample_size, nb_neighbors, std_ratio\n",
    "    ):\n",
    "        from pyrl.utils.lib3d import np2pcd\n",
    "\n",
    "        if isinstance(pts_lst, np.ndarray):\n",
    "            pts_lst = [pts_lst]\n",
    "\n",
    "        ret_pts_lst = []\n",
    "        for pts in pts_lst:\n",
    "            pcd = np2pcd(pts)\n",
    "            if voxel_downsample_size is not None:\n",
    "                pcd = pcd.voxel_down_sample(voxel_size=voxel_downsample_size)\n",
    "            pcd_filter, inlier_inds = pcd.remove_statistical_outlier(\n",
    "                nb_neighbors=nb_neighbors, std_ratio=std_ratio\n",
    "            )\n",
    "            ret_pts_lst.append(np.asarray(pcd_filter.points))\n",
    "\n",
    "        if len(ret_pts_lst) == 1:\n",
    "            return ret_pts_lst[0]\n",
    "\n",
    "        return ret_pts_lst\n",
    "\n",
    "from collections import OrderedDict\n",
    "def get_obs(object_filt_pcds):\n",
    "    cube_pts = object_filt_pcds[env_object_texts[0]]\n",
    "    bowl_pts = object_filt_pcds[env_object_texts[1]]\n",
    "\n",
    "    # Extract cube position\n",
    "    # cube_pos = np.mean(cube_pts, axis=0)\n",
    "    # bowl_pos = np.mean(bowl_pts, axis=0)\n",
    "    # Extract bbox from object_pts\n",
    "    bowl_mins, bowl_maxs = bowl_pts.min(0), bowl_pts.max(0)\n",
    "    cube_mins, cube_maxs = cube_pts.min(0), cube_pts.max(0)\n",
    "\n",
    "    cube_pos = np.mean([cube_mins, cube_maxs], axis=0)\n",
    "    bowl_pos = np.mean([bowl_mins, bowl_maxs], axis=0)\n",
    "\n",
    "    goal_pos = bowl_pos + [0, 0, 0.05]\n",
    "    tcp_pose = robot.get_tcp_pose()\n",
    "\n",
    "    obs = OrderedDict()\n",
    "    obs[\"agent\"] = OrderedDict(\n",
    "        qpos=robot.get_qpos(),\n",
    "        qvel=robot.get_qvel(),\n",
    "        base_pose=np.array([0., 0, 0, 1, 0, 0, 0]),\n",
    "    )\n",
    "    obs[\"extra\"] = OrderedDict(\n",
    "        tcp_pose=tcp_pose,\n",
    "        goal_pos=goal_pos,\n",
    "        tcp_to_goal_pos=goal_pos - tcp_pose[:3],\n",
    "        cube_pose=np.hstack([cube_pos, [1, 0, 0, 0]]),\n",
    "        tcp_to_cube_pos=cube_pos - tcp_pose[:3],\n",
    "        cube_to_goal_pos=goal_pos - cube_pos,\n",
    "        bowl_pose=np.hstack([bowl_pos, [1, 0, 0, 0]]),\n",
    "        tcp_to_bowl_pos=bowl_pos - tcp_pose[:3],\n",
    "        cube_to_bowl_pos=bowl_pos - cube_pos,\n",
    "    )\n",
    "\n",
    "    with np.printoptions(suppress=True, precision=3):\n",
    "        for k, v in obs.items():\n",
    "            if isinstance(v, dict):\n",
    "                for kk, vv in v.items():\n",
    "                    print(f\"{kk}: {vv}\")\n",
    "\n",
    "    from mani_skill2.utils.common import flatten_state_dict\n",
    "    obs = flatten_state_dict(obs)\n",
    "    return obs\n",
    "\n",
    "cv2.namedWindow(\"Color / Depth\")\n",
    "cv2.imshow(\"Color / Depth\", color_image)\n",
    "cv2.waitKey(1)\n",
    "\n",
    "voxel_downsample_size, nb_neighbors, std_ratio = 0.005, 20, 0.005\n",
    "\n",
    "pcd_vis = o3d.visualization.Visualizer()\n",
    "pcd_vis.create_window(\"Point Cloud\", width=1280, height=720)\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(world_xyz_image.reshape(-1, 3))\n",
    "pcd.colors = o3d.utility.Vector3dVector(color_image.reshape(-1, 3) / 255.0)\n",
    "coord_frame = o3d.geometry.TriangleMesh().create_coordinate_frame()\n",
    "pcd_vis.add_geometry(coord_frame)\n",
    "pcd_vis.add_geometry(pcd)\n",
    "\n",
    "\n",
    "frame_i = 0\n",
    "ret_dict = grounded_sam_track.predict_and_track_batch([color_image], [frame_i], env_object_texts)\n",
    "ret_dict[\"pred_masks\"] = np.stack(ret_dict[\"pred_masks\"], axis=0)\n",
    "pred_masks = ret_dict[\"pred_masks\"][0]  # [H, W]\n",
    "\n",
    "object_pcds = {}\n",
    "object_filt_pcds = {}\n",
    "for i, object_text in enumerate(env_object_texts):\n",
    "    object_pcd = world_xyz_image[pred_masks == i+1]\n",
    "    object_pcds[object_text] = object_pcd\n",
    "    object_filt_pcds[object_text] = _process_pts(\n",
    "        object_pcd, voxel_downsample_size, nb_neighbors, std_ratio\n",
    "    )\n",
    "\n",
    "cube_aabb = np2pcd(object_filt_pcds[\"red cube\"]).get_axis_aligned_bounding_box()\n",
    "bowl_aabb = np2pcd(object_filt_pcds[\"green bowl\"]).get_axis_aligned_bounding_box()\n",
    "pcd_vis.add_geometry(cube_aabb)\n",
    "pcd_vis.add_geometry(bowl_aabb)\n",
    "\n",
    "obs = get_obs(object_filt_pcds)\n",
    "action = agent(torch.Tensor(obs)).cpu().numpy()\n",
    "with np.printoptions(suppress=True, precision=3):\n",
    "    print(f\"\\naction: {action}\")\n",
    "while True:\n",
    "    pcd_vis.poll_events()\n",
    "    pcd_vis.update_renderer()\n",
    "\n",
    "    depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "    cv2.imshow(\"Color / Depth\", np.hstack([cv2.cvtColor(color_image, cv2.COLOR_RGB2BGR), depth_colormap]))\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:  # ESC\n",
    "        break\n",
    "    elif key == ord('s'):\n",
    "        print(\"Stepping action ...\")\n",
    "        robot.set_action(action, wait=True, action_scale=50)\n",
    "\n",
    "        color_image, depth_image, intr_array = realsense.capture()\n",
    "        xyz_image = depth2xyz(depth_image, *intr_array)\n",
    "        world_xyz_image = transform_points(xyz_image, camera_pose)\n",
    "        pcd.points = o3d.utility.Vector3dVector(world_xyz_image.reshape(-1, 3))\n",
    "        pcd.colors = o3d.utility.Vector3dVector(color_image.reshape(-1, 3) / 255.0)\n",
    "\n",
    "        pcd_vis.update_geometry(pcd)\n",
    "\n",
    "        frame_i += 1\n",
    "        ret_dict = grounded_sam_track.predict_and_track_batch([color_image], [frame_i], env_object_texts)\n",
    "        ret_dict[\"pred_masks\"] = np.stack(ret_dict[\"pred_masks\"], axis=0)\n",
    "        pred_masks = ret_dict[\"pred_masks\"][0]  # [H, W]\n",
    "\n",
    "        object_pcds = {}\n",
    "        object_filt_pcds = {}\n",
    "        for i, object_text in enumerate(env_object_texts):\n",
    "            object_pcd = world_xyz_image[pred_masks == i+1]\n",
    "            object_pcds[object_text] = object_pcd\n",
    "            object_filt_pcds[object_text] = _process_pts(\n",
    "                object_pcd, voxel_downsample_size, nb_neighbors, std_ratio\n",
    "            )\n",
    "\n",
    "        cube_aabb_new = np2pcd(object_filt_pcds[\"red cube\"]).get_axis_aligned_bounding_box()\n",
    "        bowl_aabb_new = np2pcd(object_filt_pcds[\"green bowl\"]).get_axis_aligned_bounding_box()\n",
    "        cube_aabb.max_bound = cube_aabb_new.max_bound\n",
    "        cube_aabb.min_bound = cube_aabb_new.min_bound\n",
    "        bowl_aabb.max_bound = bowl_aabb_new.max_bound\n",
    "        bowl_aabb.min_bound = bowl_aabb_new.min_bound\n",
    "        pcd_vis.update_geometry(cube_aabb)\n",
    "        pcd_vis.update_geometry(bowl_aabb)\n",
    "\n",
    "        obs = get_obs(object_filt_pcds)\n",
    "        action = agent(torch.Tensor(obs)).cpu().numpy()\n",
    "        with np.printoptions(suppress=True, precision=3):\n",
    "            print(f\"\\naction: {action}\")\n",
    "    elif key == ord('r'):\n",
    "        robot.reset()\n",
    "\n",
    "        color_image, depth_image, intr_array = realsense.capture()\n",
    "        xyz_image = depth2xyz(depth_image, *intr_array)\n",
    "        world_xyz_image = transform_points(xyz_image, camera_pose)\n",
    "        pcd.points = o3d.utility.Vector3dVector(world_xyz_image.reshape(-1, 3))\n",
    "        pcd.colors = o3d.utility.Vector3dVector(color_image.reshape(-1, 3) / 255.0)\n",
    "\n",
    "        pcd_vis.update_geometry(pcd)\n",
    "\n",
    "        frame_i += 1\n",
    "        ret_dict = grounded_sam_track.predict_and_track_batch([color_image], [frame_i], env_object_texts)\n",
    "        ret_dict[\"pred_masks\"] = np.stack(ret_dict[\"pred_masks\"], axis=0)\n",
    "        pred_masks = ret_dict[\"pred_masks\"][0]  # [H, W]\n",
    "\n",
    "        object_pcds = {}\n",
    "        object_filt_pcds = {}\n",
    "        for i, object_text in enumerate(env_object_texts):\n",
    "            object_pcd = world_xyz_image[pred_masks == i+1]\n",
    "            object_pcds[object_text] = object_pcd\n",
    "            object_filt_pcds[object_text] = _process_pts(\n",
    "                object_pcd, voxel_downsample_size, nb_neighbors, std_ratio\n",
    "            )\n",
    "\n",
    "        cube_aabb_new = np2pcd(object_filt_pcds[\"red cube\"]).get_axis_aligned_bounding_box()\n",
    "        bowl_aabb_new = np2pcd(object_filt_pcds[\"green bowl\"]).get_axis_aligned_bounding_box()\n",
    "        cube_aabb.max_bound = cube_aabb_new.max_bound\n",
    "        cube_aabb.min_bound = cube_aabb_new.min_bound\n",
    "        bowl_aabb.max_bound = bowl_aabb_new.max_bound\n",
    "        bowl_aabb.min_bound = bowl_aabb_new.min_bound\n",
    "        pcd_vis.update_geometry(cube_aabb)\n",
    "        pcd_vis.update_geometry(bowl_aabb)\n",
    "\n",
    "        obs = get_obs(object_filt_pcds)\n",
    "        action = agent(torch.Tensor(obs)).cpu().numpy()\n",
    "        with np.printoptions(suppress=True, precision=3):\n",
    "            print(f\"\\naction: {action}\")\n",
    "    elif key == ord('c'):\n",
    "        robot.arm.get_err_warn_code(show=True)\n",
    "        robot.arm.clean_warn()\n",
    "        robot.arm.clean_error()\n",
    "        robot.arm.motion_enable(enable=True)\n",
    "        robot.arm.set_state(state=0)\n",
    "        robot.arm.set_mode(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "pcd_vis.destroy_window()\n",
    "del realsense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.32831, -0.01156, -0.01011,  0.0036 , -0.7189 , -0.69509,\n",
       "        0.00473], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robot.get_tcp_pose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-05-16 21:37:02.104] [svulkan2] [warning] A second renderer will share the same internal context with the first one. Arguments passed to constructor will be ignored.\n"
     ]
    }
   ],
   "source": [
    "import mani_skill2.envs\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "env = gym.make(\"PlaceCubeInBowlXArm-v5\", control_mode=\"pd_ee_delta_pos\",\n",
    "                remove_obs_extra=[\"cube_bbox\",\"bowl_bbox\"])\n",
    "env._max_episode_steps = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W] Mouse not available\n",
      "Stepping with action [-0.99154 -0.99463  0.84437 -0.79757]\n",
      "Stepping with action [-0.99911 -0.99794  0.71402 -0.5568 ]\n",
      "Stepping with action [-0.99321 -0.9906   0.74618 -0.76542]\n",
      "Stepping with action [-0.99212  0.35183  0.92736 -0.86966]\n",
      "Stepping with action [-0.99995  0.73728  0.19965 -0.90442]\n",
      "Stepping with action [-0.9987   0.19392  0.97342 -0.44084]\n",
      "Stepping with action [-0.9753   0.22705  0.74432  0.99984]\n",
      "Stepping with action [ 0.99954  0.98037 -0.99436  0.98153]\n",
      "Stepping with action [ 0.99961  0.17239 -0.97624  0.99058]\n",
      "Stepping with action [ 0.99844  0.08987 -0.73548  0.99543]\n",
      "Stepping with action [ 0.99972 -0.45171  0.93234  0.9974 ]\n",
      "Stepping with action [ 0.83907 -0.61358  0.96607 -0.28416]\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset(seed=0)\n",
    "\n",
    "env.render(\"human\")\n",
    "env.unwrapped._viewer.toggle_pause(True)\n",
    "\n",
    "while True:\n",
    "    env.render(\"human\")\n",
    "    action = agent(torch.Tensor(obs)).cpu().numpy()\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    print(f\"Stepping with action {action}\")\n",
    "    if done:\n",
    "        print(\"Success\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
