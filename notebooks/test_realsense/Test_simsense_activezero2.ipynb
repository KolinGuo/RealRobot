{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['60cm_images',\n",
       " '8cm_images',\n",
       " '45cm_max_power_images',\n",
       " '45cm_images',\n",
       " '8cm_max_power_images',\n",
       " '30cm_images',\n",
       " '15cm_max_power_images',\n",
       " '60cm_max_power_images',\n",
       " '30cm_max_power_images',\n",
       " '15cm_images']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from sapien.core import Pose\n",
    "\n",
    "from real_robot.utils.visualization import Visualizer\n",
    "from real_robot.sensors.simsense_depth import SimsenseDepth\n",
    "from active_zero2.models.cgi_stereo.cgi_stereo import CGI_Stereo\n",
    "\n",
    "data_dir = Path(\"capture\").resolve()\n",
    "image_paths = [p for p in data_dir.glob(\"*_images.npz\") if \"unaligned\" not in p.name]  # all aligned images\n",
    "\n",
    "# ----- ActiveZero++ ----- #\n",
    "#ckpt_path = '/rl_benchmark/activezero2/model.pth'\n",
    "ckpt_path = '/rl_benchmark/activezero2/model_oct19_veryclose.pth'\n",
    "img_resize = (424, 240)\n",
    "device = 'cuda:0'\n",
    "disp_conf_topk = 2\n",
    "disp_conf_thres = 0.8 # 0.95\n",
    "MAX_DISP = 256\n",
    "\n",
    "model = CGI_Stereo(maxdisp=MAX_DISP)\n",
    "model.load_state_dict(torch.load(ckpt_path)['model'])\n",
    "model = model.to(device)\n",
    "\n",
    "def preprocess_image(image: np.ndarray) -> torch.Tensor:\n",
    "    img_L = cv2.resize((image / 255.0).astype(np.float32), img_resize, interpolation=cv2.INTER_CUBIC)\n",
    "    return torch.from_numpy(img_L).to(device)[None, None, ...]  # [1, 1, *img_resize]\n",
    "\n",
    "# ----- Simsense ----- #\n",
    "image_path = image_paths[0]\n",
    "images = np.load(image_path)\n",
    "params = np.load(image_path.parent / image_path.name.replace(\"images\", \"params\"))\n",
    "\n",
    "ir_shape = images[\"ir_l\"].shape\n",
    "assert images[\"ir_r\"].shape == ir_shape, f'Mismatched IR shape: left={ir_shape}, right={images[\"ir_r\"].shape}'\n",
    "k_rgb = params[\"intrinsic_cv\"]\n",
    "\n",
    "k_irl = k_irr = np.array([[430.13980103,   0.        , 425.1628418 ],\n",
    "                          [  0.        , 430.13980103, 235.27651978],\n",
    "                          [  0.        ,   0.        ,   1.        ]])\n",
    "\n",
    "# rsdevice.all_extrinsics[\"Infrared 1=>Infrared 2\"]\n",
    "T_irr_irl = np.array([[ 1.       ,  0.       ,  0.       , -0.0501572],\n",
    "                      [ 0.       ,  1.       ,  0.       ,  0.       ],\n",
    "                      [ 0.       ,  0.       ,  1.       ,  0.       ],\n",
    "                      [ 0.       ,  0.       ,  0.       ,  1.       ]])\n",
    "# rsdevice.all_extrinsics[\"Infrared 1=>Color\"]\n",
    "T_rgb_irl = np.array([[ 9.99862015e-01,  1.34780351e-02,  9.70994867e-03, 1.48976548e-02],\n",
    "                      [-1.35059441e-02,  9.99904811e-01,  2.81448336e-03, 1.15314942e-05],\n",
    "                      [-9.67109110e-03, -2.94523709e-03,  9.99948919e-01, 1.56505470e-04],\n",
    "                      [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, 1.00000000e+00]])\n",
    "\n",
    "depth_engine = SimsenseDepth(\n",
    "    ir_shape[::-1], k_l=k_irl, k_r=k_irr, l2r=T_irr_irl, k_rgb=k_rgb,\n",
    "    rgb_size=images[\"rgb\"].shape[1::-1], l2rgb=T_rgb_irl,\n",
    "    max_disp=1024, median_filter_size=3, depth_dilation=True\n",
    ")\n",
    "[p.stem for p in image_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-10-20 17:47:15,471] [CV2Visualizer] [cv2_visualizer.py:162] [INFO] Running <CV2Visualizer: Images> as a separate process\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEngine (64 bits) created at 0x55628956ad10 (threading is enabled)\n",
      "FEngine resolved backend: OpenGL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-10-20 17:47:17,745] [O3DGUIVisualizer] [o3d_gui_visualizer.py:1579] [INFO] Running <O3DGUIVisualizer: Point Clouds> as a separate process\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['vis_activezero2|15cm_hand_camera_color',\n",
       " 'vis_activezero2|15cm_hand_camera_depth',\n",
       " 'vis_activezero2|15cm_hand_camera_intr',\n",
       " 'vis_activezero2|15cm_hand_camera_pose',\n",
       " 'vis_activezero2|15cm_max_power_hand_camera_color',\n",
       " 'vis_activezero2|15cm_max_power_hand_camera_depth',\n",
       " 'vis_activezero2|15cm_max_power_hand_camera_intr',\n",
       " 'vis_activezero2|15cm_max_power_hand_camera_pose',\n",
       " 'vis_activezero2|30cm_hand_camera_color',\n",
       " 'vis_activezero2|30cm_hand_camera_depth',\n",
       " 'vis_activezero2|30cm_hand_camera_intr',\n",
       " 'vis_activezero2|30cm_hand_camera_pose',\n",
       " 'vis_activezero2|30cm_max_power_hand_camera_color',\n",
       " 'vis_activezero2|30cm_max_power_hand_camera_depth',\n",
       " 'vis_activezero2|30cm_max_power_hand_camera_intr',\n",
       " 'vis_activezero2|30cm_max_power_hand_camera_pose',\n",
       " 'vis_activezero2|45cm_hand_camera_color',\n",
       " 'vis_activezero2|45cm_hand_camera_depth',\n",
       " 'vis_activezero2|45cm_hand_camera_intr',\n",
       " 'vis_activezero2|45cm_hand_camera_pose',\n",
       " 'vis_activezero2|45cm_max_power_hand_camera_color',\n",
       " 'vis_activezero2|45cm_max_power_hand_camera_depth',\n",
       " 'vis_activezero2|45cm_max_power_hand_camera_intr',\n",
       " 'vis_activezero2|45cm_max_power_hand_camera_pose',\n",
       " 'vis_activezero2|60cm_hand_camera_color',\n",
       " 'vis_activezero2|60cm_hand_camera_depth',\n",
       " 'vis_activezero2|60cm_hand_camera_intr',\n",
       " 'vis_activezero2|60cm_hand_camera_pose',\n",
       " 'vis_activezero2|60cm_max_power_hand_camera_color',\n",
       " 'vis_activezero2|60cm_max_power_hand_camera_depth',\n",
       " 'vis_activezero2|60cm_max_power_hand_camera_intr',\n",
       " 'vis_activezero2|60cm_max_power_hand_camera_pose',\n",
       " 'vis_activezero2|8cm_hand_camera_color',\n",
       " 'vis_activezero2|8cm_hand_camera_depth',\n",
       " 'vis_activezero2|8cm_hand_camera_intr',\n",
       " 'vis_activezero2|8cm_hand_camera_pose',\n",
       " 'vis_activezero2|8cm_max_power_hand_camera_color',\n",
       " 'vis_activezero2|8cm_max_power_hand_camera_depth',\n",
       " 'vis_activezero2|8cm_max_power_hand_camera_intr',\n",
       " 'vis_activezero2|8cm_max_power_hand_camera_pose',\n",
       " 'vis_rs|15cm_hand_camera_color',\n",
       " 'vis_rs|15cm_hand_camera_depth',\n",
       " 'vis_rs|15cm_hand_camera_infrared_1',\n",
       " 'vis_rs|15cm_hand_camera_infrared_2',\n",
       " 'vis_rs|15cm_hand_camera_intr',\n",
       " 'vis_rs|15cm_hand_camera_pose',\n",
       " 'vis_rs|15cm_max_power_hand_camera_color',\n",
       " 'vis_rs|15cm_max_power_hand_camera_depth',\n",
       " 'vis_rs|15cm_max_power_hand_camera_infrared_1',\n",
       " 'vis_rs|15cm_max_power_hand_camera_infrared_2',\n",
       " 'vis_rs|15cm_max_power_hand_camera_intr',\n",
       " 'vis_rs|15cm_max_power_hand_camera_pose',\n",
       " 'vis_rs|30cm_hand_camera_color',\n",
       " 'vis_rs|30cm_hand_camera_depth',\n",
       " 'vis_rs|30cm_hand_camera_infrared_1',\n",
       " 'vis_rs|30cm_hand_camera_infrared_2',\n",
       " 'vis_rs|30cm_hand_camera_intr',\n",
       " 'vis_rs|30cm_hand_camera_pose',\n",
       " 'vis_rs|30cm_max_power_hand_camera_color',\n",
       " 'vis_rs|30cm_max_power_hand_camera_depth',\n",
       " 'vis_rs|30cm_max_power_hand_camera_infrared_1',\n",
       " 'vis_rs|30cm_max_power_hand_camera_infrared_2',\n",
       " 'vis_rs|30cm_max_power_hand_camera_intr',\n",
       " 'vis_rs|30cm_max_power_hand_camera_pose',\n",
       " 'vis_rs|45cm_hand_camera_color',\n",
       " 'vis_rs|45cm_hand_camera_depth',\n",
       " 'vis_rs|45cm_hand_camera_infrared_1',\n",
       " 'vis_rs|45cm_hand_camera_infrared_2',\n",
       " 'vis_rs|45cm_hand_camera_intr',\n",
       " 'vis_rs|45cm_hand_camera_pose',\n",
       " 'vis_rs|45cm_max_power_hand_camera_color',\n",
       " 'vis_rs|45cm_max_power_hand_camera_depth',\n",
       " 'vis_rs|45cm_max_power_hand_camera_infrared_1',\n",
       " 'vis_rs|45cm_max_power_hand_camera_infrared_2',\n",
       " 'vis_rs|45cm_max_power_hand_camera_intr',\n",
       " 'vis_rs|45cm_max_power_hand_camera_pose',\n",
       " 'vis_rs|60cm_hand_camera_color',\n",
       " 'vis_rs|60cm_hand_camera_depth',\n",
       " 'vis_rs|60cm_hand_camera_infrared_1',\n",
       " 'vis_rs|60cm_hand_camera_infrared_2',\n",
       " 'vis_rs|60cm_hand_camera_intr',\n",
       " 'vis_rs|60cm_hand_camera_pose',\n",
       " 'vis_rs|60cm_max_power_hand_camera_color',\n",
       " 'vis_rs|60cm_max_power_hand_camera_depth',\n",
       " 'vis_rs|60cm_max_power_hand_camera_infrared_1',\n",
       " 'vis_rs|60cm_max_power_hand_camera_infrared_2',\n",
       " 'vis_rs|60cm_max_power_hand_camera_intr',\n",
       " 'vis_rs|60cm_max_power_hand_camera_pose',\n",
       " 'vis_rs|8cm_hand_camera_color',\n",
       " 'vis_rs|8cm_hand_camera_depth',\n",
       " 'vis_rs|8cm_hand_camera_infrared_1',\n",
       " 'vis_rs|8cm_hand_camera_infrared_2',\n",
       " 'vis_rs|8cm_hand_camera_intr',\n",
       " 'vis_rs|8cm_hand_camera_pose',\n",
       " 'vis_rs|8cm_max_power_hand_camera_color',\n",
       " 'vis_rs|8cm_max_power_hand_camera_depth',\n",
       " 'vis_rs|8cm_max_power_hand_camera_infrared_1',\n",
       " 'vis_rs|8cm_max_power_hand_camera_infrared_2',\n",
       " 'vis_rs|8cm_max_power_hand_camera_intr',\n",
       " 'vis_rs|8cm_max_power_hand_camera_pose',\n",
       " 'vis_simsense|15cm_hand_camera_color',\n",
       " 'vis_simsense|15cm_hand_camera_depth',\n",
       " 'vis_simsense|15cm_hand_camera_intr',\n",
       " 'vis_simsense|15cm_hand_camera_pose',\n",
       " 'vis_simsense|15cm_max_power_hand_camera_color',\n",
       " 'vis_simsense|15cm_max_power_hand_camera_depth',\n",
       " 'vis_simsense|15cm_max_power_hand_camera_intr',\n",
       " 'vis_simsense|15cm_max_power_hand_camera_pose',\n",
       " 'vis_simsense|30cm_hand_camera_color',\n",
       " 'vis_simsense|30cm_hand_camera_depth',\n",
       " 'vis_simsense|30cm_hand_camera_intr',\n",
       " 'vis_simsense|30cm_hand_camera_pose',\n",
       " 'vis_simsense|30cm_max_power_hand_camera_color',\n",
       " 'vis_simsense|30cm_max_power_hand_camera_depth',\n",
       " 'vis_simsense|30cm_max_power_hand_camera_intr',\n",
       " 'vis_simsense|30cm_max_power_hand_camera_pose',\n",
       " 'vis_simsense|45cm_hand_camera_color',\n",
       " 'vis_simsense|45cm_hand_camera_depth',\n",
       " 'vis_simsense|45cm_hand_camera_intr',\n",
       " 'vis_simsense|45cm_hand_camera_pose',\n",
       " 'vis_simsense|45cm_max_power_hand_camera_color',\n",
       " 'vis_simsense|45cm_max_power_hand_camera_depth',\n",
       " 'vis_simsense|45cm_max_power_hand_camera_intr',\n",
       " 'vis_simsense|45cm_max_power_hand_camera_pose',\n",
       " 'vis_simsense|60cm_hand_camera_color',\n",
       " 'vis_simsense|60cm_hand_camera_depth',\n",
       " 'vis_simsense|60cm_hand_camera_intr',\n",
       " 'vis_simsense|60cm_hand_camera_pose',\n",
       " 'vis_simsense|60cm_max_power_hand_camera_color',\n",
       " 'vis_simsense|60cm_max_power_hand_camera_depth',\n",
       " 'vis_simsense|60cm_max_power_hand_camera_intr',\n",
       " 'vis_simsense|60cm_max_power_hand_camera_pose',\n",
       " 'vis_simsense|8cm_hand_camera_color',\n",
       " 'vis_simsense|8cm_hand_camera_depth',\n",
       " 'vis_simsense|8cm_hand_camera_intr',\n",
       " 'vis_simsense|8cm_hand_camera_pose',\n",
       " 'vis_simsense|8cm_max_power_hand_camera_color',\n",
       " 'vis_simsense|8cm_max_power_hand_camera_depth',\n",
       " 'vis_simsense|8cm_max_power_hand_camera_intr',\n",
       " 'vis_simsense|8cm_max_power_hand_camera_pose']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_dict = {}\n",
    "\n",
    "for image_path in image_paths:\n",
    "    images = np.load(image_path)\n",
    "    params = np.load(image_path.parent / image_path.name.replace(\"images\", \"params\"))\n",
    "\n",
    "    tag = image_path.stem.replace(\"_images\", \"\")\n",
    "    pose_world_camCV = Pose.from_transformation_matrix(params[\"cam2world_cv\"])\n",
    "\n",
    "    # RS capture\n",
    "    obs_dict[f\"vis_rs|{tag}_hand_camera_color\"] = images[\"rgb\"]\n",
    "    obs_dict[f\"vis_rs|{tag}_hand_camera_depth\"] = images[\"depth\"]\n",
    "    obs_dict[f\"vis_rs|{tag}_hand_camera_intr\"] = params[\"intrinsic_cv\"]\n",
    "    obs_dict[f\"vis_rs|{tag}_hand_camera_infrared_1\"] = images[\"ir_l\"]\n",
    "    obs_dict[f\"vis_rs|{tag}_hand_camera_infrared_2\"] = images[\"ir_r\"]\n",
    "    obs_dict[f\"vis_rs|{tag}_hand_camera_pose\"] = pose_world_camCV\n",
    "\n",
    "    # ----- ActiveZero++ ----- #\n",
    "    orig_h, orig_w = images[\"ir_l\"].shape\n",
    "    with torch.no_grad():\n",
    "        pred_dict = model({'img_l': preprocess_image(images[\"ir_l\"]),\n",
    "                           'img_r': preprocess_image(images[\"ir_r\"])})\n",
    "        torch.cuda.synchronize()\n",
    "    for k in pred_dict:\n",
    "        pred_dict[k] = pred_dict[k].detach().cpu().numpy()\n",
    "\n",
    "    disparity = pred_dict['pred_orig'] # [1, H, W]\n",
    "    disparity = disparity.squeeze() # [H, W]\n",
    "    disparity_probs = pred_dict['cost_prob'].squeeze() # [1, disp//4, H, W]\n",
    "    top_disparity_prob_idx = np.argpartition(-disparity_probs, disp_conf_topk, axis=0)[:disp_conf_topk, :, :]\n",
    "    disparity_confidence = np.take_along_axis(disparity_probs, top_disparity_prob_idx, axis=0).sum(axis=0) # [H, W]\n",
    "    disparity_conf_mask = disparity_confidence > disp_conf_thres\n",
    "\n",
    "    # disparity => depth\n",
    "    focal_length = k_irl[0, 0] * img_resize[0] / orig_w\n",
    "    baseline = np.linalg.norm(T_irr_irl[:3, -1])\n",
    "    depth = focal_length * baseline / (disparity + 1e-5)\n",
    "    # filter out depth\n",
    "    depth[~disparity_conf_mask] = 0.0\n",
    "\n",
    "    # Upsample predicted depth image\n",
    "    depth = cv2.resize(depth, images[\"ir_l\"].shape[::-1], interpolation=cv2.INTER_NEAREST_EXACT)\n",
    "    from real_robot.utils.camera import register_depth\n",
    "    depth = register_depth(depth, k_irl, k_rgb, T_rgb_irl, images[\"rgb\"].shape[1::-1], depth_dilation=True)\n",
    "    # ActiveZero++ results\n",
    "    obs_dict[f\"vis_activezero2|{tag}_hand_camera_color\"] = images[\"rgb\"]\n",
    "    obs_dict[f\"vis_activezero2|{tag}_hand_camera_depth\"] = depth\n",
    "    obs_dict[f\"vis_activezero2|{tag}_hand_camera_intr\"] = params[\"intrinsic_cv\"]\n",
    "    obs_dict[f\"vis_activezero2|{tag}_hand_camera_pose\"] = pose_world_camCV\n",
    "\n",
    "    # No upsample\n",
    "    # resize_trans = np.array([[img_resize[0] / orig_w, 0, 0],\n",
    "    #                          [0, img_resize[1] / orig_h, 0],\n",
    "    #                          [0, 0, 1]], dtype=params[\"intrinsic_cv\"].dtype)\n",
    "    # # ActiveZero++ results\n",
    "    # obs_dict[f\"vis_activezero2|{tag}_hand_camera_color\"] = cv2.resize(images[\"rgb\"], img_resize, interpolation=cv2.INTER_CUBIC)\n",
    "    # obs_dict[f\"vis_activezero2|{tag}_hand_camera_depth\"] = depth\n",
    "    # obs_dict[f\"vis_activezero2|{tag}_hand_camera_intr\"] = resize_trans @ params[\"intrinsic_cv\"]\n",
    "    # obs_dict[f\"vis_activezero2|{tag}_hand_camera_pose\"] = pose_world_camCV\n",
    "\n",
    "    # ----- Simsense ----- #\n",
    "    depth_simsense = depth_engine.compute(images[\"ir_l\"], images[\"ir_r\"])\n",
    "    # SimSense results\n",
    "    obs_dict[f\"vis_simsense|{tag}_hand_camera_color\"] = images[\"rgb\"]\n",
    "    obs_dict[f\"vis_simsense|{tag}_hand_camera_depth\"] = depth_simsense\n",
    "    obs_dict[f\"vis_simsense|{tag}_hand_camera_intr\"] = params[\"intrinsic_cv\"]\n",
    "    obs_dict[f\"vis_simsense|{tag}_hand_camera_pose\"] = pose_world_camCV\n",
    "\n",
    "obs_dict = dict(sorted(obs_dict.items()))  # sort by key\n",
    "\n",
    "visualizer = Visualizer(run_as_process=True)\n",
    "visualizer.show_obs(obs_dict)\n",
    "visualizer.render()\n",
    "\n",
    "list(obs_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((480, 848), dtype('float32'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from real_robot.utils.visualization import Visualizer\n",
    "\n",
    "from real_robot.sensors.simsense_depth import SimsenseDepth\n",
    "\n",
    "data_dir = Path(\"capture\").resolve()\n",
    "tag = \"15cm_max_power\"\n",
    "align_depth_to_color = True\n",
    "\n",
    "gt_images = np.load(data_dir / \"60cm_images.npz\")\n",
    "images = np.load(data_dir / f\"{tag}_images.npz\")\n",
    "params = np.load(data_dir / f\"{tag}_params.npz\")\n",
    "images_unaligned = np.load(data_dir / f\"{tag}_unaligned_images.npz\")\n",
    "params_unaligned = np.load(data_dir / f\"{tag}_unaligned_params.npz\")\n",
    "ir_shape = images[\"ir_l\"].shape\n",
    "assert images[\"ir_r\"].shape == ir_shape, f'Mismatched IR shape: left={ir_shape}, right={images[\"ir_r\"].shape}'\n",
    "k_rgb = params[\"intrinsic_cv\"]\n",
    "k_irl = k_irr = np.array([[430.13980103,   0.        , 425.1628418 ],\n",
    "                          [  0.        , 430.13980103, 235.27651978],\n",
    "                          [  0.        ,   0.        ,   1.        ]])\n",
    "\n",
    "# rsdevice.all_extrinsics[\"Infrared 1=>Infrared 2\"]\n",
    "T_irr_irl = np.array([[ 1.       ,  0.       ,  0.       , -0.0501572],\n",
    "                      [ 0.       ,  1.       ,  0.       ,  0.       ],\n",
    "                      [ 0.       ,  0.       ,  1.       ,  0.       ],\n",
    "                      [ 0.       ,  0.       ,  0.       ,  1.       ]])\n",
    "# rsdevice.all_extrinsics[\"Infrared 1=>Color\"]\n",
    "T_rgb_irl = np.array([[ 9.99862015e-01,  1.34780351e-02,  9.70994867e-03, 1.48976548e-02],\n",
    "                      [-1.35059441e-02,  9.99904811e-01,  2.81448336e-03, 1.15314942e-05],\n",
    "                      [-9.67109110e-03, -2.94523709e-03,  9.99948919e-01, 1.56505470e-04],\n",
    "                      [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, 1.00000000e+00]])\n",
    "\n",
    "if align_depth_to_color:\n",
    "    depth_engine = SimsenseDepth(\n",
    "        ir_shape[::-1], k_l=k_irl, k_r=k_irr, l2r=T_irr_irl, k_rgb=k_rgb,\n",
    "        rgb_size=images[\"rgb\"].shape[1::-1], l2rgb=T_rgb_irl,\n",
    "        max_disp=1024, median_filter_size=3, depth_dilation=True\n",
    "    )\n",
    "else:\n",
    "    depth_engine = SimsenseDepth(\n",
    "        ir_shape[::-1], k_l=k_irl, k_r=k_irr, l2r=T_irr_irl, k_rgb=k_rgb,\n",
    "        max_disp=1024, median_filter_size=3, depth_dilation=True\n",
    "    )\n",
    "    print(\"No align\")\n",
    "\n",
    "depth_simsense = depth_engine.compute(images[\"ir_l\"], images[\"ir_r\"])\n",
    "depth_simsense.shape, depth_simsense.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-10-20 15:47:23,105] [CV2Visualizer] [cv2_visualizer.py:162] [INFO] Running <CV2Visualizer: Images> as a separate process\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEngine (64 bits) created at 0x5595200ef9e0 (threading is enabled)\n",
      "FEngine resolved backend: OpenGL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-10-20 15:47:25,399] [O3DGUIVisualizer] [o3d_gui_visualizer.py:1579] [INFO] Running <O3DGUIVisualizer: Point Clouds> as a separate process\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sapien.core import Pose\n",
    "visualizer = Visualizer(run_as_process=True)\n",
    "visualizer.show_obs({\n",
    "    \"vis_rs_hand_camera_color\": images[\"rgb\"],\n",
    "    \"vis_rs_hand_camera_depth\": images[\"depth\"],\n",
    "    \"vis_rs_hand_camera_intr\": params[\"intrinsic_cv\"],\n",
    "    \"vis_rs_hand_camera_infrared_1\": images[\"ir_l\"],\n",
    "    \"vis_rs_hand_camera_infrared_2\": images[\"ir_r\"],\n",
    "    \"vis_rs_hand_camera_pose\": Pose.from_transformation_matrix(params[\"cam2world_cv\"]),\n",
    "    \"vis_simsense_hand_camera_color\": images[\"rgb\"],\n",
    "    \"vis_simsense_hand_camera_depth\": depth_simsense,\n",
    "    \"vis_simsense_hand_camera_intr\": params[\"intrinsic_cv\"],\n",
    "    #\"vis_simsense_hand_camera_intr\": k_irl,\n",
    "    \"vis_simsense_hand_camera_pose\": Pose.from_transformation_matrix(params[\"cam2world_cv\"]),\n",
    "})\n",
    "visualizer.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((480, 848), dtype('float32'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Register depth (align depth to color)\n",
    "from real_robot.utils.camera import register_depth\n",
    "\n",
    "depth = register_depth(depth, k_irl, k_rgb, T_rgb_irl, images[\"rgb\"].shape[1::-1], depth_dilation=True)\n",
    "depth.shape, depth.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.16 ms ± 1.26 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit register_depth(depth, k_irl, k_rgb, T_rgb_irl, images[\"rgb\"].shape[1::-1], depth_dilation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((480, 848), dtype('float32'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Register depth (align depth to color)\n",
    "from real_robot.utils.camera import register_depth\n",
    "\n",
    "depth = register_depth(depth_simsense, k_irl, k_rgb, T_rgb_irl, images[\"rgb\"].shape[1::-1], depth_dilation=True)\n",
    "depth.shape, depth.dtype"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
