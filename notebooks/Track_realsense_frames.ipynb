{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;21mRealSenseAPI - (realsense.py:161) - INFO - 2023-05-19 11:39 - Found Intel RealSense D435 (S/N: 146322072630 FW: 05.12.09.00 on USB 3.2)\u001b[0m\n",
      "\u001b[38;21mRSDevice - (realsense.py:88) - INFO - 2023-05-19 11:39 - Loaded \"High Accuracy\" preset for <RSDevice: Intel RealSense D435 (S/N: 146322072630)>\u001b[0m\n",
      "\u001b[38;21mRSDevice - (realsense.py:37) - INFO - 2023-05-19 11:39 - Setting Depth \"option.exposure\" to 1500\u001b[0m\n",
      "\u001b[38;21mRealSenseAPI - (realsense.py:167) - INFO - 2023-05-19 11:39 - Loading finished: found 1 devices\u001b[0m\n",
      "\u001b[38;21mRSDevice - (realsense.py:100) - INFO - 2023-05-19 11:39 - Started device <RSDevice: Intel RealSense D435 (S/N: 146322072630)> with 2 streams\u001b[0m\n",
      "\u001b[38;21mRSDevice - (realsense.py:102) - INFO - 2023-05-19 11:39 - <pyrealsense2.[video_]stream_profile: Depth(0) 848x480 @ 30fps Z16>\u001b[0m\n",
      "\u001b[38;21mRSDevice - (realsense.py:102) - INFO - 2023-05-19 11:39 - <pyrealsense2.[video_]stream_profile: Color(0) 848x480 @ 30fps RGB8>\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(dtype('uint8'), (480, 848, 3), (480, 848), (4,), (480, 848, 3))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import pyrealsense2 as rs\n",
    "from real_robot.utils.realsense import RealSenseAPI\n",
    "from real_robot.utils.camera import depth2xyz, transform_points\n",
    "\n",
    "realsense = RealSenseAPI(preset=\"High Accuracy\",\n",
    "                         depth_option_kwargs={\n",
    "                             rs.option.exposure: 1500\n",
    "                         })\n",
    "color_image, depth_image, intr_array = realsense.capture()\n",
    "\n",
    "xyz_image = depth2xyz(depth_image, *intr_array)\n",
    "#world_xyz_image = transform_points(xyz_image, T)\n",
    "#world_xyz_image.shape\n",
    "\n",
    "color_image.dtype, color_image.shape, depth_image.shape, intr_array.shape, xyz_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seg_and_track_anything.seg_track_anything import draw_mask, colorize_mask\n",
    "from mani_skill2.utils.visualization.misc import tile_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "from real_robot.utils.camera import depth2xyz, transform_points\n",
    "\n",
    "from pyrl.utils.lib3d import np2pcd\n",
    "def _process_pts(\n",
    "        pts_lst,\n",
    "        voxel_downsample_size, nb_neighbors, std_ratio\n",
    "    ):\n",
    "        from pyrl.utils.lib3d import np2pcd\n",
    "\n",
    "        if isinstance(pts_lst, np.ndarray):\n",
    "            pts_lst = [pts_lst]\n",
    "\n",
    "        ret_pts_lst = []\n",
    "        for pts in pts_lst:\n",
    "            pcd = np2pcd(pts)\n",
    "            if voxel_downsample_size is not None:\n",
    "                pcd = pcd.voxel_down_sample(voxel_size=voxel_downsample_size)\n",
    "            pcd_filter, inlier_inds = pcd.remove_statistical_outlier(\n",
    "                nb_neighbors=nb_neighbors, std_ratio=std_ratio\n",
    "            )\n",
    "            ret_pts_lst.append(np.asarray(pcd_filter.points))\n",
    "\n",
    "        if len(ret_pts_lst) == 1:\n",
    "            return ret_pts_lst[0]\n",
    "\n",
    "        return ret_pts_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight'])\n",
      "\n",
      "Loading GroundingDINO: Took 3.082 seconds\n",
      "\n",
      "Loading SAM: Took 4.191 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "2023-05-19 11:39:29.735921: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[38;21mRSDevice - (realsense.py:134) - INFO - 2023-05-19 11:41 - Stopped device <RSDevice: Intel RealSense D435 (S/N: 146322072630)>\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "\n",
    "from grounded_sam_track import GroundedSAMTrack\n",
    "grounded_sam_track = GroundedSAMTrack(predict_gap=9999, device=\"cuda:1\")\n",
    "\n",
    "camera_pose = np.load(\"/rl_benchmark/real_robot/notebooks/Tb_b2c.npy\")\n",
    "\n",
    "voxel_downsample_size, nb_neighbors, std_ratio = 0.005, 20, 0.005\n",
    "\n",
    "\n",
    "ret = grounded_sam_track.predict_and_track_batch(\n",
    "    [color_image], [0], [\"red cube\", \"green bowl\"]\n",
    ")\n",
    "pred_mask = ret[\"pred_masks\"][0]\n",
    "\n",
    "xyz_image = depth2xyz(depth_image, *intr_array)\n",
    "world_xyz_image = transform_points(xyz_image, camera_pose)\n",
    "\n",
    "cv2.namedWindow(\"Color / Depth\")\n",
    "cv2.imshow(\"Color / Depth\", color_image)\n",
    "cv2.waitKey(1)\n",
    "\n",
    "pcd_vis = o3d.visualization.Visualizer()\n",
    "pcd_vis.create_window(\"Point Cloud\", width=1280, height=720)\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(world_xyz_image.reshape(-1, 3))\n",
    "pcd.colors = o3d.utility.Vector3dVector(color_image.reshape(-1, 3) / 255.0)\n",
    "coord_frame = o3d.geometry.TriangleMesh().create_coordinate_frame()\n",
    "pcd_vis.add_geometry(coord_frame)\n",
    "pcd_vis.add_geometry(pcd)\n",
    "\n",
    "cube_pts = world_xyz_image[pred_mask == 1]\n",
    "cube_pts = _process_pts(\n",
    "    cube_pts, voxel_downsample_size, nb_neighbors, std_ratio\n",
    ")\n",
    "bowl_pts = world_xyz_image[pred_mask == 2]\n",
    "bowl_pts = _process_pts(\n",
    "    bowl_pts, voxel_downsample_size, nb_neighbors, std_ratio\n",
    ")\n",
    "cube_pos = np.mean(cube_pts, axis=0)\n",
    "bowl_pos = np.mean(bowl_pts, axis=0)\n",
    "# Extract bbox from object_pts\n",
    "bowl_mins, bowl_maxs = bowl_pts.min(0), bowl_pts.max(0)\n",
    "cube_mins, cube_maxs = cube_pts.min(0), cube_pts.max(0)\n",
    "\n",
    "cube_bbox_pos = np.mean([cube_mins, cube_maxs], axis=0)\n",
    "bowl_bbox_pos = np.mean([bowl_mins, bowl_maxs], axis=0)\n",
    "\n",
    "pcd_center = o3d.geometry.PointCloud()\n",
    "pcd_center.points = o3d.utility.Vector3dVector(np.stack([cube_pos, bowl_pos, cube_bbox_pos, bowl_bbox_pos], axis=0))\n",
    "pcd_center.colors = o3d.utility.Vector3dVector(np.stack([[0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0.]], axis=0))\n",
    "pcd_vis.add_geometry(pcd_center)\n",
    "\n",
    "cube_aabb = np2pcd(cube_pts).get_axis_aligned_bounding_box()\n",
    "bowl_aabb = np2pcd(bowl_pts).get_axis_aligned_bounding_box()\n",
    "pcd_vis.add_geometry(cube_aabb)\n",
    "pcd_vis.add_geometry(bowl_aabb)\n",
    "\n",
    "while True:\n",
    "    color_image, depth_image, intr_array = realsense.capture()\n",
    "    pcd_vis.poll_events()\n",
    "    pcd_vis.update_renderer()\n",
    "\n",
    "    depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "    cv2.imshow(\"Color / Depth\", np.hstack([cv2.cvtColor(color_image, cv2.COLOR_RGB2BGR), depth_colormap]))\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:  # ESC\n",
    "        break\n",
    "    elif key == ord('s'):\n",
    "        xyz_image = depth2xyz(depth_image, *intr_array)\n",
    "        world_xyz_image = transform_points(xyz_image, camera_pose)\n",
    "        pcd.points = o3d.utility.Vector3dVector(world_xyz_image.reshape(-1, 3))\n",
    "        pcd.colors = o3d.utility.Vector3dVector(color_image.reshape(-1, 3) / 255.0)\n",
    "\n",
    "        ret = grounded_sam_track.predict_and_track_batch(\n",
    "            [color_image], [0], [\"red cube\", \"green bowl\"]\n",
    "        )\n",
    "        pred_mask = ret[\"pred_masks\"][0]\n",
    "\n",
    "        cube_pts = world_xyz_image[pred_mask == 1]\n",
    "        cube_pts = _process_pts(\n",
    "            cube_pts, voxel_downsample_size, nb_neighbors, std_ratio\n",
    "        )\n",
    "        bowl_pts = world_xyz_image[pred_mask == 2]\n",
    "        bowl_pts = _process_pts(\n",
    "            bowl_pts, voxel_downsample_size, nb_neighbors, std_ratio\n",
    "        )\n",
    "        cube_pos = np.mean(cube_pts, axis=0)\n",
    "        bowl_pos = np.mean(bowl_pts, axis=0)\n",
    "        # Extract bbox from object_pts\n",
    "        bowl_mins, bowl_maxs = bowl_pts.min(0), bowl_pts.max(0)\n",
    "        cube_mins, cube_maxs = cube_pts.min(0), cube_pts.max(0)\n",
    "\n",
    "        cube_bbox_pos = np.mean([cube_mins, cube_maxs], axis=0)\n",
    "        bowl_bbox_pos = np.mean([bowl_mins, bowl_maxs], axis=0)\n",
    "\n",
    "        pcd_center.points = o3d.utility.Vector3dVector(np.stack([cube_pos, bowl_pos, cube_bbox_pos, bowl_bbox_pos], axis=0))\n",
    "        pcd_center.colors = o3d.utility.Vector3dVector(np.stack([[0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0.]], axis=0))\n",
    "        pcd_vis.update_geometry(pcd_center)\n",
    "\n",
    "        cube_aabb_new = np2pcd(cube_pts).get_axis_aligned_bounding_box()\n",
    "        bowl_aabb_new = np2pcd(bowl_pts).get_axis_aligned_bounding_box()\n",
    "        cube_aabb.max_bound = cube_aabb_new.max_bound\n",
    "        cube_aabb.min_bound = cube_aabb_new.min_bound\n",
    "        bowl_aabb.max_bound = bowl_aabb_new.max_bound\n",
    "        bowl_aabb.min_bound = bowl_aabb_new.min_bound\n",
    "        pcd_vis.update_geometry(cube_aabb)\n",
    "        pcd_vis.update_geometry(bowl_aabb)\n",
    "\n",
    "        pcd_vis.update_geometry(pcd)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "pcd_vis.destroy_window()\n",
    "del realsense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1AAAAHgAQAAAACDNbHAAAAD2klEQVR4nO3dPXLTUBSGYZkwDB3aAVqKlkXHXQpLUcFCVFKqoEhBuBSObJnJ/cF+7+GM9L0FESSjR8e/kmyHrlNKKaWUUkoppZRSSimllHLYFyvoKcbZiIoxPttIn2KMv9E1nlLfiNnv3tO77CYEkkp1ijEa3S7O1C90lalvxPOfqQv4jhKr+rBuicXt/Ws8N2FrTF5AKzG0p9b69tT4+vVje2rtPUYVbuxd94JZ+QemzA9w1OXfuUdc8NHgXup6DYXWVIPK1GhHYR2VGuworBSF7lXkqeveZt+aatBRKewZ39VUhlTzfYsGpaiY+PcGVIPKFLYxrqYSJeqNsOMDV1NZUsGOohK1K2psTQUIqKCuDXYUlaj2VG9HURVPExtQfL4o6gg1Sc0QUEHxeaAWO4rPF0WdTfAwFf/Kn4ep9knx54k9TPVPP0JRVEmKfVtHluLzQPGnOT1MtVMq2FF4vijqhKCvqdpTkx2FdzRqviyF1hTe0ajFjsKroUY7CsoFhR82uphqnxR+2Fgz1WBHQR2X6ltT+MGwswtQ1F0UfojvYqpr0IsizqYS5Z4K6wL0SoWPqXZOQZuTWc3ECDXUJeh8VtWFszBWus9xjdmndnYLhLanai3M7aJug4MdNdpRSBlqeHOxCTUS668rXpuJ9dVdV31bCv1cd57ahuzfpin8buDjfrUJ2T1zN5UhhWyQu6kMKeSRw91UllSwo4gqqdGOIhLVjLo5dzs0pfAqTz32TSm8Q1PEPqe/qfZJEbu3/qYSJer/UsQW+ZtqnxRxgOVvKlF3UMGOoqulgh0F5GOqyY6ic0iNdhSQD2q2o+gcUoMdBZShlu1f+qYUnQ/q5k3SwIkLH1PdBBzi11LA9JlV0G+Srt1a4PjAx83i9j2+oSVFl6Hot6j6mIo+FKme6nE3R00Pr72amjfLwG0kRy2bZeCN9Dnq52YZeEDMUS+b5R9tqe0xwbfHqewj9ulyDRG/zzw7VQzr0vfHpULrGx+RD3LkHy2W168G1Bry3J+nnv/62pBC92Ty1HodLe2p9UF2bk+tz1KTAYUYdb3eh5F1FaZaEKSKOt+hTKYi71gFivzAnJNdzo7dmS5NFeyoyY7qus7qrfMzolRRYCVqsaPA3H3MAalEgb9jwNFUoh6kwKdhR1MZUuDOheFUxWc97n84dHRdgfsxRWqyo7qus3q+mgmljuKqo0Y7CkmUqLupwYRClDqKS5QoUaJEHY6a7SjO83QBLnYUV5F67jqr15aerF5UOvdS/hGiEzSTUkoppZRSSimllFJKKaWUUkoppZRSSimllFJKGfQHdWqnrQEB2NsAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=848x480>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "Image.fromarray(pred_mask == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_image = depth2xyz(depth_image, *intr_array)\n",
    "world_xyz_image = transform_points(xyz_image, camera_pose)\n",
    "\n",
    "cube_pts = world_xyz_image[pred_mask == 1]\n",
    "# cube_pts = _process_pts(\n",
    "#     cube_pts, 0.005, 20, 0.005\n",
    "# )\n",
    "bowl_pts = world_xyz_image[pred_mask == 2]\n",
    "# bowl_pts = _process_pts(\n",
    "#     bowl_pts, 0.005, 20, 0.005\n",
    "# )\n",
    "cube_pos = np.mean(cube_pts, axis=0)\n",
    "bowl_pos = np.mean(bowl_pts, axis=0)\n",
    "# Extract bbox from object_pts\n",
    "bowl_mins, bowl_maxs = bowl_pts.min(0), bowl_pts.max(0)\n",
    "cube_mins, cube_maxs = cube_pts.min(0), cube_pts.max(0)\n",
    "\n",
    "cube_bbox_pos = np.mean([cube_mins, cube_maxs], axis=0)\n",
    "bowl_bbox_pos = np.mean([bowl_mins, bowl_maxs], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_downsample_size, nb_neighbors, std_ratio = 0.005, 20, 0.005\n",
    "cube_pcd = np2pcd(cube_pts)\n",
    "pcd = np2pcd(cube_pts)\n",
    "if voxel_downsample_size is not None:\n",
    "    pcd = pcd.voxel_down_sample(voxel_size=voxel_downsample_size)\n",
    "pcd_filter, inlier_inds = pcd.remove_statistical_outlier(\n",
    "    nb_neighbors=nb_neighbors, std_ratio=std_ratio\n",
    ")\n",
    "\n",
    "o3d.visualization.draw_geometries([cube_pcd, pcd, pcd_filter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 7341 points\n",
      "After downsample: 433 points\n",
      "After filter: 403 points\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33f2b9900bb46aaa480e26c39dedacf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value=\"<iframe src='http://localhost:40047/index.html?ui=P_0x7f4e3c232e90_2&reconnect=auto' style='widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "pcd = np2pcd(bowl_pts)\n",
    "#pcd.remove_statisti\n",
    "print(f\"Before: {len(pcd.points)} points\")\n",
    "pcd = pcd.voxel_down_sample(voxel_size=0.005)\n",
    "print(f\"After downsample: {len(pcd.points)} points\")\n",
    "pcd_filter, inlier_inds = pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=0.005)\n",
    "#%timeit pcd_filter, inlier_inds = pcd.remove_radius_outlier(nb_points=20, radius=0.1)\n",
    "print(f\"After filter: {len(pcd_filter.points)} points\")\n",
    "\n",
    "inlier_mask = np.zeros(len(pcd.points)).astype(bool)\n",
    "inlier_mask[inlier_inds] = True\n",
    "\n",
    "import pyvista as pv\n",
    "plotter = pv.Plotter(notebook=True)\n",
    "plotter.add_points(np.asarray(pcd.points)[inlier_mask], color='w', point_size=10.0)\n",
    "plotter.add_points(np.asarray(pcd.points)[~inlier_mask], color='r', point_size=10.0)\n",
    "plotter.add_axes()\n",
    "plotter.add_bounding_box()\n",
    "plotter.show(jupyter_backend='trame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;21mRSDevice - (realsense.py:115) - INFO - 2023-05-14 18:54 - Received frame #29\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "color_image, depth_image, intr_array = realsense.capture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;21mRSDevice - (realsense.py:134) - INFO - 2023-05-14 18:54 - Stopped device <RSDevice: Intel RealSense D435 (S/N: 146322070293)>\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "del realsense"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
